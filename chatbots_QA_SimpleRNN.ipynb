{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Question-Answering Machine\n",
    "\n",
    "\n",
    "### Project  Statement: Working on a language understanding module for a chatbot. The chatbot must be able to answer questions about historical facts you hand it through a chat window: it must be able to refer back to older information in order to answer a question. Specifically, every question can be answered by exactly one statement that occurred in the past. I have at hand a large dataset of hand-annotated questions linked to supporting facts, and a set of candidate architectures that allow me to reason about memory. \n",
    "\n",
    "### Models that I am going to use to implement chatbot module:\n",
    "\n",
    "#### 1. RNN, \n",
    "#### 2. LSTM\n",
    "#### 3. End-to-end memory networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Import modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import keras.utils\n",
    "from keras import layers\n",
    "from keras.layers import merge\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Activation, SimpleRNN\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from functools import reduce\n",
    "import tarfile\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Import dataset: facts, questions and answers in text format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "train=os.path.realpath('C:/Users/nisht/Desktop/MITA/capstone_project/qa1_single-supporting-fact_train.txt')\n",
    "test=os.path.realpath('C:/Users/nisht/Desktop/MITA/capstone_project/qa1_single-supporting-fact_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Create a Tokenizer- A lookup facility that converts words into numerical indices. This tokenizer is fitted on a vocabulary, and here, we use all words in both training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(trainingdata, testdata):\n",
    "    f=open(trainingdata, \"r\")\n",
    "    text=[]\n",
    "\n",
    "    for line in f:\n",
    "        m=re.match(\"^\\d+\\s([^\\.]+)[\\.].*\",line.rstrip())\n",
    "        if m:\n",
    "            text.append(m.group(1))\n",
    "        else:\n",
    "            m=re.match(\"^\\d+\\s([^\\?]+)[\\?]\\s\\t([^\\t]+)\",line.rstrip())\n",
    "            if m:\n",
    "                text.append(m.group(1)+' '+m.group(2))\n",
    "    f.close()\n",
    "\n",
    "    f=open(testdata, \"r\")\n",
    "    for line in f:\n",
    "        m=re.match(\"^\\d+\\s([^\\.]+)[\\.].*\",line.rstrip())\n",
    "        if m:\n",
    "            text.append(m.group(1))\n",
    "        else:\n",
    "            m=re.match(\"^\\d+\\s([^\\?]+)[\\?].*\",line.rstrip())\n",
    "            if m:\n",
    "                text.append(m.group(1))\n",
    "    f.close()\n",
    "\n",
    "    vocabulary=set([word for word in text])\n",
    "    max_words = len(vocabulary)\n",
    "    tokenizer = Tokenizer(num_words=max_words, char_level=False, split=' ')\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    return tokenizer, max_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stories_n_context(filename,tokenizer,vocab_size,use_context=context):\n",
    "    f=open(filename,\"r\")\n",
    "    X=[]\n",
    "    Q=[]\n",
    "    y=[]\n",
    "    max_story_len=0\n",
    "    max_query_len=0\n",
    "\n",
    "    for line in f:\n",
    "        m=re.match(\"^(\\d+)\\s(.+)\\.\",line.rstrip())\n",
    "        if m:\n",
    "            if int(m.group(1))==1:\n",
    "                story={}\n",
    "            story[int(m.group(1))]=m.group(2)\n",
    "        else:\n",
    "            m=re.match(\"^\\d+\\s(.+)\\?\\s\\t([^\\t]+)\\t(.+)\",line.rstrip())\n",
    "            if m:\n",
    "                question=m.group(1)\n",
    "                answer=m.group(2)\n",
    "                answer_ids=[int(x) for x in m.group(3).split(\" \")]\n",
    "                facts=' '.join([story[id] for id in answer_ids])\n",
    "                all_facts=' '.join([story[id] for id in story])\n",
    "                facts_v=vectorize(facts,tokenizer)\n",
    "                all_facts_v=vectorize(all_facts,tokenizer)\n",
    "\n",
    "                if use_context==0:\n",
    "                    vectorized_fact=facts_v\n",
    "                elif use_context==-1:\n",
    "                    vectorized_fact=all_facts_v\n",
    "                else:\n",
    "                    x=min(use_context, len(story))\n",
    "                    facts=' '.join([story[id] for id in answer_ids])+' '\n",
    "                    n=0\n",
    "                    for id in story:\n",
    "                        if n<x and id not in answer_ids:\n",
    "                            facts+=story[id]+' '\n",
    "                            n+=1\n",
    "                    vectorized_fact=vectorize(facts,tokenizer)\n",
    "                l=len(vectorized_fact)\n",
    "                if l>max_story_len:\n",
    "                    max_story_len=l\n",
    "                vectorized_question=vectorize(question,tokenizer)\n",
    "                l=len(vectorized_question)\n",
    "                if l>max_query_len:\n",
    "                    max_query_len=l\n",
    "\n",
    "                vectorized_answer=vectorize(answer,tokenizer)\n",
    "\n",
    "                X.append(vectorized_fact)\n",
    "                Q.append(vectorized_question)\n",
    "                answer=np.zeros(vocab_size)\n",
    "                answer[vectorized_answer[0]]=1\n",
    "                y.append(answer)\n",
    "    f.close()\n",
    "\n",
    "    return np.array(X),np.array(Q),np.array(y), max_story_len, max_query_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(s, tokenizer):\n",
    "    vector=tokenizer.texts_to_sequences([s])\n",
    "    return vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trainingData, testData, context):\n",
    "    tokenizer,vocab_size=create_tokenizer(trainingData,testData)\n",
    "\n",
    "    X_tr,Q_tr,y_tr,max_story_len_tr, max_query_len_tr=process_stories_n_context(trainingData,tokenizer,vocab_size,use_context=context)\n",
    "    X_te,Q_te,y_te, max_story_len_te, max_query_len_te=process_stories_n_context(testData,tokenizer,vocab_size,use_context=context)\n",
    "\n",
    "    max_story_len=max(max_story_len_tr, max_story_len_te)\n",
    "    max_query_len=max(max_query_len_tr, max_query_len_te)\n",
    "\n",
    "    X_tr=pad_sequences(X_tr,max_story_len)\n",
    "    Q_tr=pad_sequences(Q_tr, max_query_len)\n",
    "    X_te=pad_sequences(X_te,max_story_len)\n",
    "    Q_te=pad_sequences(Q_te,max_query_len)\n",
    "\n",
    "    embedding=layers.Embedding(vocab_size,100)\n",
    "\n",
    "    story = layers.Input(shape=(max_story_len,), dtype='int32')\n",
    "    encoded_story = embedding(story)\n",
    "    encoded_story = SimpleRNN(30)(encoded_story)\n",
    "\n",
    "    question = layers.Input(shape=(max_query_len,), dtype='int32')\n",
    "    encoded_question = embedding(question)\n",
    "    encoded_question = SimpleRNN(30)(encoded_question)\n",
    "\n",
    "    merged = layers.concatenate([encoded_story, encoded_question])\n",
    "    preds = layers.Dense(vocab_size, activation='softmax')(merged)\n",
    "\n",
    "    model = Model([story, question], preds)\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    #print(X_te,Q_te)\n",
    "\n",
    "    return X_tr,Q_tr,y_tr,X_te,Q_te,y_te,model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "9000/9000 [==============================] - 12s 1ms/step - loss: 1.0589 - acc: 0.8548 - val_loss: 0.0591 - val_acc: 1.0000\n",
      "Epoch 2/30\n",
      "9000/9000 [==============================] - 3s 278us/step - loss: 0.0276 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 1.0000\n",
      "Epoch 3/30\n",
      "9000/9000 [==============================] - 3s 289us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 4/30\n",
      "9000/9000 [==============================] - 3s 284us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 5/30\n",
      "9000/9000 [==============================] - 3s 296us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 6/30\n",
      "9000/9000 [==============================] - 3s 291us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 7/30\n",
      "9000/9000 [==============================] - 3s 287us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 8/30\n",
      "9000/9000 [==============================] - 2s 269us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
      "Epoch 9/30\n",
      "9000/9000 [==============================] - 2s 273us/step - loss: 9.1382e-04 - acc: 1.0000 - val_loss: 8.0899e-04 - val_acc: 1.0000\n",
      "Epoch 10/30\n",
      "9000/9000 [==============================] - 3s 285us/step - loss: 7.2500e-04 - acc: 1.0000 - val_loss: 6.4744e-04 - val_acc: 1.0000\n",
      "Epoch 11/30\n",
      "9000/9000 [==============================] - 3s 349us/step - loss: 5.8430e-04 - acc: 1.0000 - val_loss: 5.2548e-04 - val_acc: 1.0000\n",
      "Epoch 12/30\n",
      "9000/9000 [==============================] - 3s 322us/step - loss: 4.7674e-04 - acc: 1.0000 - val_loss: 4.3130e-04 - val_acc: 1.0000\n",
      "Epoch 13/30\n",
      "9000/9000 [==============================] - 3s 302us/step - loss: 3.9301e-04 - acc: 1.0000 - val_loss: 3.5695e-04 - val_acc: 1.0000\n",
      "Epoch 14/30\n",
      "9000/9000 [==============================] - 3s 358us/step - loss: 3.2645e-04 - acc: 1.0000 - val_loss: 2.9754e-04 - val_acc: 1.0000\n",
      "Epoch 15/30\n",
      "9000/9000 [==============================] - 2s 246us/step - loss: 2.7291e-04 - acc: 1.0000 - val_loss: 2.4959e-04 - val_acc: 1.0000\n",
      "Epoch 16/30\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 2.2973e-04 - acc: 1.000 - 2s 259us/step - loss: 2.2943e-04 - acc: 1.0000 - val_loss: 2.1019e-04 - val_acc: 1.0000\n",
      "Epoch 17/30\n",
      "9000/9000 [==============================] - 3s 304us/step - loss: 1.9343e-04 - acc: 1.0000 - val_loss: 1.7755e-04 - val_acc: 1.0000\n",
      "Epoch 18/30\n",
      "9000/9000 [==============================] - 3s 298us/step - loss: 1.6351e-04 - acc: 1.0000 - val_loss: 1.5016e-04 - val_acc: 1.0000\n",
      "Epoch 19/30\n",
      "9000/9000 [==============================] - 3s 297us/step - loss: 1.3853e-04 - acc: 1.0000 - val_loss: 1.2737e-04 - val_acc: 1.0000\n",
      "Epoch 20/30\n",
      "9000/9000 [==============================] - 3s 325us/step - loss: 1.1772e-04 - acc: 1.0000 - val_loss: 1.0831e-04 - val_acc: 1.0000\n",
      "Epoch 21/30\n",
      "9000/9000 [==============================] - 3s 296us/step - loss: 1.0011e-04 - acc: 1.0000 - val_loss: 9.2203e-05 - val_acc: 1.0000\n",
      "Epoch 22/30\n",
      "9000/9000 [==============================] - 3s 282us/step - loss: 8.5369e-05 - acc: 1.0000 - val_loss: 7.8561e-05 - val_acc: 1.0000\n",
      "Epoch 23/30\n",
      "9000/9000 [==============================] - 3s 285us/step - loss: 7.2762e-05 - acc: 1.0000 - val_loss: 6.7059e-05 - val_acc: 1.0000\n",
      "Epoch 24/30\n",
      "9000/9000 [==============================] - 3s 282us/step - loss: 6.2159e-05 - acc: 1.0000 - val_loss: 5.7500e-05 - val_acc: 1.0000\n",
      "Epoch 25/30\n",
      "9000/9000 [==============================] - 2s 269us/step - loss: 5.3388e-05 - acc: 1.0000 - val_loss: 4.9415e-05 - val_acc: 1.0000\n",
      "Epoch 26/30\n",
      "9000/9000 [==============================] - 2s 265us/step - loss: 4.5815e-05 - acc: 1.0000 - val_loss: 4.2396e-05 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "9000/9000 [==============================] - 2s 266us/step - loss: 3.9437e-05 - acc: 1.0000 - val_loss: 3.6567e-05 - val_acc: 1.0000\n",
      "Epoch 28/30\n",
      "9000/9000 [==============================] - 3s 287us/step - loss: 3.4009e-05 - acc: 1.0000 - val_loss: 3.1556e-05 - val_acc: 1.0000\n",
      "Epoch 29/30\n",
      "9000/9000 [==============================] - 2s 269us/step - loss: 2.9372e-05 - acc: 1.0000 - val_loss: 2.7291e-05 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "9000/9000 [==============================] - 3s 287us/step - loss: 2.5428e-05 - acc: 1.0000 - val_loss: 2.3633e-05 - val_acc: 1.0000\n",
      "Evaluation for context=0\n",
      "1000/1000 [==============================] - 0s 169us/step\n",
      "Test loss / test accuracy = 0.0000 / 1.0000\n"
     ]
    }
   ],
   "source": [
    "#def run_evaluate(trainingData, testData, context=6):\n",
    "import os\n",
    "import sys\n",
    "train=os.path.realpath('C:/Users/nisht/Desktop/MITA/capstone_project/qa1_single-supporting-fact_train.txt')\n",
    "test=os.path.realpath('C:/Users/nisht/Desktop/MITA/capstone_project/qa1_single-supporting-fact_test.txt')\n",
    "\n",
    "context1=0\n",
    "X_tr,Q_tr,y_tr,X_te,Q_te,y_te,model1=create_model(train,test,context1)\n",
    "print('Training')\n",
    "history1=model1.fit([X_tr, Q_tr], y_tr,batch_size=32,epochs=30, verbose=1,validation_split=0.1, shuffle=False)\n",
    "print('Evaluation for context=0')\n",
    "loss1, acc1 = model1.evaluate([X_te,Q_te], y_te,batch_size=32)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss1, acc1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "9000/9000 [==============================] - 15s 2ms/step - loss: 1.8595 - acc: 0.3059 - val_loss: 1.0835 - val_acc: 0.4800\n",
      "Epoch 2/30\n",
      "9000/9000 [==============================] - 3s 342us/step - loss: 0.7118 - acc: 0.7593 - val_loss: 0.4134 - val_acc: 0.8780\n",
      "Epoch 3/30\n",
      "9000/9000 [==============================] - 3s 370us/step - loss: 0.2354 - acc: 0.9762 - val_loss: 0.1149 - val_acc: 0.9970\n",
      "Epoch 4/30\n",
      "9000/9000 [==============================] - 3s 357us/step - loss: 0.0879 - acc: 0.9958 - val_loss: 0.0473 - val_acc: 0.9980\n",
      "Epoch 5/30\n",
      "9000/9000 [==============================] - 3s 358us/step - loss: 0.0361 - acc: 0.9994 - val_loss: 0.0245 - val_acc: 1.0000\n",
      "Epoch 6/30\n",
      "9000/9000 [==============================] - 3s 362us/step - loss: 0.0227 - acc: 0.9992 - val_loss: 0.0498 - val_acc: 0.9930\n",
      "Epoch 7/30\n",
      "9000/9000 [==============================] - 3s 344us/step - loss: 0.0236 - acc: 0.9979 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 8/30\n",
      "9000/9000 [==============================] - 3s 345us/step - loss: 0.0205 - acc: 0.9970 - val_loss: 0.0239 - val_acc: 0.9980\n",
      "Epoch 9/30\n",
      "9000/9000 [==============================] - 3s 353us/step - loss: 0.0160 - acc: 0.9988 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 10/30\n",
      "9000/9000 [==============================] - 3s 377us/step - loss: 0.0183 - acc: 0.9957 - val_loss: 0.0363 - val_acc: 0.9930\n",
      "Epoch 11/30\n",
      "9000/9000 [==============================] - 3s 388us/step - loss: 0.0105 - acc: 0.9994 - val_loss: 0.0069 - val_acc: 0.9990\n",
      "Epoch 12/30\n",
      "9000/9000 [==============================] - 4s 394us/step - loss: 0.0048 - acc: 0.9999 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 13/30\n",
      "9000/9000 [==============================] - 3s 371us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 14/30\n",
      "9000/9000 [==============================] - 3s 384us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 15/30\n",
      "9000/9000 [==============================] - 3s 376us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 16/30\n",
      "9000/9000 [==============================] - 3s 381us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 17/30\n",
      "9000/9000 [==============================] - 3s 370us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 18/30\n",
      "9000/9000 [==============================] - 3s 374us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 9.2896e-04 - val_acc: 1.0000\n",
      "Epoch 19/30\n",
      "9000/9000 [==============================] - 3s 387us/step - loss: 8.5805e-04 - acc: 1.0000 - val_loss: 7.7857e-04 - val_acc: 1.0000\n",
      "Epoch 20/30\n",
      "9000/9000 [==============================] - 3s 386us/step - loss: 7.2189e-04 - acc: 1.0000 - val_loss: 6.5625e-04 - val_acc: 1.0000\n",
      "Epoch 21/30\n",
      "9000/9000 [==============================] - 3s 359us/step - loss: 6.0989e-04 - acc: 1.0000 - val_loss: 5.5584e-04 - val_acc: 1.0000\n",
      "Epoch 22/30\n",
      "9000/9000 [==============================] - 3s 358us/step - loss: 5.1702e-04 - acc: 1.0000 - val_loss: 4.7269e-04 - val_acc: 1.0000\n",
      "Epoch 23/30\n",
      "9000/9000 [==============================] - 3s 371us/step - loss: 4.3952e-04 - acc: 1.0000 - val_loss: 4.0324e-04 - val_acc: 1.0000\n",
      "Epoch 24/30\n",
      "9000/9000 [==============================] - 3s 379us/step - loss: 3.7448e-04 - acc: 1.0000 - val_loss: 3.4476e-04 - val_acc: 1.0000\n",
      "Epoch 25/30\n",
      "9000/9000 [==============================] - 3s 369us/step - loss: 3.1967e-04 - acc: 1.0000 - val_loss: 2.9520e-04 - val_acc: 1.0000\n",
      "Epoch 26/30\n",
      "9000/9000 [==============================] - 3s 389us/step - loss: 2.7331e-04 - acc: 1.0000 - val_loss: 2.5302e-04 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "9000/9000 [==============================] - 3s 365us/step - loss: 2.3398e-04 - acc: 1.0000 - val_loss: 2.1709e-04 - val_acc: 1.0000\n",
      "Epoch 28/30\n",
      "9000/9000 [==============================] - 3s 357us/step - loss: 2.0054e-04 - acc: 1.0000 - val_loss: 1.8644e-04 - val_acc: 1.0000\n",
      "Epoch 29/30\n",
      "9000/9000 [==============================] - 3s 356us/step - loss: 1.7204e-04 - acc: 1.0000 - val_loss: 1.6025e-04 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "9000/9000 [==============================] - 3s 356us/step - loss: 1.4771e-04 - acc: 1.0000 - val_loss: 1.3786e-04 - val_acc: 1.0000\n",
      "Evaluation for context=2\n",
      "1000/1000 [==============================] - 0s 154us/step\n",
      "Test loss / test accuracy = 0.0002 / 1.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "train=os.path.realpath('C:/Users/nisht/Desktop/MITA/capstone_project/qa1_single-supporting-fact_train.txt')\n",
    "test=os.path.realpath('C:/Users/nisht/Desktop/MITA/capstone_project/qa1_single-supporting-fact_test.txt')\n",
    "\n",
    "context2=2\n",
    "X_tr,Q_tr,y_tr,X_te,Q_te,y_te,model2=create_model(train,test,context2)\n",
    "\n",
    "print('Training')\n",
    "history2=model2.fit([X_tr, Q_tr], y_tr,batch_size=32,epochs=30, verbose=1,validation_split=0.1, shuffle=False)\n",
    "\n",
    "print('Evaluation for context=2')\n",
    "loss2, acc2 = model2.evaluate([X_te,Q_te], y_te,batch_size=32)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss2, acc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "9000/9000 [==============================] - 11s 1ms/step - loss: 2.1087 - acc: 0.1657 - val_loss: 1.7949 - val_acc: 0.1710\n",
      "Epoch 2/30\n",
      "9000/9000 [==============================] - 4s 421us/step - loss: 1.7555 - acc: 0.2191 - val_loss: 1.6417 - val_acc: 0.2860\n",
      "Epoch 3/30\n",
      "9000/9000 [==============================] - 4s 479us/step - loss: 1.6104 - acc: 0.2882 - val_loss: 1.4196 - val_acc: 0.3900\n",
      "Epoch 4/30\n",
      "9000/9000 [==============================] - 4s 429us/step - loss: 1.2135 - acc: 0.4547 - val_loss: 1.0745 - val_acc: 0.5320\n",
      "Epoch 5/30\n",
      "9000/9000 [==============================] - 4s 444us/step - loss: 0.8829 - acc: 0.6510 - val_loss: 0.7714 - val_acc: 0.7110\n",
      "Epoch 6/30\n",
      "9000/9000 [==============================] - 4s 430us/step - loss: 0.6329 - acc: 0.8022 - val_loss: 0.5247 - val_acc: 0.8240\n",
      "Epoch 7/30\n",
      "9000/9000 [==============================] - 4s 425us/step - loss: 0.4680 - acc: 0.8563 - val_loss: 0.4061 - val_acc: 0.8830\n",
      "Epoch 8/30\n",
      "9000/9000 [==============================] - 4s 437us/step - loss: 0.3303 - acc: 0.9001 - val_loss: 0.2935 - val_acc: 0.9180\n",
      "Epoch 9/30\n",
      "9000/9000 [==============================] - 4s 440us/step - loss: 0.3107 - acc: 0.8918 - val_loss: 0.2747 - val_acc: 0.9140\n",
      "Epoch 10/30\n",
      "9000/9000 [==============================] - 4s 434us/step - loss: 0.2459 - acc: 0.9124 - val_loss: 0.2333 - val_acc: 0.9200\n",
      "Epoch 11/30\n",
      "9000/9000 [==============================] - 4s 420us/step - loss: 0.1871 - acc: 0.9487 - val_loss: 0.1626 - val_acc: 0.9680\n",
      "Epoch 12/30\n",
      "9000/9000 [==============================] - 5s 522us/step - loss: 0.1598 - acc: 0.9604 - val_loss: 0.1392 - val_acc: 0.9690\n",
      "Epoch 13/30\n",
      "9000/9000 [==============================] - 4s 405us/step - loss: 0.1470 - acc: 0.9608 - val_loss: 0.1303 - val_acc: 0.9730\n",
      "Epoch 14/30\n",
      "9000/9000 [==============================] - 4s 405us/step - loss: 0.1322 - acc: 0.9673 - val_loss: 0.1049 - val_acc: 0.9830\n",
      "Epoch 15/30\n",
      "9000/9000 [==============================] - 4s 431us/step - loss: 0.0917 - acc: 0.9821 - val_loss: 0.0892 - val_acc: 0.9870\n",
      "Epoch 16/30\n",
      "9000/9000 [==============================] - 4s 416us/step - loss: 0.0758 - acc: 0.9847 - val_loss: 0.0682 - val_acc: 0.9930\n",
      "Epoch 17/30\n",
      "9000/9000 [==============================] - 4s 394us/step - loss: 0.0597 - acc: 0.9910 - val_loss: 0.0651 - val_acc: 0.9910\n",
      "Epoch 18/30\n",
      "9000/9000 [==============================] - 4s 464us/step - loss: 0.0531 - acc: 0.9910 - val_loss: 0.0569 - val_acc: 0.9910\n",
      "Epoch 19/30\n",
      "9000/9000 [==============================] - 4s 428us/step - loss: 0.0372 - acc: 0.9944 - val_loss: 0.0369 - val_acc: 0.9960\n",
      "Epoch 20/30\n",
      "9000/9000 [==============================] - 4s 401us/step - loss: 0.0725 - acc: 0.9831 - val_loss: 0.3274 - val_acc: 0.9020\n",
      "Epoch 21/30\n",
      "9000/9000 [==============================] - 4s 427us/step - loss: 0.0894 - acc: 0.9759 - val_loss: 0.0516 - val_acc: 0.9910\n",
      "Epoch 22/30\n",
      "9000/9000 [==============================] - 4s 456us/step - loss: 0.0319 - acc: 0.9952 - val_loss: 0.0345 - val_acc: 0.9960\n",
      "Epoch 23/30\n",
      "9000/9000 [==============================] - 4s 429us/step - loss: 0.0263 - acc: 0.9959 - val_loss: 0.0268 - val_acc: 0.9960\n",
      "Epoch 24/30\n",
      "9000/9000 [==============================] - 4s 447us/step - loss: 0.0251 - acc: 0.9959 - val_loss: 0.0268 - val_acc: 0.9960\n",
      "Epoch 25/30\n",
      "9000/9000 [==============================] - 4s 439us/step - loss: 0.0270 - acc: 0.9953 - val_loss: 0.0215 - val_acc: 0.9960\n",
      "Epoch 26/30\n",
      "9000/9000 [==============================] - 4s 454us/step - loss: 0.1477 - acc: 0.9606 - val_loss: 0.0382 - val_acc: 0.9950\n",
      "Epoch 27/30\n",
      "9000/9000 [==============================] - 4s 431us/step - loss: 0.0283 - acc: 0.9954 - val_loss: 0.0308 - val_acc: 0.9960\n",
      "Epoch 28/30\n",
      "9000/9000 [==============================] - 4s 449us/step - loss: 0.0358 - acc: 0.9922 - val_loss: 0.0273 - val_acc: 0.9960s - loss: 0. - - ETA: 0s - loss: 0.0370 - acc:\n",
      "Epoch 29/30\n",
      "9000/9000 [==============================] - 4s 456us/step - loss: 0.0340 - acc: 0.9921 - val_loss: 0.0198 - val_acc: 0.9970\n",
      "Epoch 30/30\n",
      "9000/9000 [==============================] - 4s 429us/step - loss: 0.0201 - acc: 0.9963 - val_loss: 0.0195 - val_acc: 0.9960\n",
      "Evaluation for context=4\n",
      "1000/1000 [==============================] - 0s 171us/step\n",
      "Test loss / test accuracy = 0.0109 / 0.9990\n"
     ]
    }
   ],
   "source": [
    "#def run_evaluate(trainingData, testData, context=6):\n",
    "import os\n",
    "import sys\n",
    "train=os.path.realpath('C:/Users/nisht/Desktop/MITA/capstone_project/qa1_single-supporting-fact_train.txt')\n",
    "test=os.path.realpath('C:/Users/nisht/Desktop/MITA/capstone_project/qa1_single-supporting-fact_test.txt')\n",
    "\n",
    "\n",
    "context3=4\n",
    "X_tr,Q_tr,y_tr,X_te,Q_te,y_te,model3=create_model(train,test,context3)\n",
    "\n",
    "print('Training')\n",
    "history3=model3.fit([X_tr, Q_tr], y_tr,batch_size=32,epochs=30, verbose=1,validation_split=0.1, shuffle=False)\n",
    "\n",
    "print('Evaluation for context=4')\n",
    "loss3, acc3 = model3.evaluate([X_te,Q_te], y_te,batch_size=32)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss3, acc3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "9000/9000 [==============================] - 13s 1ms/step - loss: 2.0935 - acc: 0.1662 - val_loss: 1.7975 - val_acc: 0.1660\n",
      "Epoch 2/30\n",
      "9000/9000 [==============================] - 4s 497us/step - loss: 1.7993 - acc: 0.1677 - val_loss: 1.7942 - val_acc: 0.1780\n",
      "Epoch 3/30\n",
      "9000/9000 [==============================] - 4s 497us/step - loss: 1.7967 - acc: 0.1731 - val_loss: 1.7934 - val_acc: 0.1690\n",
      "Epoch 4/30\n",
      "9000/9000 [==============================] - 5s 506us/step - loss: 1.7956 - acc: 0.1748 - val_loss: 1.7929 - val_acc: 0.1690\n",
      "Epoch 5/30\n",
      "9000/9000 [==============================] - 5s 533us/step - loss: 1.7950 - acc: 0.1762 - val_loss: 1.7927 - val_acc: 0.1720\n",
      "Epoch 6/30\n",
      "9000/9000 [==============================] - 5s 534us/step - loss: 1.7945 - acc: 0.1772 - val_loss: 1.7925 - val_acc: 0.1720 loss - ETA: 1s -\n",
      "Epoch 7/30\n",
      "9000/9000 [==============================] - 5s 506us/step - loss: 1.7941 - acc: 0.1779 - val_loss: 1.7916 - val_acc: 0.1730\n",
      "Epoch 8/30\n",
      "9000/9000 [==============================] - 5s 511us/step - loss: 1.7859 - acc: 0.1966 - val_loss: 1.7782 - val_acc: 0.2110\n",
      "Epoch 9/30\n",
      "9000/9000 [==============================] - 5s 529us/step - loss: 1.7803 - acc: 0.2056 - val_loss: 1.7687 - val_acc: 0.2490\n",
      "Epoch 10/30\n",
      "9000/9000 [==============================] - 5s 518us/step - loss: 1.7690 - acc: 0.2217 - val_loss: 1.7593 - val_acc: 0.2350\n",
      "Epoch 11/30\n",
      "9000/9000 [==============================] - 5s 512us/step - loss: 1.7172 - acc: 0.2614 - val_loss: 1.6511 - val_acc: 0.2990\n",
      "Epoch 12/30\n",
      "9000/9000 [==============================] - 4s 454us/step - loss: 1.5455 - acc: 0.3514 - val_loss: 1.3966 - val_acc: 0.4150\n",
      "Epoch 13/30\n",
      "9000/9000 [==============================] - 5s 518us/step - loss: 1.3451 - acc: 0.4422 - val_loss: 1.2202 - val_acc: 0.4660\n",
      "Epoch 14/30\n",
      "9000/9000 [==============================] - 5s 523us/step - loss: 1.0895 - acc: 0.5129 - val_loss: 1.1841 - val_acc: 0.4210\n",
      "Epoch 15/30\n",
      "9000/9000 [==============================] - 5s 521us/step - loss: 0.7884 - acc: 0.6343 - val_loss: 0.6634 - val_acc: 0.7040\n",
      "Epoch 16/30\n",
      "9000/9000 [==============================] - 5s 528us/step - loss: 0.6125 - acc: 0.7274 - val_loss: 0.5645 - val_acc: 0.7560\n",
      "Epoch 17/30\n",
      "9000/9000 [==============================] - 5s 537us/step - loss: 0.5097 - acc: 0.7992 - val_loss: 0.4031 - val_acc: 0.8760\n",
      "Epoch 18/30\n",
      "9000/9000 [==============================] - 5s 509us/step - loss: 0.3755 - acc: 0.8760 - val_loss: 0.3282 - val_acc: 0.8910\n",
      "Epoch 19/30\n",
      "9000/9000 [==============================] - 5s 549us/step - loss: 0.3696 - acc: 0.8783 - val_loss: 0.2004 - val_acc: 0.9470\n",
      "Epoch 20/30\n",
      "9000/9000 [==============================] - 5s 519us/step - loss: 0.1550 - acc: 0.9709 - val_loss: 0.1144 - val_acc: 0.9860\n",
      "Epoch 21/30\n",
      "9000/9000 [==============================] - 5s 579us/step - loss: 0.0983 - acc: 0.9846 - val_loss: 0.1091 - val_acc: 0.9830\n",
      "Epoch 22/30\n",
      "9000/9000 [==============================] - 6s 668us/step - loss: 0.0949 - acc: 0.9812 - val_loss: 0.0963 - val_acc: 0.9750\n",
      "Epoch 23/30\n",
      "9000/9000 [==============================] - 6s 616us/step - loss: 0.1079 - acc: 0.9718 - val_loss: 0.0609 - val_acc: 0.9900\n",
      "Epoch 24/30\n",
      "9000/9000 [==============================] - 6s 635us/step - loss: 0.0622 - acc: 0.9872 - val_loss: 0.0479 - val_acc: 0.9930\n",
      "Epoch 25/30\n",
      "9000/9000 [==============================] - 6s 720us/step - loss: 0.0893 - acc: 0.9763 - val_loss: 0.1705 - val_acc: 0.9550\n",
      "Epoch 26/30\n",
      "9000/9000 [==============================] - 5s 523us/step - loss: 0.0587 - acc: 0.9872 - val_loss: 0.0358 - val_acc: 0.9950\n",
      "Epoch 27/30\n",
      "9000/9000 [==============================] - 5s 533us/step - loss: 0.0500 - acc: 0.9879 - val_loss: 0.0365 - val_acc: 0.9950\n",
      "Epoch 28/30\n",
      "9000/9000 [==============================] - 5s 507us/step - loss: 0.0319 - acc: 0.9937 - val_loss: 0.0553 - val_acc: 0.9880\n",
      "Epoch 29/30\n",
      "9000/9000 [==============================] - 5s 514us/step - loss: 0.0380 - acc: 0.9917 - val_loss: 0.0265 - val_acc: 0.9950\n",
      "Epoch 30/30\n",
      "9000/9000 [==============================] - 5s 532us/step - loss: 0.0592 - acc: 0.9826 - val_loss: 0.0859 - val_acc: 0.9700\n",
      "Evaluation for context=6\n",
      "1000/1000 [==============================] - 0s 221us/step\n",
      "Test loss / test accuracy = 0.0671 / 0.9740\n"
     ]
    }
   ],
   "source": [
    "#def run_evaluate(trainingData, testData, context=6):\n",
    "import os\n",
    "import sys\n",
    "train=os.path.realpath('C:/Users/nisht/Desktop/MITA/capstone_project/qa1_single-supporting-fact_train.txt')\n",
    "test=os.path.realpath('C:/Users/nisht/Desktop/MITA/capstone_project/qa1_single-supporting-fact_test.txt')\n",
    "\n",
    "\n",
    "context4=6\n",
    "X_tr,Q_tr,y_tr,X_te,Q_te,y_te,model4=create_model(train,test,context4)\n",
    "\n",
    "history4=model4.fit([X_tr, Q_tr], y_tr,batch_size=32,epochs=30, verbose=1,validation_split=0.1, shuffle=False)\n",
    "\n",
    "print('Evaluation for context=6')\n",
    "loss4, acc4 = model4.evaluate([X_te,Q_te], y_te,batch_size=32)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss4, acc4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "9000/9000 [==============================] - 15s 2ms/step - loss: 1.9705 - acc: 0.3746 - val_loss: 1.4163 - val_acc: 0.5380\n",
      "Epoch 2/30\n",
      "9000/9000 [==============================] - 5s 607us/step - loss: 1.3183 - acc: 0.5421 - val_loss: 1.2611 - val_acc: 0.5300\n",
      "Epoch 3/30\n",
      "9000/9000 [==============================] - 5s 575us/step - loss: 1.2033 - acc: 0.5398 - val_loss: 1.1854 - val_acc: 0.5290\n",
      "Epoch 4/30\n",
      "9000/9000 [==============================] - 5s 595us/step - loss: 1.1610 - acc: 0.5364 - val_loss: 1.1678 - val_acc: 0.5250\n",
      "Epoch 5/30\n",
      "9000/9000 [==============================] - 7s 738us/step - loss: 1.1389 - acc: 0.5357 - val_loss: 1.1512 - val_acc: 0.5180\n",
      "Epoch 6/30\n",
      "9000/9000 [==============================] - 5s 573us/step - loss: 1.1224 - acc: 0.5360 - val_loss: 1.1470 - val_acc: 0.5130\n",
      "Epoch 7/30\n",
      "9000/9000 [==============================] - 5s 590us/step - loss: 1.1103 - acc: 0.5382 - val_loss: 1.1393 - val_acc: 0.5170\n",
      "Epoch 8/30\n",
      "9000/9000 [==============================] - 7s 747us/step - loss: 1.0992 - acc: 0.5392 - val_loss: 1.1367 - val_acc: 0.5150\n",
      "Epoch 9/30\n",
      "9000/9000 [==============================] - 9s 1ms/step - loss: 1.0898 - acc: 0.5374 - val_loss: 1.1382 - val_acc: 0.5170\n",
      "Epoch 10/30\n",
      "9000/9000 [==============================] - 6s 657us/step - loss: 1.0816 - acc: 0.5420 - val_loss: 1.1386 - val_acc: 0.5110\n",
      "Epoch 11/30\n",
      "9000/9000 [==============================] - 6s 650us/step - loss: 1.0744 - acc: 0.5444 - val_loss: 1.1380 - val_acc: 0.5140\n",
      "Epoch 12/30\n",
      "9000/9000 [==============================] - 6s 660us/step - loss: 1.0676 - acc: 0.5480 - val_loss: 1.1366 - val_acc: 0.5050\n",
      "Epoch 13/30\n",
      "9000/9000 [==============================] - 6s 686us/step - loss: 1.0612 - acc: 0.5504 - val_loss: 1.1400 - val_acc: 0.5060\n",
      "Epoch 14/30\n",
      "9000/9000 [==============================] - 6s 640us/step - loss: 1.0560 - acc: 0.5534 - val_loss: 1.1438 - val_acc: 0.5050\n",
      "Epoch 15/30\n",
      "9000/9000 [==============================] - 7s 745us/step - loss: 1.0520 - acc: 0.5539 - val_loss: 1.1484 - val_acc: 0.5040\n",
      "Epoch 16/30\n",
      "9000/9000 [==============================] - 6s 667us/step - loss: 1.0474 - acc: 0.5518 - val_loss: 1.1488 - val_acc: 0.5070\n",
      "Epoch 17/30\n",
      "9000/9000 [==============================] - 7s 764us/step - loss: 1.0448 - acc: 0.5548 - val_loss: 1.1423 - val_acc: 0.5120\n",
      "Epoch 18/30\n",
      "9000/9000 [==============================] - 6s 680us/step - loss: 1.0400 - acc: 0.5561 - val_loss: 1.1424 - val_acc: 0.5030\n",
      "Epoch 19/30\n",
      "9000/9000 [==============================] - 8s 866us/step - loss: 1.0367 - acc: 0.5574 - val_loss: 1.1463 - val_acc: 0.5020\n",
      "Epoch 20/30\n",
      "9000/9000 [==============================] - 8s 895us/step - loss: 1.0327 - acc: 0.5606 - val_loss: 1.1504 - val_acc: 0.5050\n",
      "Epoch 21/30\n",
      "9000/9000 [==============================] - 8s 857us/step - loss: 1.0281 - acc: 0.5624 - val_loss: 1.1475 - val_acc: 0.5160\n",
      "Epoch 22/30\n",
      "9000/9000 [==============================] - 6s 674us/step - loss: 1.0245 - acc: 0.5636 - val_loss: 1.1514 - val_acc: 0.5130\n",
      "Epoch 23/30\n",
      "9000/9000 [==============================] - 5s 583us/step - loss: 1.0223 - acc: 0.5637 - val_loss: 1.1521 - val_acc: 0.5060\n",
      "Epoch 24/30\n",
      "9000/9000 [==============================] - 7s 727us/step - loss: 1.0176 - acc: 0.5647 - val_loss: 1.1559 - val_acc: 0.5050\n",
      "Epoch 25/30\n",
      "9000/9000 [==============================] - 6s 685us/step - loss: 1.0135 - acc: 0.5660 - val_loss: 1.1598 - val_acc: 0.5120\n",
      "Epoch 26/30\n",
      "9000/9000 [==============================] - 10s 1ms/step - loss: 1.0098 - acc: 0.5694 - val_loss: 1.1636 - val_acc: 0.5180\n",
      "Epoch 27/30\n",
      "9000/9000 [==============================] - 8s 936us/step - loss: 1.0226 - acc: 0.5694 - val_loss: 1.1641 - val_acc: 0.5140\n",
      "Epoch 28/30\n",
      "9000/9000 [==============================] - 6s 696us/step - loss: 1.0075 - acc: 0.5701 - val_loss: 1.1687 - val_acc: 0.5080\n",
      "Epoch 29/30\n",
      "9000/9000 [==============================] - 7s 783us/step - loss: 1.0117 - acc: 0.5701 - val_loss: 1.1658 - val_acc: 0.5240\n",
      "Epoch 30/30\n",
      "9000/9000 [==============================] - 6s 675us/step - loss: 1.0025 - acc: 0.5697 - val_loss: 1.1734 - val_acc: 0.5180\n",
      "Evaluation for context=All\n",
      "1000/1000 [==============================] - 0s 226us/step\n",
      "Test loss / test accuracy = 1.1717 / 0.5180\n"
     ]
    }
   ],
   "source": [
    "#def run_evaluate(trainingData, testData, context=6):\n",
    "import os\n",
    "import sys\n",
    "train=os.path.realpath('C:/Users/nisht/Desktop/MITA/capstone_project/qa1_single-supporting-fact_train.txt')\n",
    "test=os.path.realpath('C:/Users/nisht/Desktop/MITA/capstone_project/qa1_single-supporting-fact_test.txt')\n",
    "\n",
    "context5=-1\n",
    "X_tr,Q_tr,y_tr,X_te,Q_te,y_te,model5=create_model(train,test,context5)\n",
    "print('Training')\n",
    "\n",
    "history5=model5.fit([X_tr, Q_tr], y_tr,batch_size=32,epochs=30, verbose=1,validation_split=0.1, shuffle=False)\n",
    "\n",
    "print('Evaluation for context=All')\n",
    "loss5, acc5 = model5.evaluate([X_te,Q_te], y_te,batch_size=32)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss5, acc5))\n",
    "#pred=model.pred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figsize=(16,4)\n",
    "history1_dict = history1.history\n",
    "#history_dict.keys()\n",
    "history2_dict = history2.history\n",
    "history3_dict = history3.history\n",
    "history4_dict = history4.history\n",
    "history5_dict = history5.history\n",
    "acc_values1 = history1_dict['val_acc']\n",
    "acc_values2 = history2_dict['val_acc']\n",
    "acc_values3 = history3_dict['val_acc']\n",
    "acc_values4 = history4_dict['val_acc']\n",
    "acc_values5 = history5_dict['val_acc']\n",
    "epochs = range(1, len(history1_dict['acc']) + 1)\n",
    "plt.plot(epochs,  acc_values1, 'b', label='Context=0',color='red')\n",
    "plt.plot(epochs, acc_values2, 'b', label='Context=2', color='black')\n",
    "plt.plot(epochs, acc_values3, 'b', label='Context=4', color='green')\n",
    "plt.plot(epochs, acc_values4, 'b', label='Context=6', color='blue')\n",
    "plt.plot(epochs, acc_values5, 'b', label='Context=All', color='yellow')\n",
    "plt.title('Accuracy on test data for SimpleRNN Model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd4FOX2wPHvSSEJTUpCDTUJnSR0FOndC1JUBBsI9oJ6bXj1KoK9oui1U2wIIgjyEykCgoAK0juEGoFA6KEnnN8fM4ElbJJN2cwmeT/PM8/uTj1JNnt23vedM6KqGIZhGEZm/JwOwDAMw8gfTMIwDMMwPGIShmEYhuERkzAMwzAMj5iEYRiGYXjEJAzDMAzDIyZhGAWSiLQTkfg8PN79IpIgIkkiUtbLx7pVRGZ7ad/jROQlb+zbl2Xl/SIiw0Xka2/H5ItMwvBRIrJTRDo5HUdO5NaHj4hUFxEVkYDciMvN/geJyO852D4QeAfooqrFVfVQLsR0rYgsEZFjInJYRBaLSDMAVf1GVbvk9Bi5EONOETltJ8n99t+7uMvycfbfrbnLvEgRUZfXC0TkjIhUcZnXSUR2ZnBctZNzgMu8ABE54LpvI/eZhGEYOVceCAbWZ3VDsfilmVcSmAGMBsoAlYEXgbM5DzXX9VTV4kAs0Ah4Js3yw0BmXxpOAv/N4nGPAt1dXl8HHMniPowsMgkjHxKRu0Vkm/3Nc7qIVLLni4i8a3/TOiYia0Skgb3sOhHZICInROQfEXkinX37ichzIrLL3s+XInKVvSz1m/5AEdktIoki8mw6+7kHuBV4yv4G+pM9v5KI/CAiB0Vkh4gMddmmuYgsF5Hj9jfId+xFC+3Ho/a+rnZzvBD7G+0REdkANEuzfJiIxNk//wYR6WPPrwt8DFxt7/uoPf9fIrLSjmWPiAxP5+esBWx2iW+ePf8aEVlm/x2Wicg1LtssEJGXRWQxcAqomWa3tQBUdYKqpqjqaVWdrapr7O0vOyOy/yYPiMhW++cbKSIRIrLUjn+SiBSx120nIvEi8h/777dTRG5197PZ6/cQkVUictQ+44l2t56q7gdmYSUOV+OBaBFpm94xgPeBASISmcE6aX0F3OHy+g7gyzSxV7L/Pw7b/y93uyzL7P2S7vu0UFNVM/ngBOwEOrmZ3wFIBBoDQVjfQhfay7oCfwOlAAHqAhXtZfuA1vbz0kDjdI47GNiG9SFWHJgCfGUvqw4o8BkQAsRgfeutm86+xgEvubz2s+N7HihiH2M70NVevhS43X5eHGiZ5rgBGfy+XgMWYX0jrwKsA+Jdlt8EVLJjuBnrW23q72YQ8Hua/bUDGtrrRwMJQO90jn1ZfHYMR4DbgQBggP26rL18AbAbqG8vD0yzv5LAIawP2+5A6TTLL4vXPvZ0e7v69t/kV/v3exWwARjo8nMlYzWhBQFt7d9F7bR/M6z32AGgBeAPDMR6XwalfY8C4cBa4L20f39gaGq8QCSgLussAO6y4/nantcJ2JnB31qBBvbfpJQ9JdjzXPf9G/A/rLO/WOAg0DGz9wuZv0+Hp8Za2CZzhpH/3AqMUdUVqnoWqwngahGpDpwHSgB1AFHVjaq6z97uPFBPREqq6hFVXZHB/t9R1e2qmmTvv79c3n/wolrfelcDq7EShyeaAWGqOkJVz6nqdqzk098lxkgRCVXVJFX9w8P9AvQDXlbVw6q6B+tb60Wq+r2q7lXVC6o6EdgKNHe3I3v9Baq61l5/DTAB68PVE/8CtqrqV6qarKoTgE1AT5d1xqnqenv5+TTHPg5cy6XkfND+plw+g2O+rqrHVXU91offbPtveAyYidVc5Oq/qnpWVX8D/g/r95fW3cAnqvqnWmc647GSUUuXdX4UkRPAHqzk8oKb/XwCVBWR7m6WpXoV6Cki9TNYx9UZ4Ces5N8fK2GeSV0oVp/ItcDTqnpGVVcBn2Mlccj4/ZLZ+7TQMgkj/6kE7Ep9YX+oHwIqq+o84APgQyBBRD6128MBbsBq590lIr+5a9Zxt3/7eQBWO32q/S7PT2GdDXiiGlDJbt44ajf//Mdl30OwmmM22c04PTzcb2rce9LEfZGI3OHStHIU69toaHo7E5EWIjLfbpI4BtyX0fpuYtmVZt4urL6IVHvIgJ3sB6lquB1rJWBUBpskuDw/7ea169/oiKqeTBNbJTf7rAY8nubvVSXNur1VtQTWmUsd3PyO7C82I+1J3AWvqgex3rsj3P507n2J1RR1RXOUHeNhVT3hMs/1b5DR+yWz92mhZRJG/rMX6w0NgIgUA8oC/wCo6vuq2gSraaIW8KQ9f5mq9gLKAT8CkzzZP1AVqwkjwf3qGUo7YmUPsENVS7lMJVT1OjvGrao6wI7xdWCy/fN5MvJlH9aHmWvcAIhINaxviA9hNQuVwvoWnvrh5W7/32J9a62iqldh9XO4/bBzI+3vMDWef1xeezyaR1U3YTXvNPB0m0yUtn+vqapixZzWHqxv4a5/r6L2GVPaGH+zY3wrnWOOxWoe65NBXG8C7YEmHvwMYDUpVcT6IE87ym0vUEZESrjMc/0bpPt+IZP3aWFmEoZvCxSRYJcpAOuD7E4RiRWRIOAV4E9V3SkizexvxoFY7dJngBQRKSLW2P2r7OaP40BKOsecADwmIjXEGiL5CjBRVZOzEX8Cl3fo/gUcF5Gn7U5HfxFpIPZwURG5TUTCVPUC1igY7DgPAhe4snPY1STgGREpLSLhwMMuy1KTzkH7OHdy+YdvAhCe2jFsK4H1DfWMWMNCb8nCz/0zUEtEbhFruOfNQD2skU+ZEpE6IvK4/XOkNq8MALLSRJeZF+33RWugB/C9m3U+A+6z31MiIsXEGgxQws26YJ0BdRaRtB3f2O+f4cDT6QWkqkeBt4GnPPkBVFWxmvmut5+7LtsDLAFetf93orHOYL+xV8no/ZLh+7QwMwnDt/2M1ZyQOg1X1V+xhiD+gPUtKYJLbaslsf7Jj2CdYh/i0je+24GdInIcq3nltnSOOQZrBMpCYAdW0nk4nXUz8wVWv8lREflRVVOw/sFj7X0nYrUrX2Wv3w1YLyJJwHtAf7v9+RTwMrDY3lfLK45kDTvdZe93tv0zAKCqG7A+iJZiJYeGwGKXbedhDYndLyKJ9rwHgBF2+/zzpH9GdgW1rsPoATyO9Td4CuihqokZbnjJCayO5j9F5CRWolhn7y837Md6j+zF+gC9zz6LuYyqLsfqx/jAXn8bVoe7W3az0pekP0R2AtZ7NiPvkf6XGXfHXG/327gzAGtAwl5gKvCCqs6xl2X0fsnsfVpoSZrEbBhGASYi7bBG+IQ7HYuR/5gzDMMwDMMjJmEYhmEYHjFNUoZhGIZHzBmGYRiG4RGvVP90SmhoqFavXt3pMAzDMPKNv//+O1FVwzxZt0AljOrVq7N8+XKnwzAMw8g3RCRtVYJ0mSYpwzAMwyMmYRiGYRgeMQnDMAzD8EiB6sMwDMO3nT9/nvj4eM6cOZP5ykauCg4OJjw8nMDAwGzvwyQMwzDyTHx8PCVKlKB69eqIeFr818gpVeXQoUPEx8dTo0aNbO/HNEkZhpFnzpw5Q9myZU2yyGMiQtmyZXN8ZmcShmEYecokC2fkxu/dNEkBDzy1lxJBJShXqgTBwRAScvnkOi8oCPz9wc/v0mPa56mvRS5Nfn4Zvzb/Q4Zh+LpCnzCOnD7CR++VhHOe3mXU+1KTh7tHT5elJiV3SS3tvIoVITLSmiIiLj0vVSpvfl7DyGv79+/n0UcfZdmyZQQFBVG9enVGjRpFrVq1srSfUaNGcc8991C0aNFsxfHKK6/wn//8x+P1Dx8+zM0338zOnTupXr06kyZNonTp0tk6dnYUqOKDTZs21exc6T3yt5E8/+sIJvf5mWsrdebMGTh9+vIpdd7Zs3DhAqSkWI9pn6e+TkkB1cunCxfSfw1XPk/7mJVlrvG4xpg27uRk+Ocf2LYN9qa5SWfZspcnkRo1oHJlqFTJSjKlS5szIyNrNm7cSN26dR2NQVW55pprGDhwIPfddx8Aq1at4sSJE7Ru3TpL+0qtLhEa6unt3i9XvHhxkpKSPF7/qaeeokyZMgwbNozXXnuNI0eO8Prrr3u8vbvfv4j8rapNPdnea2cYIjIG665jB1T1insRi8iTwK0ucdQFwlT1sIjsxLrrWAqQ7OkPk11PtXqKb9d9yxML72H9A+spH5i9bwv53alTsH27lTy2bYO4OOtxyRL47jsrybgKCrqUPCpVuvx5xYqXpjJlTGIxfMf8+fMJDAy8mCwAYmNjUVWefPJJZs6ciYjw3HPPcfPNN7NgwQKGDx9OaGgo69ato0mTJnz99deMHj2avXv30r59e0JDQ5k/fz6zZ8/mhRde4OzZs0RERDB27FhSUlJo3rw506dPp3bt2gwYMIAOHToQFxfH6dOniY2NpX79+nzzzTcZRG2ZNm0aCxYsAGDgwIG0a9cuSwkjp7zZJDUO69aOX7pbqKpvYt30HRHpCTymqoddVmmfhVta5khQQBAf/+tj2o1vx8jfRvJqp1fz4rA+p2hRaNDAmtI6dw5274Z9+6xp795L0759sG4dzJ4Nx49fuW2RIpcnENepcWNo1Mj7P5vhgx59FFatyt19xsbCqFEZrpL6oZ/WlClTWLVqFatXryYxMZFmzZrRpk0bAFauXMn69eupVKkSrVq1YvHixQwdOpR33nmH+fPnExoaSmJiIi+99BJz586lWLFivP7667zzzjs8//zzfPDBBwwaNIhHHnmEI0eOcPfddwPwwQcfsMrld9C6dWtOnDhxRWxvvfUWnTp1IiEhgYoVKwJQsWJFDhw4kO1fVXZ4LWGo6kIRqe7h6gOw7vfrmLbV2zIodhBvLX2LW6NvpUE5N5+ahViRIpf6NjJy8uSlJOJu2rIFfvsNDttfDURgyhTo3dv7P4NhZOT3339nwIAB+Pv7U758edq2bcuyZcsoWbIkzZs3JzzcuqttbGwsO3fu5Nprr71s+z/++IMNGzbQqlUrAM6dO8fVV18NQOfOnfn+++958MEHWb16dboxLFq0yEs/Xe5wvNNbRIoC3YCHXGYrMFtEFPhEVT/NYPt7gHsAqlatmqNY3uz8Jj9t/ol7Z9zLojsX4Sdm1HFWFSsGUVHWlJGzZ63EMmCANc2fDy1b5k2Mho/I5EzAW+rXr8/kyZOvmJ9Rf25QUNDF5/7+/iQnJ7vdvnPnzkyYcOV33wsXLrBx40ZCQkI4fPjwxeSTVmZnGOXLl2ffvn1UrFiRffv2Ua5cuXRj9gZf+ETsCSxO0xzVSlUbA92BB0WkTXobq+qnqtpUVZuGhXlU0j1doUVDeavLWyzZs4QvVnyRo30ZGQsKsjrRf/oJwsOhZ0/YutXpqIzCoEOHDpw9e5bPPvvs4rxly5ZRunRpJk6cSEpKCgcPHmThwoU0b948w32VKFHi4gd8y5YtWbx4Mdu2bQPg1KlTbNmyBYB3332XunXrMmHCBAYPHsz58+cBCAwMvPgcrDOMVatWXTF16tQJgOuvv57x48cDMH78eHr16pVLvxXP+ELC6E+a5ihV3Ws/HgCmAhn/1XLRwJiBtK3WlqfmPkVCUkJeHbbQCguDmTOt5927Qx43yRqFkIgwdepU5syZQ0REBPXr12f48OHccsstREdHExMTQ4cOHXjjjTeoUKFChvu655576N69O+3btycsLIxx48YxYMAAoqOjadmyJZs2bWLLli18/vnnvP3227Ru3Zo2bdrw0ksvXdw+OjqaW2+9NcPjpBo2bBhz5swhKiqKOXPmMGzYsBz/PrLCq8Nq7T6MGe5GSdnLrwJ2AFVU9aQ9rxjgp6on7OdzgBGq+ktmx8vusNq0NiVuIvqjaPrV78fXfb/O8f6MzP35J7Rvb3W4z59vNW0ZBY8vDKstzHI6rNZrZxgiMgFYCtQWkXgRGSIi94nIfS6r9QFmpyYLW3ngdxFZDfwF/J8nySI31Qmtw7Brh/HN2m+Yu31uXh660GrRwhq6+/ffVp+GmyZiwzAcZi7cS8eZ5DM0/KghAGvvX0twQHCu7NfI2EcfwQMPwP33w4cfmus3ChpzhuEsnz3DyO+CA4L56F8fse3wNl5Z9IrT4RQa998PTz9tJY48vB7JMAwPmISRgU41O3Fb9G289vtrbErc5HQ4hcYrr8Att8Azz8DXpgvJMHyGSRiZeLvL2xQvUpz7ZtyX4ThtI/f4+cGYMVYn+ODB8OuvTkdkGAaYhJGpcsXK8Xqn1/lt12+MXz3e6XAKjaAg6wrwWrWgb19Yu9bpiAzDMAnDA0MaD6FVlVY8MfsJEk/lSXkrA6u8+syZULy4dY1GfLzTERkFxf79++nfvz8RERHUq1eP66677uJFdlkxatQoTp06le04Xnkla/2jTz75JHXq1CE6Opo+ffpw9OjRbB87O0zC8ICf+PFJj084dvYYT8550ulwCpUqVaykcfgwvPii09EYBYGq0qdPH9q1a0dcXBwbNmzglVdeISEh6xfq5nXC6Ny5M+vWrWPNmjXUqlWLV1/N20KpJmF4qH65+jx+9eOMWzWOjQc3Oh1OoRIdDf36waRJVgl2w8iJ9MqbX3vttTz55JM0aNCAhg0bMnHiRAAWLFhAu3btuPHGG6lTpw633norqsr7779/sbx5+/btAZg9ezZXX301jRs35qabbiIpKYljx45Ru3ZtNm/eDMCAAQP47LPPGDZs2MXy5p5e6d2lSxcCAqwSgC1btiQ+j0+7HS8+mJ88fvXjjPpjFB/89QEf/utDp8MpVAYNgvHj4ccfrRFURv736KOPXlbaOzfExsYyqgCXN3c1ZswYbr755iz/jnLCJIwsCCsWxoCGAxi/ejwvd3yZUsHmHqZ5pU0bqF4dxo0zCcPwjvxU3vzll18mICDA4zOT3GISRhY93Pxhxq0ax9iVY3ns6secDqfQ8PODgQNhxAjYs8fq2zDyt8zOBLwlP5c3B6tK7YwZM/j111+RPC6FYPowsqhxxcZcW/VaPlj2ASkXUpwOp1C54w7rnuVffeV0JEZ+lp/Lm//yyy+8/vrrTJ8+naJF8/5W0iZhZMPQ5kPZfmQ7P2/92elQCpWaNaFtW6tZylxDaWRXfi5v/tBDD3HixAk6d+5MbGzsZR33ecEUH8yG8ynnqfl+TeqE1mHO7XO8fjzjknHj4M47YfFiuOYap6MxssoUH3SWKT7ogED/QB5o+gBzt89lw8ENTodTqNx4o3WvjHHjnI7EMAofkzCy6e4mdxPkH8ToP0c7HUqhUry4lTQmTjTXZBhGXjMJI5tCi4Zya8Nb+XLNlxw5fcTpcAqVQYPg+HHrmgzDMPKOSRg58HCLhzl1/hRfrPzC6VAKFddrMgzDyDsmYeRAbIVY2lRrwwd/mSG2eSn1moy5c61rMgzDyBsmYeTQIy0eYdexXfy05SenQylUzDUZhpH3vJYwRGSMiBwQkXXpLG8nIsdEZJU9Pe+yrJuIbBaRbSIyzFsx5obra19P1auq8v6f7zsdSqFirskwciK/ljdP9dZbbyEiJCbm7e0WvHmGMQ7olsk6i1Q11p5GAIiIP/Ah0B2oBwwQkXpejDNHAvwCeLDZg8zfOZ+1CeYuP3lp0CDYuhWWLnU6EiM/yc/lzQH27NnDnDlzqFq1araPm11eSxiquhA4nI1NmwPbVHW7qp4DvgN65WpwueyuxncREhDC6L/MENu8ZK7JMLIjP5c3B3jsscd444038ryOFDhffPBqEVkN7AWeUNX1QGXAtSszHmiR3g5E5B7gHsCRjAtQJqQMt0XfxtdrvubVjq9StmhZR+IobFyvyRg1ChworWPkwKO/PMqq/blc3rxCLKO6Fdzy5tOnT6dy5crExMTk5NeUbU4mjBVANVVNEpHrgB+BKMBd2ky3lVpVPwU+Bas0iDcC9cTDzR/msxWf8cXKL3iq1VNOhVHomPtkGLnF18ubnzp1ipdffpnZs2fn9EfNNscShqoed3n+s4j8T0RCsc4oXItXh2Odgfi0huUb0r56ez5c9iH/vvrfBPg5ffJWOJj7ZORfmZ0JeEt+LW9evnx5duzYcfHsIj4+nsaNG/PXX39lWiQxtzg2rFZEKojdCCcize1YDgHLgCgRqSEiRYD+wHSn4syKoS2GsvvYbqZvzhfhFgjmmgwjq/JrefOGDRty4MABdu7cyc6dOwkPD2fFihV5lizAu8NqJwBLgdoiEi8iQ0TkPhFJ7Wm6EVhn92G8D/RXSzLwEDAL2AhMsvs2fF7PWj2pdlU1M8Q2j5lrMoysyM/lzZ1mypvnsreWvMWTc55k1b2riKngTMdUYdSuHezdC5s3gwODRwwPmfLmzjLlzX3MkEZDKBpY1AyxzWPmmgzD8D6TMHJZ6ZDS3B59O9+s/YbEU3l7FWZhZq7JMAzvMwmD08DTwNxc2+PDzR/mTPIZxq4cm2v7NDJm7pNhGN5nEgYCTAEeAM7kyh7rl6tPowqNTEHCPGbuk2EY3mUSBsFYpau2Am/k2l67RnRlafxSjp89nvnKRq4w98kwDO8yCQOALsDNwCvAttzZY0QXki8kM3/H/FzZn5E5Pz+4806YMwdWrnQ6GsMoeEzCuOgdIAh4kAwqkXisVdVWFAssxqy4WTnel+G5oUOhTBkY5tNF8Q2n5efy5qNHj6Z27drUr1+fp57K2zJEJmFcVAl4CZgNTMrx3or4F6F9jfYmYeSxUqXg2Wdh9mzr6m/DSCs/lzefP38+06ZNY82aNaxfv54nnngi28fODpMwLvMA0Bh4DDiW4711jejK9iPbiTscl+N9GZ578EGoVg2efhouXHA6GsPX5Ofy5h999BHDhg27WNuqXLlyufmryZSpkHcZf+BjrGrq/8WqWJJ9XSO6AjArbhYPlHkgp8EZHgoKgpEjrZIhkyZB//5OR2S48+ijsCp3q5sTG2uVus9Ifi5vvmXLFhYtWsSzzz5LcHAwb731Fs2aNcvBbyxrTMK4QjPgfqyRUwOBK99YnoosE0n1UtWthNHMJIy8dOut8PbbVvNU375QpIjTERm+ztfLmwMkJydz5MgR/vjjD5YtW0a/fv3Yvn17nt1MySQMt14GfgDuA/7AOvPIOhGha0RXvln7DedSzlHE33xq5RU/P3j9dejWDT7+2OoMN3xLZmcC3pJfy5t36tSJ8PBw+vbti4jQvHlz/Pz8SExMJCwsLN3Yc5Ppw3CrFNaoqeXAJznaU9eIriSdS2LpHlPkKK916QIdOljNU8fN5TCGLb+WNwfo3bs38+bNA2DLli2cO3eO0NDQXPrNZM4kjHQNADoC/wH2Z3svHWp0wF/8mR3n3F2yCisR6ywjMRHefNPpaAxfkZ/Lmw8ePJjt27fToEED+vfvz/jx4/P03t6mvHmGtgANsW7d8U2299J6bGtOnz/N8nucLb1eWPXvDz/9BNu2QcWKTkdTuJny5s4y5c29qhZWYcJvgV+zvZcuNbuwYt8KDp48mFuBGVnw8stw7hy8+KLTkRhG/mYSRqaeASKwrtE4m609dI3siqLM2T4nNwMzPBQRAffdB59/bt1gyTCM7DEJI1MhWENst5Dd4oRNKjahTEgZc9W3g/77XwgJgf/8x+lIDCP/8uY9vceIyAERWZfO8ltFZI09LRGRGJdlO0VkrYisEhEfaPjvCvTDGm6b9eKE/n7+dK7ZmdlxszMcumd4T7ly8NRTMGUK/PGH09EYRv7kzTOMcUC3DJbvANqqajQwEvg0zfL2qhrraWeM970LFMG6qO98JuteqUtEF/Yn7WftgbW5HZjhocceg/LlrcRh8rZhZJ3XEoaqLgQOZ7B8iaoesV/+Abi/ksVnVMJqkpoLdAYOZGnrLhFdAJi1zTRLOaV4cRg+HBYtghkznI7GMPIfX+nDGALMdHmtwGwR+VtE7sloQxG5R0SWi8jygwe9PQrpPuBL4E+skiHLPN4yvGQ49cPqm34Mhw0ZArVqWeXPU1KcjsZwSn4ub56cnExoaCjPPPPMZfPbtWtH6mUF1atXJzExMdtxpcfxhCEi7bESxtMus1upamOgO/CgiLRJb3tV/VRVm6pq07y5PP52YDFWuZDWwBiPt+wa0ZVFuxdx8txJL8VmZCYwEF55BTZsgPHjnY7GcEJ+Lm8OVkXc2rVrM2nSpDzvE3U0YYhINPA50EtVD6XOV9W99uMBYCqQ8fX5ea4xVtmQ1li57n7gXKZbdY3syrmUcyzctdC74RkZ6tsXWrSA55+H06edjsbIa/m5vDnAhAkTeOSRR6hatSp/5PEIDseKD4pIVWAKcLuqbnGZXwzwU9UT9vMuwAiHwsxAKFYr2rNYfRurgclYfR3uta7amuCAYGbFzaJ7VPc8idK4kgi88Qa0bQutWsHdd8OAAdbNl4y89CiQy/XNiQUyrmqYn8ubnz59ml9//ZVPPvmEo0ePMmHChIsVcfOC1xKGiEwA2gGhIhIPvAAEAqjqx8DzQFngf3YtlGR7RFR5YKo9LwD4VlV/8VacORMAvA40Be7E6teYDLRyu3ZIYAhtqrUx/Rg+oE0b60K+996DBx6wRlD16WPdE7xjR/DPXoFiIx/LD+XNZ8yYQfv27SlatCg33HADI0eO5N1338U/j96wXksYqjogk+V3AXe5mb8diLlyC192E1AX6IOVI9/Daqa6sihY14iuPD77cXYf203Vq6rmZZBGGkOGwODBsGIFjB0L334L330HVarAwIEwaJB1lbjhLc7UN8/P5c0nTJjA4sWLqV69OgCHDh1i/vz5F6vZepvjnd4FRwOsUVNdgQeBwcChK9a6eBc+M7zWJ4hAkybwwQewdy9MnAj161sd45GRVrPVuHGQlOR0pEZuya/lzY8fP87vv//O7t272blzJzt37uTDDz90m6C8xSSMXFUKmI7V+jYOq5+jCtADq69jEvXC/KlSshKzt5ty574mOBj69YOZM2H3bitp7NtnNVM1aWLuD15Q5Nfy5lOmTKFDhw6Xne306tWL6dOnc/Zs9urcZZUpb+41y4AFWJ3hq4FNgHUaezbZn3UHoFHFgfhJI6wWuIZYCcfwJarWPTWeeQa2brXOOozsKxzlzRW4YE8pbh4V67u62I+IeRNRAAAgAElEQVSuz10fxd4mGau6RHIGkwD1Mo0sp+XNzS1avaaZPaU6C2wAVrPz6CSOnZ1JyoXJ+Pm7XscRjtW01dCeGmD1jQTnUcxGWiJWJzjA6tUmYfg+1w9rd1NKJsvdTa77dvfc9bip+/e2AJcpCKtsUd4c1cgTQUAjoBGhRXtS98Mwnm/7KMPb3Q2sAdYBa+1pHpeu6/AHoriUQMoDxYFi9uT6PPV1UUxrY+5p0MC6R/iaNXDDDemtlQycAJLs5+rBFACUxjqzDPTmj5CJZOAkVuwn3Uznsb60ZDYFYb1vTwKn0nmMABK49IGb9tHdvOx+wHvK9Zt+2inQZZ2026R97of1/+r6mPrcdX7qmYOmeXT33J/Lk0PqlHd32XNlEoYDyhYtS7PKzZgVN5vh7V7EOrO4zmWNZGArVvJITSQrsIbsetqEWByrDyUUCMvksRjWP3vqVIScvyHT+5C8kOY1XPkP63panlvOA6fTmU5lOIWEnGTy5FNUqJCaENw95rQNuQRW8igNlHHzPO2/anrvg2TS/7BO+5g6ZX7Rae75P1SFzO8q6rpCRh/maef5Z7C+u3VT32sFX250P5iE4ZAuNbvwyu+vcOT0EUqHlE6zNACrKaouVln1VKeAo1z5TdDd6+NAInDQnjbYrz0tS1KESwkk9dtjANYpd0ZtqalTbnFNJqnf1AK4/JtX2nlwKRGkJoXsFI4SrLO1olx7bVEOHSqBlYiLAxXsR9d5JbCSbyCX2qAzms5j/T0PA0fsKfX5JpfXWU1Gflw64yya5rH0xZ/J/RmquynQjuGMB1NQmmNefvzgYOXQobKULVvWvhd1amJI+2jkJlXl0KFDBAfnrHnbJAyHdI3sykuLXuLXHb9yY70bPdwq9R8wJ05jJZBEl8dTXPpAOJvBlIz70+O0U+q3vLQfkO7mQean5q5TMpcnrRQ3j4p14yt3U1E3r9Obgi/G+Pnn1s2Xjh6Fq67K6u88p87gPuG5+3D1J3fOEL0jPPw88fHxHDyYbiFrw0uCg4PTvf7DUyZhOKRF5RaUDCrJrG2zspAwckMIUNWeDE/F2JeSrlkDrVvn9dELzqCHwMBAatSo4XQYRjYVjsY7HxToH0jHGh2ZFTfL3IUvH0hNGBlUdTCMAs8kDAd1jejKnuN72Hxos9OhGJmoVAnKljUJwyjcTMLA6hA6dy4vR4pYzF348g8R6yzDJAyjMCv0CSMlJYWyZcsycuTIPD92jdI1iCoTZarX5hMxMbBunblTn1F4FfqE4e/vT+nSpS8WDMtrXSO6smDnAk6fN3fy8XUxMdYNl7ZudToSw3BGoU8YAFFRUWx16FOgR60enE4+zdztcx05vuG56Gjr0TRLGYWVSRhAZGQk27Ztc2S0Uvsa7SkZVJKpm6bm+bGNrKlXDwICTMIwCi+TMLDOMI4dO0ZiYmKeH7uIfxH+FfUvpm+eTvKF3LxC2shtQUFQp45JGEbhZRIG1hkG4Fg/Rp86fTh0+hCLdy925PiG58xIKaMwMwmDSwnDqX6MbpHdCPIP4sdNPzpyfMNzMTHwzz9w6MqbKRpGgefVhCEiY0TkgIisS2e5iMj7IrJNRNaISGOXZQNFZKs9DfRmnDVq1MDPz8+xM4wSQSXoVLMTUzdNNVd9+zhzxbdRmHn7DGMc0C2D5d2xbvYQBdwDfAQgImWw7nPaAmgOvCAiaUu65poiRYpQrVo1x84wwGqW2nVsF6v2r3IsBiNzrjWlDKOw8WrCUNWFWPWZ09ML+FItfwClRKQi0BWYo6qHVfUIMIeME0+ORUVFOXaGAdCzdk/8xM80S/m48uWtyZxhGIWR030YlYE9Lq/j7Xnpzb+CiNwjIstFZPnBgwezHUhkZCRbt251rEmoXLFytKrSygyvzQdMx7dRWDmdMNwV7dcM5l85U/VTVW2qqk3DwsKyHUjq0NpDDvZm9qnTh7UH1hJ3OM6xGIzMxcTA+vVw/rzTkRhG3nI6YcQDVVxehwN7M5jvNU4PrQXoXac3gGmW8nExMXDuHGw2RYaNQsajhCEiESISZD9vJyJDRaRULhx/OnCHPVqqJXBMVfcBs4AuIlLa7uzuYs/zmqioKMC5obVgFSOMKR9jmqV8nBkpZRRWnp5h/ACkiEgk8AVQA/g2s41EZAKwFKgtIvEiMkRE7hOR++xVfga2A9uAz4AHAFT1MDASWGZPI+x5XuP00NpUvev0ZsmeJSQkJTgah5G+2rWhSBGTMIzCx9NbtF5Q1WQR6QOMUtXRIrIys41UdUAmyxV4MJ1lY4AxHsaXY74wtBasfowXf3uR6Zunc3eTux2NxXAvMNCqK2UShlHYeHqGcV5EBgADgRn2vEDvhOSc1CKEToouH02NUjX4cbPpx/BlZqSUURh5mjDuBK4GXlbVHSJSA/jae2E5I7XMuZNXW4sIvev0Zu72uRw/e9yxOIyMxcRAQoI1GUZh4VHCUNUNqjpUVSfYndAlVPU1L8eW5yIjIzl69CiHD3u1uyRTfer04VzKOWZuneloHEb6TMe3URh5OkpqgYiUtEt2rAbGisg73g0t7zldhDDVNVWuIaxomGmW8mEmYRiFkadNUlep6nGgLzBWVZsAnbwXljNSh9Y63Y/h7+fP9bWv5/+2/B9nk886GovhXtmyULmySRhG4eJpwgiwazz141Knd4GTOrTW6TMMsJqlTpw7wbwd85wOxUiH6fg2ChtPE8YIrAvn4lR1mYjUBJz/VM1lQUFBVK1a1fEzDICONTtSvEhxc9W3D4uJgU2b4Kw5CTQKCU87vb9X1WhVvd9+vV1Vb/BuaM5ILULotOCAYLpHdmfa5mmkXEhxOhzDjZgYSE6GjRudjsQw8oannd7hIjLVvhlSgoj8ICLh3g7OCU6XOXfVp04fEk4m8Oc/fzodiuGG6fg2ChtPm6TGYtV9qoRVZvwne16BExkZyZEjRxwfWgtwXdR1BPoFMnWjqS3li6KiIDjYJAyj8PA0YYSp6lhVTbancUD2a4n7MF8oQpjqquCr6FCjg7l1q4/y94cGDUzCMAoPTxNGoojcJiL+9nQb4NyNI7zIF8qcu+pdpzdxR+JYf3C906EYbqSOlDL53CgMPE0Yg7GG1O4H9gE3YpULKXBq1qyJiPjEGQZAr9q9EMQ0S/momBg4dAj2evVuLYbhGzwdJbVbVa9X1TBVLaeqvbEu4itwfGloLUDFEhVpGd7SXPXto0zHt1GY5OSOe//OtSh8TGoRQl/Ru05vVuxbwa6ju5wOxUgjOtp6NAnDKAxykjDc3Xe7QPCFMueu+tTpA5hbt/qiUqWgWjWTMIzCIScJo8B280VGRnL48GGfGFoLEFU2ivph9U2zlI8yJUKMwiLDhCEiJ0TkuJvpBNY1GQWSrxQhdNW7Tm8W7lpI4qlEp0Mx0oiJgS1b4PRppyMxDO/KMGGoaglVLelmKqGqmd7eVUS6ichmEdkmIsPcLH9XRFbZ0xYROeqyLMVl2fTs/XjZ4ytlzl31qdOHC3qBnzb/5HQoRhoxMXDhAqxb53QkhuFdOWmSypCI+AMfAt2BesAAEannuo6qPqaqsaoaC4wGprgsPp26TFWv91ac7qQOrfWlM4zGFRtTo1QNvl5b4G50mO+ZkVJGYeG1hAE0B7bZhQrPAd8BvTJYfwAwwYvxeCw4OJgqVar41BmGiHBn7J3M2zGP7Ue2Ox2O4aJmTShe3CQMo+DzZsKoDOxxeR1vz7uCiFQDagCuN38IFpHlIvKHiPRO7yAico+93vKDBw/mRtyAbxUhTDUodhCCMHZlgSzjlW/5+UHDhiZhGAWfNxOGu2G36Y2s6g9MVlXXOt5VVbUpcAswSkQi3G2oqp+qalNVbRoWlnvlrXylzLmrKldVoWtkV8atHmdKnvuY6GhYs8aUCDEKNm8mjHigisvrcCC9Agr9SdMcpap77cftwAKgUe6HmL6oqCifGlqbakijIcQfj2d23GynQzFcxMTAsWOwe7fTkRiG93gzYSwDokSkhogUwUoKV4x2EpHaQGlgqcu80iISZD8PBVoBG7wY6xVSR0rFxcXl5WEzdX3t6wktGsoXK79wOhTDhen4NgoDryUMVU0GHsK6tetGYJKqrheRESLiOuppAPCdXl6/uy6wXERWA/OB11Q1TxOGL5U5d1XEvwi3R9/O9M3TOXgy9/psjJxp2NB6NAnDKMi8eYaBqv6sqrVUNUJVX7bnPa+q013WGa6qw9Jst0RVG6pqjP2Y51+nfXFobaohjYZw/sJ5vlrzldOhGLYSJSAiwiQMo2DzasLIz3xxaG2q+uXq0zK8JV+s/MLcWMmHmBIhRkFnEkYGfK0IoashjYaw4eAGc79vHxITA3FxkJTkdCSG4R0mYWTAF4fWprq5/s0UCyzG5ys+dzoUwxYTYw2rXbvW6UgMwztMwshAVFQUhw4d4siRI06HcoUSQSXoV78fE9dPJOmc+UrrC1JHSv32m7NxGIa3mISRAV+7v3daQxoNIelcEpPWT3I6FAPrvhjt28Nzz8G0aU5HYxi5zySMDPhimXNX11S5htpla5trMnyECPz4IzRtCv36wS+/OB2RYeQukzAyULNmTcD3rsVIJSIMaTSEJXuWsPHgRqfDMYCSJWHmTKhXD/r0gXnzMt/GMPILkzAyEBISQpUqVXz2DAPgjpg7CPALYMzKMU6HYthKl4Y5c6zrMnr2hMWLnY7IMHKHSRiZ8OWRUgDli5enR60efLnmS86nnHc6HMMWGgpz50J4OHTvDsuWOR2RYeScSRiZ8MUy52kNaTSEAycPMGPLDKdDMVxUqAC//molj65dzUV9Rv5nEkYmIiMjSUxM5OjRo5mv7JBukd2oWLyi6fz2QeHhVj9GsWLQqRNsyNOKaIaRu0zCyISvj5QCCPALYFDsIGZum8k/x/9xOhwjjerVraQREAAdO4IPt3AaRoZMwsiEr1+LkWpwo8Fc0AuMXz3e6VAMN6KirOap5GQraezc6XREhpF1JmFkIiLCutGfL3d8A0SWiaRttbaMWTmGC3rB6XAMN+rVs0ZPnTgBHTpAfLzTERlG1piEkYmQkBDCw8N9/gwDrM7vuCNxLNy10OlQjHTExsLs2ZCYCF26wJkzTkdkGJ4zCcMDvj60NtUN9W6gZFBJ0/nt45o1g++/h40b4a23nI7GMDxnEoYH8sPQWoCigUW5pcEtTN4wmaNnfHdUl2ENs73hBnjlFXMfcCP/MAnDA5GRkRw8eJBjx445HUqmhjQewpnkM0xYO8HpUIxMvP229fjEE87GYRieMgnDA/lhaG2qJhWbEF0+ms9Xfm7uxufjqlWDZ56xmqd+/dXpaAwjc15NGCLSTUQ2i8g2ERnmZvkgETkoIqvs6S6XZQNFZKs9DfRmnJlJHVqbH/oxRISHmj3Ein0reGuJaSD3dU8+CTVrwtChcN5UdjF8nNcShoj4Ax8C3YF6wAARqedm1YmqGmtPn9vblgFeAFoAzYEXRKS0t2LNTOrQ2vxwhgFwV+O7uKneTQz7dRizts1yOhwjA8HB8O671hXgH3zgdDSGkTFvnmE0B7ap6nZVPQd8B/TycNuuwBxVPayqR4A5QDcvxZmpokWLUrly5XxxhgHWWcbYXmOpH1af/j/0Z9vh/JHoCquePaFbNxg+HBISnI7GMNLnzYRRGdjj8jrenpfWDSKyRkQmi0iVLG6LiNwjIstFZPnBgwdzI2638stIqVTFihTjx/4/4id+9P6uNyfOnnA6JCMdIvDee3D6NAy7ouHWMHyHNxOGuJmXthf2J6C6qkYDc4HUuhaebGvNVP1UVZuqatOwsLBsB5uZ/HIthquapWsy8caJbEzcyMAfB5orwH1YrVrw73/DuHGwdKnT0RiGe95MGPFAFZfX4cBe1xVU9ZCqnrVffgY08XTbvBYVFZVvhta66lSzE291foupm6byyqJXnA7HyMBzz0GlSvDww5CS4nQ0hnElbyaMZUCUiNQQkSJAf2C66woiUtHl5fVA6n1GZwFdRKS03dndxZ7nmNSRUnFxcU6GkS2PtnyU26Jv4/n5z/PT5p+cDsdIR/Hi1pXff/8NY8wNFA0f5LWEoarJwENYH/QbgUmqul5ERojI9fZqQ0VkvYisBoYCg+xtDwMjsZLOMmCEPc8xqddi5LdmKbA6wT/t8SmNKjbitqm3sSlxk9MhGeno3x/atLGuzzjs6DveMK7k1eswVPVnVa2lqhGq+rI973lVnW4/f0ZV66tqjKq2V9VNLtuOUdVIexrrzTg9UbNmTSD/DK1NKyQwhKk3TyXIP4je3/Xm2Jn81bRWWIjA6NFw5Ag8/7zT0RjG5cyV3h4qVqwYlSpVypdnGKmqXlWVyf0mE3ckjtum3mY6wX1UdDQ88AB89JG5ravhW0zCyIL8NrTWnTbV2jCq6yhmbJnB8AXDnQ7HSMeIEVCmjNUBbiq8GL7CJIwsyI9Da915oNkDDGk0hJELRzJl4xSnwzHcKF0aXn0VFi2CCaaOpOEjTMLIgjp16nDgwAH27dvndCg5IiJ8eN2HtAxvyR1T72DdgXVOh2S4MXgwNG1qVbM9Ya67NHyASRhZ0L17dwCmTZvmcCQ5FxQQxA/9fqBkUEl6TujJgZMHnA7JSMPPz6ovtW8f9O4NXixkYBgeMQkjC+rVq0etWrWYMqVgNONUKlGJ6QOmk5CUQO/venMm2dwv1Ne0aGFd/b14MTRpAn/95XRERmFmEkYWiAh9+/Zl/vz5HC4gg+SbVmrK132/Zmn8UgZPG2zuoeGDBg60EoafH7RuDZ995nRERmFlEkYW9e3bl+TkZGbMmOF0KLmmb92+vNrxVSasm8CI30Y4HY7hRpMm1hXg7drBPffAXXfBGXNCaOQxkzCyqGnTpoSHhxeYZqlUT7d6mkGxgxj+23Bze1cfVbYs/PwzPPssfPGFdbaxa5fTURmFiUkYWSQi9OnTh1mzZpGUlOR0OLlGRPikxye0qdaGO6fdyZI9S5wOyXDD3x9eegl+/BG2bLHOPObOdToqo7AwCSMb+vbty5kzZ/jll1+cDiVXFfEvwpR+U6hyVRV6f9ebHUd2OB2SkY5evWDZMqhQAbp2hddeMxf4Gd5nEkY2XHvttYSGhjJ16lSnQ8l1ZYuWZcaAGZy/cJ4eE3qYmlM+rFYt+PNP6NfPKlbYty8cP+50VEZBZhJGNgQEBNCrVy9mzJjB2bNnM98gn6kdWpsp/aaw5dAW+k3uR/KFZKdDMtJRrBh8+611X/CffoJrrsndi/ymbJzCHVPvMKPnDMAkjGzr27cvx48fZ968eU6H4hXta7Tn4399zOy42Twy8xHzgeHDRODRR60O8U2b4N57c6956s0lb/LVmq9YsW9F7uzQyNdMwsimjh07UqJEiQI3WsrVkMZDePKaJ/nf8v8x+q/RTodjZKJLF6to4YQJuXOtxp5je/gj/g8AJqwzI+cMkzCyLSgoiB49evDjjz+SUoDvp/lap9foXac3j816jBlbCs61JwXVsGFW4njkEVizJmf7Si1MGV0+monrJ5py+IZJGDnRp08fEhMT+f33350OxWv8xI+v+3xNTPkYek7oSbVR1egzsQ8jfxvJz1t/Zn/SfqdDNFz4+cFXX1nVbvv1g5yM/J68cTIx5WN4utXTxB+PZ/HuxbkXqJEvBTgdQH7WvXt3goKCmDJlCm3btnU6HK8pVqQYc26fw7hV4/h739+s2LeCaZumoVgN5RWLV6RJpSY0rtDYeqzYmPCS4Q5HXXiVK2d1hHfsCPffD19+afVzZMXeE3tZvHsxI9qP4Pra1xMSEMKEdRNoXa21d4I28gXxZmemiHQD3gP8gc9V9bU0y/8N3AUkAweBwaq6y16WAqy1V92tqteTiaZNm+ry5ctz8SfIXK9evVi5ciW7du1CsvpfmY+dOHuCVftXXUwgf+/7m02Jmy42WzSr1IxHWjzCTfVvooh/EYejLZxGjrRu8/r55zBkSNa2/eCvD3h45sNsfHAjdULrcPPkm5m3Yx77Ht9HgJ/5nlmQiMjfqtrUo5VV1SsTVpKIA2oCRYDVQL0067QHitrP7wcmuixLyuoxmzRponlt3LhxCuiyZcvy/Ni+Julski7evVjfXPym1hpdSxmOVnyroo5YMEITkhKcDq/QSU5W7dhRNSREde3arG3bdmxbrf9h/Yuvp26cqgxHf9n6Sy5HaTgNWK4efsZ6sw+jObBNVber6jngO6BXmmQ1X1VP2S//APJdO0bPnj3x9/cv0KOlPFWsSDGuqXINT1zzBBsf3MjPt/xMdPlonl/wPFXfrcrgaYNZvd/cpDqv+PvDN99AyZJWf8bJk55tl5CUwMJdC7mx3o0X53WL7EbJoJJ8t/47L0Vr5AfeTBiVgT0ur+PteekZAsx0eR0sIstF5A8R6Z3eRiJyj73e8oMO3GGmTJkytG/fnh9++MFcq+DCT/zoHtWdX277hQ0PbODO2DuZuH4isZ/E0m5cO6ZunErKhYI7usxXlC9v9Wds2gQPPujZNlM3TUXRyxJGcEAwfev2ZcrGKea+KYWYNxOGuwZ9t5+oInIb0BR402V2VbXa1W4BRolIhLttVfVTVW2qqk3DwsJyGnO29O3bly1btrBx40ZHju/r6obV5aMeHxH/WDxvdHqDHUd30HdSXyJHRzL6z9EmcXhZhw5WX8b48dbNmDIzecNkapetTf2w+pfNH9BgAMfPHmfm1pnpbGkUdN5MGPFAFZfX4cDetCuJSCfgWeB6Vb1YZ0NV99qP24EFQCMvxpojvXpZLW2mWSpjpUNK82SrJ4kbGsfkmyYTXjKcob8MpevXXc3wXC/773+hfXvrLGPDhvTXO3jyIAt2LuDGejdeMYijQ40OhBUNM81ShZg3E8YyIEpEaohIEaA/MN11BRFpBHyClSwOuMwvLSJB9vNQoBWQwdvcWZUqVeLqq682CcNDAX4B3FDvBhYOWsgX13/Bkj1LiPk4hjlxc5wOrcBK7c8oXtzqzzh1yv160zZPI0VTLmuOShXgF8BN9W7ip80/kXSu4JT2NzzntYShqsnAQ8AsYCMwSVXXi8gIEUkdIvsmUBz4XkRWiUhqQqkLLBeR1cB84DVV9dmEAVaz1MqVK9m5c6fToeQbIsLgRoNZdvcyQouG0vXrrjz767Om2KGXVKwIX39tnWE8/LD7dSZvmExE6Qhiyse4Xd6/QX9OJ59m+ubpbpcbBZynw6nyw+TEsNpU27ZtU0Dfeecdx2LIz06eO6l3TbtLGY62+qKV7j662+mQCqznnlMF1VGjLp9/6NQhDRgRoE/PeTrdbVMupGj4O+Ha49seXo7SyCv4yLDaQiUiIoKYmBjTLJVNRQOL8tn1n/Ft329ZnbCa2E9izbdYL3nhBejd26pw+9xzlyrbTt88neQLyW6bo1L5iR/96/dn1rZZHD59OI8iNnyFSRi5qG/fvixevJj9+00HbnYNaDiAFfesoNpV1ej1XS8e/eVRziYXvHuOOCkgAL7/Hu66C15+2XpMTobvN3xP9VLVaVKxSYbb92/Qn/MXzl8sTmgUHiZh5KK+ffuiqkybNs3pUPK1qLJRLB2ylIebP8x7f75HqzGtiDsc53RYBUpAAHz6qTXcdswY6NHrPLM3/s6Nda8cHZVW44qNiSoTlS9LnicnwzvvwA5z9+FsMQkjF9WvX5+oqCjTLJULggKCeL/7+0y9eSpxR+Jo9Ekj/j3r30zbNM00heQSEXjxRfjoI5g9M4DkcTPpXLG/B9sJ/Rv0Z/6O+ew7sS8PIs09zz4Ljz8OffpAAbxZpteZhJGLRIQ+ffowb948jhw54nQ4BULvOr1Zde8q2lRrw/+W/Y/eE3sT+kYoMR/HMHTmUCZvmMyBkwcy35GRrvvugyaPvgb7G/NIv8bs3p35NgMaDEBRvt/wvfcDzCVTp8Ibb0CbNrB6tZU8jKzxarXavOZEtdq0/vzzT1q2bMlXX33Fbbfd5mgsBc2Z5DMs+2cZv+36jd92/caSPUs4dd66oKBuaF3aVmtL2+ptaVG5BZVKVCIoIMjhiPOH42ePU+7NcvQMepM5Lz9MsWLwyy/QsGHG28V+HEtIYAhLhyzNm0BzYMsWaNoU6taFhQvhscesM6u5c60y8IVZVqrVmoSRyy5cuEDVqlVp3ry5aZrysnMp5/h7798s3LWQ33b9xu+7f+fEuRMXl5cKLkWF4hWoULwC5YuVv/jc9XXdsLoEBwQ7+FM4b8LaCdwy5RZ+v/N3Sh5rRbduVqHC6dOtb+Ppee3313jm12fYPnQ7NUrXyLuAs+jkSWjRAvbvhxUroGpV68LFJk3gxAnrbKNsWaejdI5JGA57+OGH+eKLLzh48CDFihVzOpxCI/lCMqv2r2LV/lUkJCWwP2k/+0/uZ3/S/ouvXRMKQEhACK2rtaZTjU50juhMdPlo/KRwtdTeMOkGlu5ZSvy/4/ETP3btgm7drI7hCROs9n53dh7dSY33avBqx1cZdu2wvA3aQ6pw663w3XcwaxZ07nxp2YoV0LIlXH+9NWqsEN3O5jImYThs/vz5dOjQgQkTJtC/f+adiEbeOXnuJAknE0hISiD+eDy/7/6duTvmsuGgVUggtGgoHWt0pHPNznSq2Ylqpao5HLF3JZ1LIuzNMO5qdBejrxt9cf6hQ9CjB/z1l9XWX7++VSbddbrqKuj2fSvOpJxk1X2rHPwp0jd6NAwdag0f/s9/rlz++uvWfdDHjIE778z7+HyBSRgOS05OplatWuzbt4833niDhx56qFDdjS8/2ntiL3O3z7047UuyRv9Elomkc83OtK3WlgblGhBVNqpA3UHw+/Xf029yPxYMXEDb6pffZvjUKRgwwGqaylBgEmFlgihbOpDwcIiIgJo1L00REVZyyWtLlkDbttC9O/z4o3W/87RSUqBTJ1i+HFauhMjIvI/TaSZh+ICEhAQGDx7MzzYPEUYAABRBSURBVD//TLdu3Rg7diwVKlRwOizDA6rKxsSNzImbw9wdc1mwc8HFYnv+4k9U2SjqhdWjXmg96oXVo25YXWqXrU1IYIjDkWfdzZNvZsHOBez99178/fyvWK4K+/bBsWNw/PilKfX13sQTvDn/UxqVaktE0abs2QNxcZCYePl+ypS5PIlER1tNQd5qsU1IgMaNISTESgalSqW/7p49Vjy1a8OiRRAY6J2YfJVJGD5CVfnoo494/PHHKV68OGPGjKFnz55Oh2Vk0fmU86w7sI6NiRvZcHDDxWnb4W2kqHUvD0GoWbom9cLq0aRiE66ucjXNKzenVHAGn1QOO3X+FOXeLMft0bfzUY+Psr2fjl92ZM+xPWx+aPPFM+njx60+kO3brSku7tLznTvh/HkrWdx4IwwaZHWuuzsDyI7kZKuv4s8/YelSiHFfR/EyEydC//7WhYwvvpg7ceSVgwets6MuXbK3vU/c09uJycnigxlZv369xsbGKqD33nuvJiUlOR2SkQvOnD+jaxPW6sR1E/WF+S/oTZNu0rof1FUZLspwVIaL1vuwng7+cbB+9vdnui5hnaZcSHE67IumbJiiDEfnxs3N0X4++/szZTi6/J/lHq2fnKy6cKHqkCGqJUpYhRCrVVP9739Vt27NUSiqqvrkk9Y+x4/P2na3367q56e6eHHOY8gLKSmqn3+uWqaMNWX3Y4UsFB80Zxh55OzZszz33HO8/fbb1KpVi2+++YYmTTKu2WPkT8fPHuevf/7ij/g/WBq/lD/i/7h4dXrJoJK0qNyCluEtaViuIcWKFCMkIITggGCCA4IJCbz0PDggmJCAEIr4F/FKH9gtP9zCnO1z2Pf4PgL8ArK9n8OnD1PhrQo80uIR3uzyZuYbuDh1yupfGD8e5syxmsBatYKBA637dmS172PKFLjhBrj/fvjf/7K27fHjEBtrPV+1yurY91UbNlgXXC5aBK1bw8cfQ7162duXaZLKqu+/t96llSrlflBpzJs3jzvuuIOEhAReeuklnnjiCfz9r2w7NgoOVWXr4a0s3bP0YhJZe2AtF/SCR9sLQpmQMoQVC6NcsXLWVLTcpef2FFYsjMolKlMiqESm+zyTfIawN8MY0GAAn/b8NKc/Ij0n9GTV/lXsenRXtocl//OPdb+O8eNh40YIDraq6l5zzaWO9Bo1ICid6zE3b4ZmzS5dnJfeehlZvNhqHrvtNisOX3P6NLz0Erz5JpQoYT0OGpSz5jyTMLLi2DErUSQnW7/5p5+23pledPjwYe69914mT55M27Zt+eqrr6hSpUrmG3pox44dJCQk0Lx5c/xyq2HYyFVJ55LYfmQ7Z5LPcPr8ac4kn7GeJ7s8t+efOn+Kw6cPc+DUAQ6cvDS5q6klCLVDa9O8cnOaV2pO88rNiS4ffcVV79M3T6fXd72YddssukRks/Hbxbdrv+XWKbfyasdX/7+9cw+OssoS+O+k84AQg5CHDzQIhIdAWAEn5QZiDRp1ZlzIWjur4G4NWlYpOD52t3Z31D9cd8atnbV0dtbaEdQdZtRxh9WdGQmlNSDgOnEZeQhCA85CjKIBJQ+EJOTV6T77x/2607Sd0CEJTbfnV3Xr3u/e0/e7p2/3d7775obJNzCzaOZZTwJQdQPVP/+5G1toaelLE+G0mVhTpjg3cSLcdRc0Nrr1FUP5Oz36KPzgB+7et9569vkAdHWB3+/KFHZdXW6dy+LFzhhmJti427AB7r3XjQN95zvw5JNQVDS08oEZjMF/sL7ebTLzs585w7FsmZucPXv28BfSQ1V54YUXuP/+++nu7qa8vJzKykoqKytZsGABYwfRFm9ubmbLli1s3ryZTZs2UV9fD0BpaSkrVqzgjjvuoOCrvJQ1TQkEA7R0tpxmROqO17Hj6A62H9ke2WMr25fNVRdfRfml5Xxtwtcon1DO4797nDcOvcGxvz1Glm/o04Lae9qZ9+w8Dh0/BLhzM6YVTKOsuIw5F82JuIljJw6qe03VzXgKD5yHXfj62LE+2YwM2Lhx6Ft9BAKwcCEcPKi8v0eZWJLYS9epU7B3L7z3Xp9x2L/fPVIAxo1zM7dE4O233X3Gj3fTfhcvdkYk3t/+88/dViZr18K0aa77adGioekYjRmMs+XoUbf38erVrvarq91qn/Ly4StkDPX19axevZra2lp27txJb28vIsKcOXOorKzk2muvpbKy8rQpuR0dHdTW1rJp0yY2b97M7t27AcjPz2fRokVUVVWRn5/P888/zzvvvENOTg5Lly5l5cqVlJeXJ31NSFtbGxs3bqSmpobDhw9z4403Ul1dzcyZM5NetnRBVfm09VO2H9kecTuP7uRU4FRE5s6r7mRN9Zphu2cwFOTDLz5k77G9Eedv9FP/RX1E5oLsCyi7qIzpBdNdN1puEUVjiijMLYyEi3KLyM3KTei30N7eZzwuvdRtAXI2tHa3sr9xP/5GP/5jfrb7j7P90Wdh1HF8Fx4jU7LJlCwyycYnWfjIIoNMMsT52pvJ5w2jCIVcmQsKQ8ydF+Lq+RlcPT+DefPgiiv6VpO3tjrjtn49vP66a0VlZrrusMWLnZs0CZ59Fh5+2HVFPfKIe489m662gTCDMVRaWtwS0aefhi++cK8sjzzizPoIPtA6OjrYtm0btbW11NbWsnXrVjo63OZ6paWlVFRU8Mknn7B161Z6enrIzs6moqKCqqoqqqqqmD9/Ppkx7Vu/38+qVat46aWXaG9vZ+7cuaxcuZLbb7/9jNuWqCpNTU3U1dVRV1dHa2srV155JWVlZRQXFw9Kt4aGBtavX09NTQ1btmyhp6eHcePGUVJSwp49ewB3amF1dTXV1dVUVFR8SRdjaARDQf7Q/Ae2H9mOv9HPPfPvYXrh9BG/b1t3G/sa90UMyN5je6k7XkdzRzOBUCDuZ0ZljqIo1xmSRBdKZvmyyM/Jdy47n7Gjxkaux+b0hXOzcvnoxEfsa9wXMRCHTx6O5JOXncfs4tnkH76duje+SUAD9Ia6CWg3PaFuekJdBEJdBAmAhDwXhIKDcMku5/KPgPeoyMrIIjcrl9FZo8nNyiUvOy9iIAtzCxmfU0R7/Sw+fHcWe2ov5/ChPAAKC5XmZuG665RnnoHp00fm2XPeGAwR+Qbwb4AP+A9V/WFMeg7wIjAfaAFuU9WPvbSHgbuAIPCAqm440/2GfZZUW5trbTz1lGv7XnMN3Hef6zAtKHBu/PjEOyEHSSAQYPfu3RED8u677zJhwgSuv/56qqqqWLhwIbm5uQmq0sbLL7/MM888g9/vJz8/n+XLl7NixQrGjRvHoUOHIoYh2rW1tcXNr7i4mLKyMsrKypg9ezZlZWXMmjUrYoRUld27d0eMxK5du4A+o7BkyRIWLFhAZmYmR44cYf369axbty5iTAoKCrj55puprq7mpptusj250hBVpbW7laaOJpo7mmk61RQ33BvqTSi/nmAPrd2tEXey+yRdvV39ymdmZDKjcAZlxWXMLp5NWXEZZReVJdxt1hHooKWjhZbOFpo7mjnVc4rO3k46Ah10Bjw/6jocbu1upaWzhaZTTr8vumKOQjg+GQ7+CXyyEKbXwJxfRIwPuHGqcPnC4YvzLubTv/40oe8plvPCYIiIDzgI3AA0ADuAZap6IErmXmCOqq4QkaXALap6m4jMBH4JlAOXApuAaareKql+GLFptV1dbnzjiSfcqqNYxo7tMyCFhX3hMWNc+3Egl53tfJ/PGZ54fmw4I+PMTqTPD7uMDBTYunUrq1at4tVXX6Wnp+c0VXw+H5MmTaK0tDTipk6dSmlpKXl5eRw4cAC/3x9x+/fvp7OzE3DngUyePJkZM2awZ88eGhoaEBEqKipYvHgxS5YsYcaMGQP+GVtbW9mwYQPr1q3j9ddf58SJE+Tk5FBVVcWUKVMYPXp0xI0aNeq067DLycnB5/Ph8/nIyMgY0BcRMjIyIn50ONqPDce62LTw9xF9bZx7eoI9tHW3cbL7ZMSQtHW3UTK2hOmF08+LbV56Q70c7zxOc0dzxFg2dzTT0tlCIOhaYIq3FsLzY+PysvN4pDLOZlkJcL4YjD8GHlPVm7zrhwFU9Z+jZDZ4Mr8XkUzgc6AIeChaNlpuoHuO+DqMQMBNeWhudt1WLS2nh2NdR4fbrOZ8RIQmEdbiTtEqFaE0I4MSEbLCM6uijU34oRftixBU5SNV/MEg/lAIfzDIB6EQ03w+lmRl8a2cHIrDhivq3nH9mHBAlXcCAdZ1dfFGVxeNoRCdqpxu4lILiXLEC0feHPuXIUqOeGkxfn/hgfJINNxfPqelx4kbjGzcuH6McKKmeTAmfETyTPAlItE8C0eN4n9PnhxECU4rS8IGYyQ7iScA0W2kBiB2SCoio6q9InISKPDi34357IR4NxGRu4G7AUpKSoal4P2SleWmOQyGYNCdBTmQ6+lxcsGgm1IRzw+HQ6HEnWqfH3ZR10Wq3B/y1gJEy8ReR8dFpwE+VUqBUlVuiUn7kh8vLl5a+OtWZRGwCPhxVFowFKKrt5fOYJDO3l7nvHBXMEhXby8hIKRKUNX5oRAh77MhIOjFuTc0Jxv2o8OqSoi+HREiYXAuKhyWJ04a0dcxMpFwjNyXZKJkiUqPlxb9IjiQ/JnyHSivgeT6kx+sbNy4fl5yE331HcxLcsJ5Jpxj4vcfTJ5jz1GX7UgajHjGMfY76E8mkc+6SNXngOfAtTAGU8Bzgs8HubnOGcOCDxjjOcMwzh0juaqrAYhePnMZcLQ/Ga9LaixwPMHPGoZhGOeQkTQYO4CpIjJJRLKBpUDszvo1wHIv/G1gi7cZVg2wVERyRGQSMBXYPoJlNQzDMM7AiHVJeWMS9wEbcL0Ia1R1v4h8H7c7Yg3wU+AlEanDtSyWep/dLyKvAAeAXuC7Z5ohZRiGYYwstnDPMAzjK8xgZknZznSGYRhGQpjBMAzDMBLCDIZhGIaREGYwDMMwjIRIq0FvEWkCDkdFFQLNSSrOSJFuOqWbPpB+OqWbPpB+Og1Fn4mqmtBRTGllMGIRkZ2Jjv6nCummU7rpA+mnU7rpA+mn07nSx7qkDMMwjIQwg2EYhmEkRLobjOeSXYARIN10Sjd9IP10Sjd9IP10Oif6pPUYhmEYhjF8pHsLwzAMwxgmzGAYhmEYCZG2BkNEviEi/ycidSLyULLLM1RE5GMR8YvI+yKSkjssisgaEWkUkX1RceNF5E0ROeT545JZxsHQjz6PicgRr57eF5FvJbOMg0VELheRt0TkAxHZLyIPevEpWU8D6JOy9SQio0Rku4js8XT6Ry9+kohs8+rov7xjJYb33uk4hiEiPuAgcAPuMKYdwDJVPZDUgg0BEfkYuFpVU3axkYhcC7QDL6rqbC/uCeC4qv7QM+zjVPV7ySxnovSjz2NAu6o+mcyynS0icglwiaruEpELgPeAPwXuIAXraQB9biVF60ncgeBjVLVdRLKAd4AHgb8Bfq2qa0VkNbBHVVcN573TtYVRDtSpar2q9gBrgeokl+krj6r+DnfuSTTVwAte+AXcnzkl6EeflEZVP1PVXV64DfgAmECK1tMA+qQs6mj3LrM8p8B1wH978SNSR+lqMCYAn0ZdN5DiPxLcD2KjiLwnIncnuzDDyEWq+hm4PzdQnOTyDAf3icher8sqJbpu4iEiVwBzgW2kQT3F6AMpXE8i4hOR94FG4E3gQ+CEqvZ6IiPyzEtXgyFx4lK9722Bqs4Dvgl81+sOMc4/VgFTgKuAz4Cnklucs0NE8oBfAX+lqq3JLs9QiaNPSteTqgZV9SrgMlyPypXxxIb7vulqMBqAy6OuLwOOJqksw4KqHvX8RuA3uB9JOnDM62cO9zc3Jrk8Q0JVj3l/5hDwPClYT16/+K+Al1X11150ytZTPH3SoZ4AVPUE8D/ANcCFIhI+dntEnnnpajB2AFO9WQPZuLPCa5JcprNGRMZ4A3aIyBjgRmDfwJ9KGWqA5V54ObAuiWUZMuGHqsctpFg9eQOqPwU+UNUfRSWlZD31p08q15OIFInIhV54NFCFG5t5C/i2JzYidZSWs6QAvGlyPwZ8wBpV/ackF+msEZHJuFYFQCbwn6moj4j8Evg6bivmY8A/AK8BrwAlwCfAn6tqSgwk96PP13HdHAp8DNwT7vtPBURkIVAL+IGQF/0Irt8/5eppAH2WkaL1JCJzcIPaPtxL/yuq+n3vObEWGA/sBv5SVbuH9d7pajAMwzCM4SVdu6QMwzCMYcYMhmEYhpEQZjAMwzCMhDCDYRiGYSSEGQzDMAwjIcxgGMYZEJFg1K6m7w/n7scickX0breGcT6TeWYRw/jK0+ltw2AYX2mshWEYZ4l3Rsm/eGcTbBeRUi9+oohs9ja22ywiJV78RSLyG+8cgz0iUuFl5ROR572zDTZ6q3cRkQdE5ICXz9okqWkYEcxgGMaZGR3TJXVbVFqrqpYD/47bWQAv/KKqzgFeBp724p8G3lbVPwLmAfu9+KnAT1R1FnAC+DMv/iFgrpfPipFSzjASxVZ6G8YZEJF2Vc2LE/8xcJ2q1nsb3H2uqgUi0ow7tCfgxX+mqoUi0gRcFr1dg7fl9puqOtW7/h6QpaqPi8hvcQc0vQa8FnUGgmEkBWthGMbQ0H7C/cnEI3q/nyB9Y4s3Az8B5gPvRe1EahhJwQyGYQyN26L833vhrbgdkgH+AneEJsBmYCVEDsDJ7y9TEckALlfVt4C/By4EvtTKMYxzib2xGMaZGe2dbhbmt6oanlqbIyLbcC9fy7y4B4A1IvJ3QBNwpxf/IPCciNyFa0msxB3eEw8f8AsRGYs7EOxfvbMPDCNp2BiGYZwl3hjG1aranOyyGMa5wLqkDMMwjISwFoZhGIaRENbCMAzDMBLCDIZhGIaREGYwDMMwjIQwg2EYhmEkhBkMwzAMIyH+H3FKOT/c9YAGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figsize=(16,4)\n",
    "history1_dict = history1.history\n",
    "#history_dict.keys()\n",
    "history2_dict = history2.history\n",
    "history3_dict = history3.history\n",
    "history4_dict = history4.history\n",
    "history5_dict = history5.history\n",
    "loss_values1 = history1_dict['val_loss']\n",
    "loss_values2 = history2_dict['val_loss']\n",
    "loss_values3 = history3_dict['val_loss']\n",
    "loss_values4 = history4_dict['val_loss']\n",
    "loss_values5 = history5_dict['val_loss']\n",
    "epochs = range(1, len(history1_dict['acc']) + 1)\n",
    "plt.plot(epochs,  loss_values1, 'b', label='Context=0',color='red')\n",
    "plt.plot(epochs, loss_values2, 'b', label='Context=2', color='black')\n",
    "plt.plot(epochs, loss_values3, 'b', label='Context=4', color='green')\n",
    "plt.plot(epochs, loss_values4, 'b', label='Context=6', color='blue')\n",
    "plt.plot(epochs, loss_values5, 'b', label='Context=All', color='yellow')\n",
    "plt.title('Loss on test data for SimpleRNN Model')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 12s 1ms/step - loss: 1.8982 - acc: 0.4246 - val_loss: 1.4236 - val_acc: 0.5380\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 5s 505us/step - loss: 1.2948 - acc: 0.5433 - val_loss: 1.2422 - val_acc: 0.5370\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 5s 562us/step - loss: 1.1919 - acc: 0.5373 - val_loss: 1.1917 - val_acc: 0.5200.1891 - acc: 0.54 - ETA: 0s - loss: 1.19\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 5s 537us/step - loss: 1.1586 - acc: 0.5362 - val_loss: 1.1605 - val_acc: 0.5120\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 5s 511us/step - loss: 1.1365 - acc: 0.5364 - val_loss: 1.1549 - val_acc: 0.5180\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 5s 515us/step - loss: 1.1225 - acc: 0.5310 - val_loss: 1.1695 - val_acc: 0.5020\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 5s 515us/step - loss: 1.1146 - acc: 0.5348 - val_loss: 1.1411 - val_acc: 0.5140\n",
      "Epoch 8/100\n",
      "9000/9000 [==============================] - 5s 563us/step - loss: 1.0995 - acc: 0.5350 - val_loss: 1.1233 - val_acc: 0.5080\n",
      "Epoch 9/100\n",
      "9000/9000 [==============================] - 5s 547us/step - loss: 1.0903 - acc: 0.5368 - val_loss: 1.1354 - val_acc: 0.5170 - los\n",
      "Epoch 10/100\n",
      "9000/9000 [==============================] - 5s 526us/step - loss: 1.0825 - acc: 0.5357 - val_loss: 1.1254 - val_acc: 0.5040\n",
      "Epoch 11/100\n",
      "9000/9000 [==============================] - 5s 518us/step - loss: 1.0742 - acc: 0.5356 - val_loss: 1.1223 - val_acc: 0.5130\n",
      "Epoch 12/100\n",
      "9000/9000 [==============================] - 5s 509us/step - loss: 1.0648 - acc: 0.5430 - val_loss: 1.1121 - val_acc: 0.5090\n",
      "Epoch 13/100\n",
      "9000/9000 [==============================] - 5s 515us/step - loss: 1.0569 - acc: 0.5456 - val_loss: 1.1151 - val_acc: 0.5120\n",
      "Epoch 14/100\n",
      "9000/9000 [==============================] - 5s 536us/step - loss: 1.0541 - acc: 0.5439 - val_loss: 1.1111 - val_acc: 0.5190\n",
      "Epoch 15/100\n",
      "9000/9000 [==============================] - 5s 512us/step - loss: 1.0465 - acc: 0.5471 - val_loss: 1.1118 - val_acc: 0.5170\n",
      "Epoch 16/100\n",
      "9000/9000 [==============================] - 5s 526us/step - loss: 1.0413 - acc: 0.5476 - val_loss: 1.1154 - val_acc: 0.5160\n",
      "Epoch 17/100\n",
      "9000/9000 [==============================] - 5s 552us/step - loss: 1.0361 - acc: 0.5528 - val_loss: 1.1076 - val_acc: 0.50000s - loss: 1.04\n",
      "Epoch 18/100\n",
      "9000/9000 [==============================] - 5s 529us/step - loss: 1.0318 - acc: 0.5507 - val_loss: 1.1154 - val_acc: 0.5160\n",
      "Epoch 19/100\n",
      "9000/9000 [==============================] - 5s 581us/step - loss: 1.0283 - acc: 0.5504 - val_loss: 1.1417 - val_acc: 0.5150\n",
      "Epoch 20/100\n",
      "9000/9000 [==============================] - 7s 829us/step - loss: 1.0227 - acc: 0.5509 - val_loss: 1.1230 - val_acc: 0.4920\n",
      "Epoch 21/100\n",
      "9000/9000 [==============================] - 6s 668us/step - loss: 1.0226 - acc: 0.5534 - val_loss: 1.1062 - val_acc: 0.5120\n",
      "Epoch 22/100\n",
      "9000/9000 [==============================] - 6s 636us/step - loss: 1.0154 - acc: 0.5590 - val_loss: 1.1204 - val_acc: 0.5140\n",
      "Epoch 23/100\n",
      "9000/9000 [==============================] - 6s 611us/step - loss: 1.0124 - acc: 0.5574 - val_loss: 1.1205 - val_acc: 0.4990\n",
      "Epoch 24/100\n",
      "9000/9000 [==============================] - 6s 663us/step - loss: 1.0049 - acc: 0.5616 - val_loss: 1.1106 - val_acc: 0.5080\n",
      "Epoch 25/100\n",
      "9000/9000 [==============================] - 6s 696us/step - loss: 1.0067 - acc: 0.5590 - val_loss: 1.1390 - val_acc: 0.4850\n",
      "Epoch 26/100\n",
      "9000/9000 [==============================] - 6s 697us/step - loss: 1.0049 - acc: 0.5612 - val_loss: 1.1226 - val_acc: 0.5040\n",
      "Epoch 27/100\n",
      "9000/9000 [==============================] - 6s 711us/step - loss: 1.0014 - acc: 0.5669 - val_loss: 1.1051 - val_acc: 0.5110\n",
      "Epoch 28/100\n",
      "9000/9000 [==============================] - 6s 647us/step - loss: 0.9948 - acc: 0.5714 - val_loss: 1.1332 - val_acc: 0.4990\n",
      "Epoch 29/100\n",
      "9000/9000 [==============================] - 5s 547us/step - loss: 0.9912 - acc: 0.5610 - val_loss: 1.1177 - val_acc: 0.4940\n",
      "Epoch 30/100\n",
      "9000/9000 [==============================] - 6s 684us/step - loss: 0.9956 - acc: 0.5701 - val_loss: 1.1263 - val_acc: 0.5030\n",
      "Epoch 31/100\n",
      "9000/9000 [==============================] - 5s 567us/step - loss: 0.9904 - acc: 0.5720 - val_loss: 1.1092 - val_acc: 0.5170\n",
      "Epoch 32/100\n",
      "9000/9000 [==============================] - 5s 576us/step - loss: 0.9854 - acc: 0.5748 - val_loss: 1.1274 - val_acc: 0.4930\n",
      "Epoch 33/100\n",
      "9000/9000 [==============================] - 6s 614us/step - loss: 0.9839 - acc: 0.5706 - val_loss: 1.1522 - val_acc: 0.4900\n",
      "Epoch 34/100\n",
      "9000/9000 [==============================] - 6s 659us/step - loss: 0.9928 - acc: 0.5692 - val_loss: 1.1294 - val_acc: 0.4980\n",
      "Epoch 35/100\n",
      "9000/9000 [==============================] - 6s 685us/step - loss: 0.9775 - acc: 0.5737 - val_loss: 1.1416 - val_acc: 0.5040\n",
      "Epoch 36/100\n",
      "9000/9000 [==============================] - 7s 726us/step - loss: 0.9808 - acc: 0.5767 - val_loss: 1.1256 - val_acc: 0.4950\n",
      "Epoch 37/100\n",
      "9000/9000 [==============================] - 7s 756us/step - loss: 0.9777 - acc: 0.5673 - val_loss: 1.1150 - val_acc: 0.5140\n",
      "Epoch 38/100\n",
      "9000/9000 [==============================] - 7s 815us/step - loss: 0.9780 - acc: 0.5723 - val_loss: 1.1377 - val_acc: 0.4990\n",
      "Epoch 39/100\n",
      "9000/9000 [==============================] - 6s 689us/step - loss: 0.9786 - acc: 0.5729 - val_loss: 1.1244 - val_acc: 0.4890\n",
      "Epoch 40/100\n",
      "9000/9000 [==============================] - 8s 883us/step - loss: 0.9707 - acc: 0.5783 - val_loss: 1.1441 - val_acc: 0.4970\n",
      "Epoch 41/100\n",
      "9000/9000 [==============================] - 6s 675us/step - loss: 0.9722 - acc: 0.5790 - val_loss: 1.1295 - val_acc: 0.5090\n",
      "Epoch 42/100\n",
      "9000/9000 [==============================] - 9s 1ms/step - loss: 0.9726 - acc: 0.5768 - val_loss: 1.1301 - val_acc: 0.4780\n",
      "Epoch 43/100\n",
      "9000/9000 [==============================] - 9s 948us/step - loss: 0.9704 - acc: 0.5763 - val_loss: 1.1457 - val_acc: 0.5150\n",
      "Epoch 44/100\n",
      "9000/9000 [==============================] - 15s 2ms/step - loss: 0.9645 - acc: 0.5799 - val_loss: 1.1307 - val_acc: 0.5140\n",
      "Epoch 45/100\n",
      "9000/9000 [==============================] - 12s 1ms/step - loss: 0.9668 - acc: 0.5799 - val_loss: 1.1529 - val_acc: 0.5060\n",
      "Epoch 46/100\n",
      "9000/9000 [==============================] - 14s 2ms/step - loss: 0.9683 - acc: 0.5787 - val_loss: 1.1400 - val_acc: 0.4940\n",
      "Epoch 47/100\n",
      "9000/9000 [==============================] - 10s 1ms/step - loss: 0.9609 - acc: 0.5821 - val_loss: 1.1427 - val_acc: 0.4840.9494 - acc: 0 - ETA: 1s - los\n",
      "Epoch 48/100\n",
      "9000/9000 [==============================] - 9s 966us/step - loss: 0.9595 - acc: 0.5791 - val_loss: 1.1407 - val_acc: 0.4960\n",
      "Epoch 49/100\n",
      "9000/9000 [==============================] - 12s 1ms/step - loss: 0.9606 - acc: 0.5779 - val_loss: 1.1451 - val_acc: 0.5030\n",
      "Epoch 50/100\n",
      "9000/9000 [==============================] - 10s 1ms/step - loss: 0.9563 - acc: 0.5816 - val_loss: 1.1503 - val_acc: 0.4830\n",
      "Epoch 51/100\n",
      "9000/9000 [==============================] - 10s 1ms/step - loss: 0.9534 - acc: 0.5836 - val_loss: 1.1587 - val_acc: 0.4770\n",
      "Epoch 52/100\n",
      "9000/9000 [==============================] - 11s 1ms/step - loss: 0.9640 - acc: 0.5809 - val_loss: 1.1498 - val_acc: 0.4960\n",
      "Epoch 53/100\n",
      "9000/9000 [==============================] - 10s 1ms/step - loss: 0.9534 - acc: 0.5859 - val_loss: 1.1414 - val_acc: 0.5050s: 0.9548 - acc: 0.58 -\n",
      "Epoch 54/100\n",
      "9000/9000 [==============================] - 9s 990us/step - loss: 0.9523 - acc: 0.5793 - val_loss: 1.1195 - val_acc: 0.5130\n",
      "Epoch 55/100\n",
      "9000/9000 [==============================] - 9s 1ms/step - loss: 0.9550 - acc: 0.5828 - val_loss: 1.1500 - val_acc: 0.5060\n",
      "Epoch 56/100\n",
      "9000/9000 [==============================] - 7s 798us/step - loss: 0.9564 - acc: 0.5804 - val_loss: 1.1746 - val_acc: 0.5000\n",
      "Epoch 57/100\n",
      "9000/9000 [==============================] - 8s 848us/step - loss: 0.9622 - acc: 0.5787 - val_loss: 1.1600 - val_acc: 0.5100\n",
      "Epoch 58/100\n",
      "9000/9000 [==============================] - 8s 865us/step - loss: 0.9541 - acc: 0.5843 - val_loss: 1.1474 - val_acc: 0.5100\n",
      "Epoch 59/100\n",
      "9000/9000 [==============================] - 7s 743us/step - loss: 0.9518 - acc: 0.5859 - val_loss: 1.1511 - val_acc: 0.5140\n",
      "Epoch 60/100\n",
      "9000/9000 [==============================] - 5s 541us/step - loss: 0.9558 - acc: 0.5802 - val_loss: 1.1578 - val_acc: 0.4950\n",
      "Epoch 61/100\n",
      "9000/9000 [==============================] - 6s 614us/step - loss: 0.9502 - acc: 0.5850 - val_loss: 1.1661 - val_acc: 0.5040\n",
      "Epoch 62/100\n",
      "9000/9000 [==============================] - 7s 723us/step - loss: 1.0407 - acc: 0.5592 - val_loss: 1.1699 - val_acc: 0.4960\n",
      "Epoch 63/100\n",
      "9000/9000 [==============================] - 6s 650us/step - loss: 1.0124 - acc: 0.5549 - val_loss: 1.1468 - val_acc: 0.5050\n",
      "Epoch 64/100\n",
      "9000/9000 [==============================] - 6s 660us/step - loss: 0.9878 - acc: 0.5657 - val_loss: 1.1474 - val_acc: 0.5130\n",
      "Epoch 65/100\n",
      "9000/9000 [==============================] - 5s 607us/step - loss: 0.9803 - acc: 0.5677 - val_loss: 1.1737 - val_acc: 0.4900\n",
      "Epoch 66/100\n",
      "9000/9000 [==============================] - 6s 632us/step - loss: 0.9750 - acc: 0.5689 - val_loss: 1.1753 - val_acc: 0.4840\n",
      "Epoch 67/100\n",
      "9000/9000 [==============================] - 7s 752us/step - loss: 0.9707 - acc: 0.5709 - val_loss: 1.1713 - val_acc: 0.5050\n",
      "Epoch 68/100\n",
      "9000/9000 [==============================] - 6s 640us/step - loss: 0.9676 - acc: 0.5738 - val_loss: 1.1859 - val_acc: 0.4870\n",
      "Epoch 69/100\n",
      "9000/9000 [==============================] - 6s 687us/step - loss: 0.9659 - acc: 0.5753 - val_loss: 1.1569 - val_acc: 0.5070\n",
      "Epoch 70/100\n",
      "9000/9000 [==============================] - 5s 606us/step - loss: 0.9564 - acc: 0.5846 - val_loss: 1.1610 - val_acc: 0.4990\n",
      "Epoch 71/100\n",
      "9000/9000 [==============================] - 5s 595us/step - loss: 0.9568 - acc: 0.5809 - val_loss: 1.1578 - val_acc: 0.5100\n",
      "Epoch 72/100\n",
      "9000/9000 [==============================] - 5s 552us/step - loss: 0.9541 - acc: 0.5841 - val_loss: 1.1871 - val_acc: 0.4950\n",
      "Epoch 73/100\n",
      "9000/9000 [==============================] - 5s 569us/step - loss: 0.9608 - acc: 0.5743 - val_loss: 1.1880 - val_acc: 0.5100\n",
      "Epoch 74/100\n",
      "9000/9000 [==============================] - 6s 663us/step - loss: 0.9542 - acc: 0.5872 - val_loss: 1.1883 - val_acc: 0.4940\n",
      "Epoch 75/100\n",
      "9000/9000 [==============================] - 6s 677us/step - loss: 0.9543 - acc: 0.5827 - val_loss: 1.1879 - val_acc: 0.4930ss: 0.9543 - - ETA: 0s - loss: 0.9550 - acc: 0.5\n",
      "Epoch 76/100\n",
      "9000/9000 [==============================] - 5s 571us/step - loss: 0.9581 - acc: 0.5750 - val_loss: 1.1936 - val_acc: 0.4940\n",
      "Epoch 77/100\n",
      "9000/9000 [==============================] - 5s 558us/step - loss: 0.9496 - acc: 0.5833 - val_loss: 1.1790 - val_acc: 0.5000s: 0\n",
      "Epoch 78/100\n",
      "9000/9000 [==============================] - 6s 648us/step - loss: 0.9395 - acc: 0.5880 - val_loss: 1.1850 - val_acc: 0.4930\n",
      "Epoch 79/100\n",
      "9000/9000 [==============================] - 6s 655us/step - loss: 0.9548 - acc: 0.5809 - val_loss: 1.1808 - val_acc: 0.4880\n",
      "Epoch 80/100\n",
      "9000/9000 [==============================] - 6s 691us/step - loss: 0.9504 - acc: 0.5822 - val_loss: 1.1862 - val_acc: 0.5020\n",
      "Epoch 81/100\n",
      "9000/9000 [==============================] - 6s 633us/step - loss: 0.9469 - acc: 0.5832 - val_loss: 1.1747 - val_acc: 0.4960\n",
      "Epoch 82/100\n",
      "9000/9000 [==============================] - 5s 603us/step - loss: 0.9520 - acc: 0.5787 - val_loss: 1.1803 - val_acc: 0.4950\n",
      "Epoch 83/100\n",
      "9000/9000 [==============================] - 5s 576us/step - loss: 0.9405 - acc: 0.5843 - val_loss: 1.1790 - val_acc: 0.5080\n",
      "Epoch 84/100\n",
      "9000/9000 [==============================] - 5s 588us/step - loss: 0.9520 - acc: 0.5828 - val_loss: 1.1677 - val_acc: 0.4990\n",
      "Epoch 85/100\n",
      "9000/9000 [==============================] - 5s 543us/step - loss: 0.9472 - acc: 0.5850 - val_loss: 1.1901 - val_acc: 0.5030\n",
      "Epoch 86/100\n",
      "9000/9000 [==============================] - 5s 550us/step - loss: 0.9382 - acc: 0.5881 - val_loss: 1.1716 - val_acc: 0.5040\n",
      "Epoch 87/100\n",
      "9000/9000 [==============================] - 5s 539us/step - loss: 0.9515 - acc: 0.5787 - val_loss: 1.1703 - val_acc: 0.4850\n",
      "Epoch 88/100\n",
      "9000/9000 [==============================] - 5s 556us/step - loss: 0.9608 - acc: 0.5799 - val_loss: 1.1880 - val_acc: 0.4900\n",
      "Epoch 89/100\n",
      "9000/9000 [==============================] - 5s 564us/step - loss: 0.9575 - acc: 0.5854 - val_loss: 1.2034 - val_acc: 0.4960\n",
      "Epoch 90/100\n",
      "9000/9000 [==============================] - 5s 552us/step - loss: 0.9639 - acc: 0.5798 - val_loss: 1.1568 - val_acc: 0.4990 1s - loss: 0\n",
      "Epoch 91/100\n",
      "9000/9000 [==============================] - 5s 536us/step - loss: 0.9351 - acc: 0.5916 - val_loss: 1.1626 - val_acc: 0.4870\n",
      "Epoch 92/100\n",
      "9000/9000 [==============================] - 5s 536us/step - loss: 0.9278 - acc: 0.5910 - val_loss: 1.1768 - val_acc: 0.4980\n",
      "Epoch 93/100\n",
      "9000/9000 [==============================] - 5s 553us/step - loss: 0.9408 - acc: 0.5912 - val_loss: 1.1866 - val_acc: 0.4890\n",
      "Epoch 94/100\n",
      "9000/9000 [==============================] - 5s 575us/step - loss: 0.9325 - acc: 0.5941 - val_loss: 1.1737 - val_acc: 0.4920\n",
      "Epoch 95/100\n",
      "9000/9000 [==============================] - 5s 574us/step - loss: 0.9520 - acc: 0.5849 - val_loss: 1.1901 - val_acc: 0.5000\n",
      "Epoch 96/100\n",
      "9000/9000 [==============================] - 5s 565us/step - loss: 0.9428 - acc: 0.5913 - val_loss: 1.1584 - val_acc: 0.5050\n",
      "Epoch 97/100\n",
      "9000/9000 [==============================] - 5s 548us/step - loss: 0.9339 - acc: 0.5970 - val_loss: 1.1585 - val_acc: 0.5050\n",
      "Epoch 98/100\n",
      "9000/9000 [==============================] - 5s 566us/step - loss: 0.9399 - acc: 0.5869 - val_loss: 1.1684 - val_acc: 0.5030\n",
      "Epoch 99/100\n",
      "9000/9000 [==============================] - 5s 564us/step - loss: 0.9687 - acc: 0.5788 - val_loss: 1.1640 - val_acc: 0.5120\n",
      "Epoch 100/100\n",
      "9000/9000 [==============================] - 6s 626us/step - loss: 0.9441 - acc: 0.5870 - val_loss: 1.1767 - val_acc: 0.4980\n",
      "Evaluation\n",
      "1000/1000 [==============================] - 0s 212us/step\n",
      "Test loss / test accuracy = 1.1941 / 0.5060\n"
     ]
    }
   ],
   "source": [
    "#contet=8; 52 words; 100 iterations\n",
    "import os\n",
    "import sys\n",
    "train=os.path.realpath('C:/Users/nisht/Desktop/MITA/capstone_project/qa1_single-supporting-fact_train.txt')\n",
    "test=os.path.realpath('C:/Users/nisht/Desktop/MITA/capstone_project/qa1_single-supporting-fact_test.txt')\n",
    "context=-1\n",
    "X_tr,Q_tr,y_tr,X_te,Q_te,y_te,model=create_model(train,test,context)\n",
    "print('Training')\n",
    "history=model.fit([X_tr, Q_tr], y_tr,batch_size=32,epochs=100, verbose=1,validation_split=0.1)\n",
    "print('Evaluation')\n",
    "loss, acc = model.evaluate([X_te,Q_te], y_te,batch_size=32)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From these results, we can conclude that RNNs have limited capacity for storing large pieces of information. The performance drops signficantly after 41 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSTMs for Question Answering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_lstm(trainingData, testData, context):\n",
    "    tokenizer,vocab_size=create_tokenizer(trainingData,testData)\n",
    "\n",
    "    X_tr,Q_tr,y_tr,max_story_len_tr, max_query_len_tr=process_stories_n_context(trainingData,tokenizer,vocab_size,use_context=context)\n",
    "    X_te,Q_te,y_te, max_story_len_te, max_query_len_te=process_stories_n_context(testData,tokenizer,vocab_size,use_context=context)\n",
    "\n",
    "    max_story_len=max(max_story_len_tr, max_story_len_te)\n",
    "    max_query_len=max(max_query_len_tr, max_query_len_te)\n",
    "\n",
    "    X_tr=pad_sequences(X_tr,max_story_len)\n",
    "    Q_tr=pad_sequences(Q_tr, max_query_len)\n",
    "    X_te=pad_sequences(X_te,max_story_len)\n",
    "    Q_te=pad_sequences(Q_te,max_query_len)\n",
    "\n",
    "    embedding=layers.Embedding(vocab_size,100)\n",
    "\n",
    "    story = layers.Input(shape=(max_story_len,), dtype='int32')\n",
    "    encoded_story = embedding(story)\n",
    "    encoded_story = LSTM(30)(encoded_story)\n",
    "\n",
    "    question = layers.Input(shape=(max_query_len,), dtype='int32')\n",
    "    encoded_question = embedding(question)\n",
    "    encoded_question = LSTM(30)(encoded_question)\n",
    "\n",
    "    merged = layers.concatenate([encoded_story, encoded_question])\n",
    "    preds = layers.Dense(vocab_size, activation='softmax')(merged)\n",
    "\n",
    "    model = Model([story, question], preds)\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    #print(X_te,Q_te)\n",
    "\n",
    "    return X_tr,Q_tr,y_tr,X_te,Q_te,y_te,model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 23s 3ms/step - loss: 2.1014 - acc: 0.3307 - val_loss: 1.5165 - val_acc: 0.5380\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 15s 2ms/step - loss: 1.4358 - acc: 0.5408 - val_loss: 1.4108 - val_acc: 0.5380\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 14s 2ms/step - loss: 1.3856 - acc: 0.5427 - val_loss: 1.3670 - val_acc: 0.5380\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 13s 1ms/step - loss: 1.2860 - acc: 0.5406 - val_loss: 1.2538 - val_acc: 0.5380\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 1.1743 - acc: 0.5376 - val_loss: 1.1391 - val_acc: 0.5400\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 1.1074 - acc: 0.5382 - val_loss: 1.1175 - val_acc: 0.5320\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 1.0767 - acc: 0.5341 - val_loss: 1.1031 - val_acc: 0.5150\n",
      "Epoch 8/100\n",
      "9000/9000 [==============================] - 15s 2ms/step - loss: 1.0567 - acc: 0.5423 - val_loss: 1.0924 - val_acc: 0.5100\n",
      "Epoch 9/100\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 1.0438 - acc: 0.5416 - val_loss: 1.0801 - val_acc: 0.5220\n",
      "Epoch 10/100\n",
      "9000/9000 [==============================] - 15s 2ms/step - loss: 1.0310 - acc: 0.5374 - val_loss: 1.0693 - val_acc: 0.5320\n",
      "Epoch 11/100\n",
      "9000/9000 [==============================] - 14s 2ms/step - loss: 1.0217 - acc: 0.5429 - val_loss: 1.0794 - val_acc: 0.5500\n",
      "Epoch 12/100\n",
      "9000/9000 [==============================] - 15s 2ms/step - loss: 1.0141 - acc: 0.5454 - val_loss: 1.0681 - val_acc: 0.5180\n",
      "Epoch 13/100\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 1.0086 - acc: 0.5443 - val_loss: 1.0690 - val_acc: 0.5340\n",
      "Epoch 14/100\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 1.0015 - acc: 0.5439 - val_loss: 1.0596 - val_acc: 0.5390\n",
      "Epoch 15/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.9974 - acc: 0.5449 - val_loss: 1.0698 - val_acc: 0.5180\n",
      "Epoch 16/100\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 0.9926 - acc: 0.5462 - val_loss: 1.0657 - val_acc: 0.5250\n",
      "Epoch 17/100\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.9881 - acc: 0.5520 - val_loss: 1.0634 - val_acc: 0.5230\n",
      "Epoch 18/100\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 0.9826 - acc: 0.5521 - val_loss: 1.0617 - val_acc: 0.5270\n",
      "Epoch 19/100\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 0.9770 - acc: 0.5547 - val_loss: 1.0823 - val_acc: 0.5190\n",
      "Epoch 20/100\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 0.9754 - acc: 0.5534 - val_loss: 1.0697 - val_acc: 0.5020\n",
      "Epoch 21/100\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 0.9690 - acc: 0.5580 - val_loss: 1.0899 - val_acc: 0.5130\n",
      "Epoch 22/100\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 0.9632 - acc: 0.5663 - val_loss: 1.0731 - val_acc: 0.5260\n",
      "Epoch 23/100\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 0.9610 - acc: 0.5621 - val_loss: 1.0716 - val_acc: 0.5110\n",
      "Epoch 24/100\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.9570 - acc: 0.5620 - val_loss: 1.0731 - val_acc: 0.5170\n",
      "Epoch 25/100\n",
      "9000/9000 [==============================] - 22s 2ms/step - loss: 0.9535 - acc: 0.5661 - val_loss: 1.0932 - val_acc: 0.5180\n",
      "Epoch 26/100\n",
      "9000/9000 [==============================] - 22s 2ms/step - loss: 0.9461 - acc: 0.5637 - val_loss: 1.0856 - val_acc: 0.5090\n",
      "Epoch 27/100\n",
      "9000/9000 [==============================] - 22s 2ms/step - loss: 0.9433 - acc: 0.5630 - val_loss: 1.0924 - val_acc: 0.5210\n",
      "Epoch 28/100\n",
      "9000/9000 [==============================] - 22s 2ms/step - loss: 0.9384 - acc: 0.5730 - val_loss: 1.0899 - val_acc: 0.5010\n",
      "Epoch 29/100\n",
      "9000/9000 [==============================] - 22s 2ms/step - loss: 0.9353 - acc: 0.5709 - val_loss: 1.0956 - val_acc: 0.5100\n",
      "Epoch 30/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.9292 - acc: 0.5766 - val_loss: 1.0847 - val_acc: 0.5090\n",
      "Epoch 31/100\n",
      "9000/9000 [==============================] - 22s 2ms/step - loss: 0.9255 - acc: 0.5726 - val_loss: 1.0943 - val_acc: 0.4970\n",
      "Epoch 32/100\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.9238 - acc: 0.5770 - val_loss: 1.0941 - val_acc: 0.5070\n",
      "Epoch 33/100\n",
      "9000/9000 [==============================] - 22s 2ms/step - loss: 0.9206 - acc: 0.5770 - val_loss: 1.0934 - val_acc: 0.5070\n",
      "Epoch 34/100\n",
      "9000/9000 [==============================] - 21s 2ms/step - loss: 0.9131 - acc: 0.5807 - val_loss: 1.1120 - val_acc: 0.4840\n",
      "Epoch 35/100\n",
      "9000/9000 [==============================] - 21s 2ms/step - loss: 0.9108 - acc: 0.5824 - val_loss: 1.1073 - val_acc: 0.5060\n",
      "Epoch 36/100\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 0.9064 - acc: 0.5850 - val_loss: 1.1038 - val_acc: 0.5050\n",
      "Epoch 37/100\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.9015 - acc: 0.5941 - val_loss: 1.1134 - val_acc: 0.5000\n",
      "Epoch 38/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.8973 - acc: 0.5879 - val_loss: 1.1112 - val_acc: 0.5080\n",
      "Epoch 39/100\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 0.8913 - acc: 0.5956 - val_loss: 1.1136 - val_acc: 0.5160\n",
      "Epoch 40/100\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.8899 - acc: 0.5898 - val_loss: 1.1360 - val_acc: 0.4960\n",
      "Epoch 41/100\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.8837 - acc: 0.5924 - val_loss: 1.1223 - val_acc: 0.4990\n",
      "Epoch 42/100\n",
      "9000/9000 [==============================] - 21s 2ms/step - loss: 0.8794 - acc: 0.6003 - val_loss: 1.1293 - val_acc: 0.4970\n",
      "Epoch 43/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.8737 - acc: 0.6031 - val_loss: 1.1391 - val_acc: 0.5060\n",
      "Epoch 44/100\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 0.8680 - acc: 0.6057 - val_loss: 1.1313 - val_acc: 0.4910\n",
      "Epoch 45/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.8643 - acc: 0.6056 - val_loss: 1.1512 - val_acc: 0.5010\n",
      "Epoch 46/100\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 0.8635 - acc: 0.6066 - val_loss: 1.1478 - val_acc: 0.5060\n",
      "Epoch 47/100\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 0.8558 - acc: 0.6096 - val_loss: 1.1464 - val_acc: 0.4980\n",
      "Epoch 48/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.8533 - acc: 0.6068 - val_loss: 1.1454 - val_acc: 0.5020\n",
      "Epoch 49/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.8487 - acc: 0.6116 - val_loss: 1.1581 - val_acc: 0.5020\n",
      "Epoch 50/100\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 0.8422 - acc: 0.6169 - val_loss: 1.1592 - val_acc: 0.5020\n",
      "Epoch 51/100\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 0.8397 - acc: 0.6222 - val_loss: 1.1565 - val_acc: 0.4960\n",
      "Epoch 52/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.8388 - acc: 0.6201 - val_loss: 1.1604 - val_acc: 0.5100\n",
      "Epoch 53/100\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 0.8351 - acc: 0.6230 - val_loss: 1.1640 - val_acc: 0.4940\n",
      "Epoch 54/100\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 0.8305 - acc: 0.6214 - val_loss: 1.1671 - val_acc: 0.5010\n",
      "Epoch 55/100\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 0.8255 - acc: 0.6260 - val_loss: 1.1612 - val_acc: 0.5020\n",
      "Epoch 56/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.8218 - acc: 0.6281 - val_loss: 1.1594 - val_acc: 0.5020\n",
      "Epoch 57/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.8160 - acc: 0.6340 - val_loss: 1.1675 - val_acc: 0.5070\n",
      "Epoch 58/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.8132 - acc: 0.6377 - val_loss: 1.1711 - val_acc: 0.5120TA: 1s \n",
      "Epoch 59/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.8175 - acc: 0.6294 - val_loss: 1.1799 - val_acc: 0.4990\n",
      "Epoch 60/100\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 0.8136 - acc: 0.6349 - val_loss: 1.1781 - val_acc: 0.4970\n",
      "Epoch 61/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.8011 - acc: 0.6400 - val_loss: 1.1880 - val_acc: 0.4940\n",
      "Epoch 62/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.8016 - acc: 0.6426 - val_loss: 1.2010 - val_acc: 0.5040\n",
      "Epoch 63/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.7975 - acc: 0.6380 - val_loss: 1.1875 - val_acc: 0.4990\n",
      "Epoch 64/100\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 0.7949 - acc: 0.6448 - val_loss: 1.1944 - val_acc: 0.5190\n",
      "Epoch 65/100\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 0.7854 - acc: 0.6459 - val_loss: 1.2020 - val_acc: 0.5110\n",
      "Epoch 66/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.7829 - acc: 0.6519 - val_loss: 1.2008 - val_acc: 0.4980\n",
      "Epoch 67/100\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 0.7783 - acc: 0.6540 - val_loss: 1.2134 - val_acc: 0.4960\n",
      "Epoch 68/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.7789 - acc: 0.6532 - val_loss: 1.2187 - val_acc: 0.5100\n",
      "Epoch 69/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.7848 - acc: 0.6456 - val_loss: 1.2122 - val_acc: 0.5010\n",
      "Epoch 70/100\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 0.7739 - acc: 0.6497 - val_loss: 1.2026 - val_acc: 0.5090\n",
      "Epoch 71/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.7676 - acc: 0.6581 - val_loss: 1.2213 - val_acc: 0.4960\n",
      "Epoch 72/100\n",
      "9000/9000 [==============================] - 15s 2ms/step - loss: 0.7668 - acc: 0.6558 - val_loss: 1.2432 - val_acc: 0.4820\n",
      "Epoch 73/100\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 0.7744 - acc: 0.6537 - val_loss: 1.2389 - val_acc: 0.4930\n",
      "Epoch 74/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.7640 - acc: 0.6599 - val_loss: 1.2249 - val_acc: 0.5010\n",
      "Epoch 75/100\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 0.7760 - acc: 0.6560 - val_loss: 1.2191 - val_acc: 0.4990\n",
      "Epoch 76/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.7529 - acc: 0.6661 - val_loss: 1.2234 - val_acc: 0.4930\n",
      "Epoch 77/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.7503 - acc: 0.6642 - val_loss: 1.2324 - val_acc: 0.4990\n",
      "Epoch 78/100\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.7541 - acc: 0.6639 - val_loss: 1.2359 - val_acc: 0.4960\n",
      "Epoch 79/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.7422 - acc: 0.6654 - val_loss: 1.2463 - val_acc: 0.4900\n",
      "Epoch 80/100\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 0.7465 - acc: 0.6638 - val_loss: 1.2432 - val_acc: 0.5010\n",
      "Epoch 81/100\n",
      "9000/9000 [==============================] - 15s 2ms/step - loss: 0.7366 - acc: 0.6731 - val_loss: 1.2392 - val_acc: 0.5060\n",
      "Epoch 82/100\n",
      "9000/9000 [==============================] - 15s 2ms/step - loss: 0.7520 - acc: 0.6644 - val_loss: 1.2524 - val_acc: 0.4780\n",
      "Epoch 83/100\n",
      "9000/9000 [==============================] - 15s 2ms/step - loss: 0.7370 - acc: 0.6769 - val_loss: 1.2621 - val_acc: 0.4920\n",
      "Epoch 84/100\n",
      "9000/9000 [==============================] - 15s 2ms/step - loss: 0.7369 - acc: 0.6727 - val_loss: 1.2480 - val_acc: 0.4950\n",
      "Epoch 85/100\n",
      "9000/9000 [==============================] - 16s 2ms/step - loss: 0.7357 - acc: 0.6747 - val_loss: 1.2701 - val_acc: 0.4900\n",
      "Epoch 86/100\n",
      "9000/9000 [==============================] - 15s 2ms/step - loss: 0.7254 - acc: 0.6771 - val_loss: 1.2583 - val_acc: 0.4930\n",
      "Epoch 87/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.7295 - acc: 0.6796 - val_loss: 1.2526 - val_acc: 0.4820\n",
      "Epoch 88/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.7239 - acc: 0.6854 - val_loss: 1.2559 - val_acc: 0.4860\n",
      "Epoch 89/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.7220 - acc: 0.6829 - val_loss: 1.2767 - val_acc: 0.4960\n",
      "Epoch 90/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.7223 - acc: 0.6860 - val_loss: 1.2812 - val_acc: 0.4900\n",
      "Epoch 91/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.7119 - acc: 0.6887 - val_loss: 1.2859 - val_acc: 0.4940\n",
      "Epoch 92/100\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.7103 - acc: 0.6907 - val_loss: 1.3097 - val_acc: 0.4740\n",
      "Epoch 93/100\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.7082 - acc: 0.6879 - val_loss: 1.2926 - val_acc: 0.4950\n",
      "Epoch 94/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.7152 - acc: 0.6879 - val_loss: 1.3020 - val_acc: 0.4890\n",
      "Epoch 95/100\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 0.7039 - acc: 0.6893 - val_loss: 1.3150 - val_acc: 0.4740\n",
      "Epoch 96/100\n",
      "9000/9000 [==============================] - 20s 2ms/step - loss: 0.7019 - acc: 0.6958 - val_loss: 1.3047 - val_acc: 0.4870\n",
      "Epoch 97/100\n",
      "9000/9000 [==============================] - 18s 2ms/step - loss: 0.7301 - acc: 0.6791 - val_loss: 1.3013 - val_acc: 0.4830\n",
      "Epoch 98/100\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 0.7054 - acc: 0.6900 - val_loss: 1.2937 - val_acc: 0.4990\n",
      "Epoch 99/100\n",
      "9000/9000 [==============================] - 19s 2ms/step - loss: 0.6909 - acc: 0.6994 - val_loss: 1.3201 - val_acc: 0.4970\n",
      "Epoch 100/100\n",
      "9000/9000 [==============================] - 17s 2ms/step - loss: 0.6952 - acc: 0.6948 - val_loss: 1.3285 - val_acc: 0.4910\n",
      "Evaluation\n",
      "1000/1000 [==============================] - 0s 335us/step\n",
      "Test loss / test accuracy = 1.4037 / 0.4820\n"
     ]
    }
   ],
   "source": [
    "#contet=8; 52 words; 100 iterations\n",
    "import os\n",
    "import sys\n",
    "train=os.path.realpath('C:/Users/nisht/Desktop/MITA/capstone_project/qa1_single-supporting-fact_train.txt')\n",
    "test=os.path.realpath('C:/Users/nisht/Desktop/MITA/capstone_project/qa1_single-supporting-fact_test.txt')\n",
    "context=-1\n",
    "X_tr,Q_tr,y_tr,X_te,Q_te,y_te,model=create_model_lstm(train, test, context)\n",
    "print('Training')\n",
    "history=model.fit([X_tr, Q_tr], y_tr,batch_size=32,epochs=100, verbose=1,validation_split=0.1)\n",
    "print('Evaluation')\n",
    "loss, acc = model.evaluate([X_te,Q_te], y_te,batch_size=32)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We see that LSTMs push the boundary a bit further compared to RNNs. But, similar to RNNs, they fail on long sequences, displaying an abrupt decline in accuracy. We conclude that neither LSTMs or RNNs are adequate tools for handing very long sequences of facts for Question Answering. LSTMs outperform RNNs for moderately long contexts, but fail on extensive sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_107 (InputLayer)          (None, 58)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_108 (InputLayer)          (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_74 (Embedding)        (None, 58, 64)       9472        input_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_76 (Embedding)        (None, 3, 64)        9472        input_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_11 (Dot)                    (None, 58, 3)        0           embedding_74[0][0]               \n",
      "                                                                 embedding_76[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 58, 3)        0           dot_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_75 (Embedding)        (None, 58, 3)        444         input_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 58, 3)        0           activation_12[0][0]              \n",
      "                                                                 embedding_75[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_11 (Permute)            (None, 3, 58)        0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 3, 122)       0           permute_11[0][0]                 \n",
      "                                                                 embedding_76[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 3, 122)       15006       concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 3, 122)       0           concatenate_54[0][0]             \n",
      "                                                                 dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 366)          0           multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 148)          54316       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 148)          0           dense_54[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 88,710\n",
      "Trainable params: 88,710\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  0,  0, ...,  1,  2, 12],\n",
       "        [ 0,  0,  0, ...,  1,  2, 14],\n",
       "        [ 0,  0,  0, ...,  1,  2, 10],\n",
       "        ...,\n",
       "        [ 0,  0,  0, ...,  1,  2, 13],\n",
       "        [ 0,  0,  0, ...,  1,  2, 10],\n",
       "        [ 0,  0,  0, ...,  1,  2, 15]]), array([[3, 4, 8],\n",
       "        [3, 4, 9],\n",
       "        [3, 4, 9],\n",
       "        ...,\n",
       "        [3, 4, 8],\n",
       "        [3, 4, 6],\n",
       "        [3, 4, 6]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]), array([[ 0,  0,  0, ...,  1,  2, 10],\n",
       "        [ 0,  0,  0, ...,  1,  2, 15],\n",
       "        [ 0,  0,  0, ...,  1,  2, 13],\n",
       "        ...,\n",
       "        [ 0,  0,  0, ...,  1,  2, 15],\n",
       "        [ 0,  0,  0, ...,  1,  2, 10],\n",
       "        [ 0,  0,  0, ...,  1,  2, 14]]), array([[3, 4, 6],\n",
       "        [3, 4, 8],\n",
       "        [3, 4, 7],\n",
       "        ...,\n",
       "        [3, 4, 7],\n",
       "        [3, 4, 7],\n",
       "        [3, 4, 6]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]), <keras.engine.training.Model at 0x23e0a2479e8>)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_model_nnm(trainingData, testData, context):\n",
    "    #import merge\n",
    "\n",
    "    tokenizer,vocab_size=create_tokenizer(trainingData,testData)\n",
    "\n",
    "    X_tr,Q_tr,y_tr,max_story_len_tr, max_query_len_tr=process_stories_n_context(trainingData,tokenizer,vocab_size,use_context=context)\n",
    "    X_te,Q_te,y_te, max_story_len_te, max_query_len_te=process_stories_n_context(testData,tokenizer,vocab_size,use_context=context)\n",
    "\n",
    "    max_story_len=max(max_story_len_tr, max_story_len_te)\n",
    "    max_query_len=max(max_query_len_tr, max_query_len_te)\n",
    "\n",
    "    X_tr=pad_sequences(X_tr,max_story_len)\n",
    "    Q_tr=pad_sequences(Q_tr, max_query_len)\n",
    "    X_te=pad_sequences(X_te,max_story_len)\n",
    "    Q_te=pad_sequences(Q_te,max_query_len)\n",
    "\n",
    "    input = Input((max_story_len,))\n",
    "    question = Input((max_query_len,))\n",
    "\n",
    "    A= Embedding(input_dim=vocab_size,output_dim=64)\n",
    "    C=Embedding(input_dim=vocab_size, output_dim=max_query_len)\n",
    "    B=Embedding(input_dim=vocab_size,output_dim=64,input_length=max_query_len)\n",
    "\n",
    "    input_A = A(input)\n",
    "    input_C = C(input)\n",
    "    question_B = B(question)\n",
    "\n",
    "    input_question_match = dot([input_A, question_B], axes=(2, 2))\n",
    "    Probs = Activation('softmax')(input_question_match)\n",
    "\n",
    "    O = add([Probs, input_C])\n",
    "    O = Permute((2, 1))(O)\n",
    "\n",
    "    final_match = concatenate([O, question_B])\n",
    "\n",
    "    size=keras.backend.int_shape(final_match)[2]\n",
    "    weights = Dense(size, activation='softmax')(final_match)\n",
    "\n",
    "    merged=layers.multiply([final_match, weights])\n",
    "    answer=Flatten()(merged)\n",
    "\n",
    "    answer = Dense(vocab_size)(answer)\n",
    "    answer = Activation('softmax')(answer)\n",
    "\n",
    "    model = Model([input, question], answer)\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "\n",
    "    return X_tr,Q_tr,y_tr,X_te,Q_te,y_te,model\n",
    "\n",
    "create_model_nnm(train,test,context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_111 (InputLayer)          (None, 41)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_112 (InputLayer)          (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_80 (Embedding)        (None, 41, 64)       9472        input_111[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_82 (Embedding)        (None, 3, 64)        9472        input_112[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_13 (Dot)                    (None, 41, 3)        0           embedding_80[0][0]               \n",
      "                                                                 embedding_82[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 41, 3)        0           dot_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_81 (Embedding)        (None, 41, 3)        444         input_111[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 41, 3)        0           activation_16[0][0]              \n",
      "                                                                 embedding_81[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_13 (Permute)            (None, 3, 41)        0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 3, 105)       0           permute_13[0][0]                 \n",
      "                                                                 embedding_82[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 3, 105)       11130       concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 3, 105)       0           concatenate_56[0][0]             \n",
      "                                                                 dense_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 315)          0           multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 148)          46768       flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 148)          0           dense_58[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 77,286\n",
      "Trainable params: 77,286\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Training\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "9000/9000 [==============================] - 10s 1ms/step - loss: 4.0470 - acc: 0.1724 - val_loss: 2.9365 - val_acc: 0.1480\n",
      "Epoch 2/100\n",
      "9000/9000 [==============================] - 4s 478us/step - loss: 2.3298 - acc: 0.1670 - val_loss: 1.9548 - val_acc: 0.1540\n",
      "Epoch 3/100\n",
      "9000/9000 [==============================] - 4s 390us/step - loss: 1.8625 - acc: 0.1732 - val_loss: 1.8104 - val_acc: 0.1880\n",
      "Epoch 4/100\n",
      "9000/9000 [==============================] - 3s 358us/step - loss: 1.8001 - acc: 0.1787 - val_loss: 1.7937 - val_acc: 0.1890\n",
      "Epoch 5/100\n",
      "9000/9000 [==============================] - 3s 337us/step - loss: 1.7919 - acc: 0.1810 - val_loss: 1.7911 - val_acc: 0.1870\n",
      "Epoch 6/100\n",
      "9000/9000 [==============================] - 3s 375us/step - loss: 1.7893 - acc: 0.1830 - val_loss: 1.7917 - val_acc: 0.1800\n",
      "Epoch 7/100\n",
      "9000/9000 [==============================] - 4s 408us/step - loss: 1.7877 - acc: 0.1838 - val_loss: 1.7887 - val_acc: 0.1930\n",
      "Epoch 8/100\n",
      "9000/9000 [==============================] - 3s 344us/step - loss: 1.7856 - acc: 0.1860 - val_loss: 1.7879 - val_acc: 0.1960\n",
      "Epoch 9/100\n",
      "9000/9000 [==============================] - 3s 368us/step - loss: 1.7826 - acc: 0.1883 - val_loss: 1.7876 - val_acc: 0.1740\n",
      "Epoch 10/100\n",
      "9000/9000 [==============================] - 3s 374us/step - loss: 1.7790 - acc: 0.1918 - val_loss: 1.7835 - val_acc: 0.1990\n",
      "Epoch 11/100\n",
      "9000/9000 [==============================] - 4s 398us/step - loss: 1.7748 - acc: 0.1931 - val_loss: 1.7804 - val_acc: 0.1800\n",
      "Epoch 12/100\n",
      "9000/9000 [==============================] - 4s 433us/step - loss: 1.7697 - acc: 0.1987 - val_loss: 1.7786 - val_acc: 0.1750\n",
      "Epoch 13/100\n",
      "9000/9000 [==============================] - 4s 392us/step - loss: 1.7641 - acc: 0.2080 - val_loss: 1.7747 - val_acc: 0.1720\n",
      "Epoch 14/100\n",
      "9000/9000 [==============================] - 3s 377us/step - loss: 1.7582 - acc: 0.2033 - val_loss: 1.7694 - val_acc: 0.1780\n",
      "Epoch 15/100\n",
      "9000/9000 [==============================] - 3s 345us/step - loss: 1.7519 - acc: 0.2058 - val_loss: 1.7662 - val_acc: 0.1700\n",
      "Epoch 16/100\n",
      "9000/9000 [==============================] - 4s 412us/step - loss: 1.7464 - acc: 0.2054 - val_loss: 1.7625 - val_acc: 0.1740\n",
      "Epoch 17/100\n",
      "9000/9000 [==============================] - 3s 344us/step - loss: 1.7412 - acc: 0.2113 - val_loss: 1.7589 - val_acc: 0.1800\n",
      "Epoch 18/100\n",
      "9000/9000 [==============================] - 3s 352us/step - loss: 1.7369 - acc: 0.2072 - val_loss: 1.7559 - val_acc: 0.1730\n",
      "Epoch 19/100\n",
      "9000/9000 [==============================] - 3s 338us/step - loss: 1.7333 - acc: 0.2103 - val_loss: 1.7536 - val_acc: 0.1760\n",
      "Epoch 20/100\n",
      "9000/9000 [==============================] - 3s 354us/step - loss: 1.7296 - acc: 0.2131 - val_loss: 1.7511 - val_acc: 0.1660\n",
      "Epoch 21/100\n",
      "9000/9000 [==============================] - 3s 328us/step - loss: 1.7271 - acc: 0.2043 - val_loss: 1.7500 - val_acc: 0.1740\n",
      "Epoch 22/100\n",
      "9000/9000 [==============================] - 3s 323us/step - loss: 1.7245 - acc: 0.2111 - val_loss: 1.7487 - val_acc: 0.1620\n",
      "Epoch 23/100\n",
      "9000/9000 [==============================] - 3s 363us/step - loss: 1.7226 - acc: 0.2060 - val_loss: 1.7478 - val_acc: 0.1770\n",
      "Epoch 24/100\n",
      "9000/9000 [==============================] - 3s 350us/step - loss: 1.7208 - acc: 0.2087 - val_loss: 1.7454 - val_acc: 0.1650\n",
      "Epoch 25/100\n",
      "9000/9000 [==============================] - 3s 330us/step - loss: 1.7194 - acc: 0.2097 - val_loss: 1.7457 - val_acc: 0.1700\n",
      "Epoch 26/100\n",
      "9000/9000 [==============================] - 3s 352us/step - loss: 1.7183 - acc: 0.2086 - val_loss: 1.7451 - val_acc: 0.1800\n",
      "Epoch 27/100\n",
      "9000/9000 [==============================] - 3s 348us/step - loss: 1.7167 - acc: 0.2033 - val_loss: 1.7439 - val_acc: 0.1840\n",
      "Epoch 28/100\n",
      "9000/9000 [==============================] - 4s 416us/step - loss: 1.7089 - acc: 0.2159 - val_loss: 1.7365 - val_acc: 0.2270\n",
      "Epoch 29/100\n",
      "9000/9000 [==============================] - 3s 354us/step - loss: 1.6820 - acc: 0.2554 - val_loss: 1.6964 - val_acc: 0.2530\n",
      "Epoch 30/100\n",
      "9000/9000 [==============================] - 4s 468us/step - loss: 1.6372 - acc: 0.2977 - val_loss: 1.6468 - val_acc: 0.3090\n",
      "Epoch 31/100\n",
      "9000/9000 [==============================] - 4s 396us/step - loss: 1.5796 - acc: 0.3583 - val_loss: 1.5792 - val_acc: 0.3740\n",
      "Epoch 32/100\n",
      "9000/9000 [==============================] - 4s 498us/step - loss: 1.5109 - acc: 0.4103 - val_loss: 1.5025 - val_acc: 0.4190\n",
      "Epoch 33/100\n",
      "9000/9000 [==============================] - 4s 419us/step - loss: 1.4362 - acc: 0.4582 - val_loss: 1.4364 - val_acc: 0.4630\n",
      "Epoch 34/100\n",
      "9000/9000 [==============================] - 3s 334us/step - loss: 1.3615 - acc: 0.4988 - val_loss: 1.3497 - val_acc: 0.5170\n",
      "Epoch 35/100\n",
      "9000/9000 [==============================] - 3s 327us/step - loss: 1.2934 - acc: 0.5320 - val_loss: 1.3016 - val_acc: 0.4890\n",
      "Epoch 36/100\n",
      "9000/9000 [==============================] - 3s 372us/step - loss: 1.2327 - acc: 0.5607 - val_loss: 1.2270 - val_acc: 0.5330\n",
      "Epoch 37/100\n",
      "9000/9000 [==============================] - 4s 474us/step - loss: 1.1779 - acc: 0.5853 - val_loss: 1.1815 - val_acc: 0.5990\n",
      "Epoch 38/100\n",
      "9000/9000 [==============================] - 4s 412us/step - loss: 1.1270 - acc: 0.6002 - val_loss: 1.1278 - val_acc: 0.5980\n",
      "Epoch 39/100\n",
      "9000/9000 [==============================] - 3s 353us/step - loss: 1.0836 - acc: 0.6136 - val_loss: 1.0864 - val_acc: 0.6250\n",
      "Epoch 40/100\n",
      "9000/9000 [==============================] - 3s 342us/step - loss: 1.0421 - acc: 0.6274 - val_loss: 1.0330 - val_acc: 0.6290\n",
      "Epoch 41/100\n",
      "9000/9000 [==============================] - 3s 365us/step - loss: 1.0059 - acc: 0.6392 - val_loss: 1.0076 - val_acc: 0.6520\n",
      "Epoch 42/100\n",
      "9000/9000 [==============================] - 4s 453us/step - loss: 0.9717 - acc: 0.6499 - val_loss: 0.9662 - val_acc: 0.6720\n",
      "Epoch 43/100\n",
      "9000/9000 [==============================] - 4s 393us/step - loss: 0.9405 - acc: 0.6677 - val_loss: 0.9351 - val_acc: 0.6940\n",
      "Epoch 44/100\n",
      "9000/9000 [==============================] - 3s 386us/step - loss: 0.9113 - acc: 0.6767 - val_loss: 0.9114 - val_acc: 0.6880\n",
      "Epoch 45/100\n",
      "9000/9000 [==============================] - 5s 541us/step - loss: 0.8842 - acc: 0.6873 - val_loss: 0.8850 - val_acc: 0.6900\n",
      "Epoch 46/100\n",
      "9000/9000 [==============================] - 4s 480us/step - loss: 0.8573 - acc: 0.6946 - val_loss: 0.8584 - val_acc: 0.7240\n",
      "Epoch 47/100\n",
      "9000/9000 [==============================] - 4s 411us/step - loss: 0.8335 - acc: 0.7051 - val_loss: 0.8627 - val_acc: 0.6590\n",
      "Epoch 48/100\n",
      "9000/9000 [==============================] - 3s 386us/step - loss: 0.8090 - acc: 0.7121 - val_loss: 0.8314 - val_acc: 0.7020\n",
      "Epoch 49/100\n",
      "9000/9000 [==============================] - 3s 368us/step - loss: 0.7885 - acc: 0.7207 - val_loss: 0.8259 - val_acc: 0.7040\n",
      "Epoch 50/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.7675 - acc: 0.726 - 3s 352us/step - loss: 0.7683 - acc: 0.7253 - val_loss: 0.7963 - val_acc: 0.7090\n",
      "Epoch 51/100\n",
      "9000/9000 [==============================] - 3s 362us/step - loss: 0.7496 - acc: 0.7306 - val_loss: 0.7977 - val_acc: 0.7080\n",
      "Epoch 52/100\n",
      "9000/9000 [==============================] - 3s 327us/step - loss: 0.7329 - acc: 0.7366 - val_loss: 0.7895 - val_acc: 0.7070\n",
      "Epoch 53/100\n",
      "9000/9000 [==============================] - 3s 360us/step - loss: 0.7161 - acc: 0.7431 - val_loss: 0.7431 - val_acc: 0.7460\n",
      "Epoch 54/100\n",
      "9000/9000 [==============================] - 3s 325us/step - loss: 0.7001 - acc: 0.7501 - val_loss: 0.7415 - val_acc: 0.7430\n",
      "Epoch 55/100\n",
      "9000/9000 [==============================] - 4s 421us/step - loss: 0.6858 - acc: 0.7506 - val_loss: 0.7135 - val_acc: 0.7630\n",
      "Epoch 56/100\n",
      "9000/9000 [==============================] - 4s 490us/step - loss: 0.6704 - acc: 0.7537 - val_loss: 0.6993 - val_acc: 0.7730\n",
      "Epoch 57/100\n",
      "9000/9000 [==============================] - 3s 385us/step - loss: 0.6585 - acc: 0.7591 - val_loss: 0.7319 - val_acc: 0.7310\n",
      "Epoch 58/100\n",
      "9000/9000 [==============================] - 4s 497us/step - loss: 0.6458 - acc: 0.7617 - val_loss: 0.7034 - val_acc: 0.7560\n",
      "Epoch 59/100\n",
      "9000/9000 [==============================] - 6s 626us/step - loss: 0.6348 - acc: 0.7666 - val_loss: 0.7104 - val_acc: 0.7370\n",
      "Epoch 60/100\n",
      "9000/9000 [==============================] - 4s 410us/step - loss: 0.6239 - acc: 0.7620 - val_loss: 0.6559 - val_acc: 0.7740\n",
      "Epoch 61/100\n",
      "9000/9000 [==============================] - 4s 394us/step - loss: 0.6125 - acc: 0.7651 - val_loss: 0.6624 - val_acc: 0.7500\n",
      "Epoch 62/100\n",
      "9000/9000 [==============================] - 4s 456us/step - loss: 0.6021 - acc: 0.7701 - val_loss: 0.6436 - val_acc: 0.7800\n",
      "Epoch 63/100\n",
      "9000/9000 [==============================] - 3s 375us/step - loss: 0.5930 - acc: 0.7714 - val_loss: 0.6859 - val_acc: 0.7440\n",
      "Epoch 64/100\n",
      "9000/9000 [==============================] - 4s 423us/step - loss: 0.5841 - acc: 0.7790 - val_loss: 0.6393 - val_acc: 0.7570\n",
      "Epoch 65/100\n",
      "9000/9000 [==============================] - 4s 468us/step - loss: 0.5755 - acc: 0.7786 - val_loss: 0.6591 - val_acc: 0.7600\n",
      "Epoch 66/100\n",
      "9000/9000 [==============================] - 4s 466us/step - loss: 0.5671 - acc: 0.7767 - val_loss: 0.6165 - val_acc: 0.7800\n",
      "Epoch 67/100\n",
      "9000/9000 [==============================] - 4s 468us/step - loss: 0.5596 - acc: 0.7797 - val_loss: 0.6239 - val_acc: 0.7510\n",
      "Epoch 68/100\n",
      "9000/9000 [==============================] - 4s 421us/step - loss: 0.5514 - acc: 0.7807 - val_loss: 0.6687 - val_acc: 0.7370\n",
      "Epoch 69/100\n",
      "9000/9000 [==============================] - 4s 426us/step - loss: 0.5465 - acc: 0.7773 - val_loss: 0.6082 - val_acc: 0.7750\n",
      "Epoch 70/100\n",
      "9000/9000 [==============================] - 4s 437us/step - loss: 0.5396 - acc: 0.7844 - val_loss: 0.6091 - val_acc: 0.7520\n",
      "Epoch 71/100\n",
      "9000/9000 [==============================] - 6s 678us/step - loss: 0.5329 - acc: 0.7842 - val_loss: 0.5846 - val_acc: 0.8010\n",
      "Epoch 72/100\n",
      "9000/9000 [==============================] - 4s 418us/step - loss: 0.5260 - acc: 0.7863 - val_loss: 0.5839 - val_acc: 0.7840\n",
      "Epoch 73/100\n",
      "9000/9000 [==============================] - 4s 474us/step - loss: 0.5226 - acc: 0.7907 - val_loss: 0.5779 - val_acc: 0.774026\n",
      "Epoch 74/100\n",
      "9000/9000 [==============================] - 3s 342us/step - loss: 0.5171 - acc: 0.7879 - val_loss: 0.5824 - val_acc: 0.7800\n",
      "Epoch 75/100\n",
      "9000/9000 [==============================] - 4s 442us/step - loss: 0.5107 - acc: 0.7932 - val_loss: 0.5810 - val_acc: 0.7720\n",
      "Epoch 76/100\n",
      "9000/9000 [==============================] - 4s 422us/step - loss: 0.5073 - acc: 0.7962 - val_loss: 0.5641 - val_acc: 0.7750\n",
      "Epoch 77/100\n",
      "9000/9000 [==============================] - 4s 390us/step - loss: 0.5026 - acc: 0.7927 - val_loss: 0.5549 - val_acc: 0.7970\n",
      "Epoch 78/100\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 0.4995 - acc: 0.797 - 3s 384us/step - loss: 0.4990 - acc: 0.7980 - val_loss: 0.5588 - val_acc: 0.7950\n",
      "Epoch 79/100\n",
      "9000/9000 [==============================] - 5s 542us/step - loss: 0.4928 - acc: 0.7942 - val_loss: 0.5850 - val_acc: 0.7790\n",
      "Epoch 80/100\n",
      "9000/9000 [==============================] - 4s 435us/step - loss: 0.4902 - acc: 0.7967 - val_loss: 0.6086 - val_acc: 0.7570\n",
      "Epoch 81/100\n",
      "9000/9000 [==============================] - 3s 382us/step - loss: 0.4855 - acc: 0.8019 - val_loss: 0.5389 - val_acc: 0.8090\n",
      "Epoch 82/100\n",
      "9000/9000 [==============================] - 3s 315us/step - loss: 0.4824 - acc: 0.8022 - val_loss: 0.5489 - val_acc: 0.8020\n",
      "Epoch 83/100\n",
      "9000/9000 [==============================] - 3s 387us/step - loss: 0.4780 - acc: 0.8031 - val_loss: 0.5522 - val_acc: 0.7860\n",
      "Epoch 84/100\n",
      "9000/9000 [==============================] - 4s 421us/step - loss: 0.4733 - acc: 0.8084 - val_loss: 0.5931 - val_acc: 0.7590\n",
      "Epoch 85/100\n",
      "9000/9000 [==============================] - 5s 531us/step - loss: 0.4713 - acc: 0.8056 - val_loss: 0.5586 - val_acc: 0.7790\n",
      "Epoch 86/100\n",
      "9000/9000 [==============================] - 4s 488us/step - loss: 0.4685 - acc: 0.8064 - val_loss: 0.6495 - val_acc: 0.7020\n",
      "Epoch 87/100\n",
      "9000/9000 [==============================] - 4s 462us/step - loss: 0.4653 - acc: 0.8094 - val_loss: 0.5360 - val_acc: 0.7930\n",
      "Epoch 88/100\n",
      "9000/9000 [==============================] - 4s 425us/step - loss: 0.4620 - acc: 0.8136 - val_loss: 0.5553 - val_acc: 0.8040\n",
      "Epoch 89/100\n",
      "9000/9000 [==============================] - 4s 420us/step - loss: 0.4594 - acc: 0.8147 - val_loss: 0.5376 - val_acc: 0.8140\n",
      "Epoch 90/100\n",
      "9000/9000 [==============================] - 4s 399us/step - loss: 0.4572 - acc: 0.8122 - val_loss: 0.5330 - val_acc: 0.7900\n",
      "Epoch 91/100\n",
      "9000/9000 [==============================] - 4s 476us/step - loss: 0.4530 - acc: 0.8203 - val_loss: 0.5456 - val_acc: 0.7820\n",
      "Epoch 92/100\n",
      "9000/9000 [==============================] - 4s 424us/step - loss: 0.4531 - acc: 0.8136 - val_loss: 0.5118 - val_acc: 0.7950\n",
      "Epoch 93/100\n",
      "9000/9000 [==============================] - 3s 320us/step - loss: 0.4491 - acc: 0.8187 - val_loss: 0.5080 - val_acc: 0.8090\n",
      "Epoch 94/100\n",
      "9000/9000 [==============================] - 3s 371us/step - loss: 0.4471 - acc: 0.8234 - val_loss: 0.5060 - val_acc: 0.8030\n",
      "Epoch 95/100\n",
      "9000/9000 [==============================] - 4s 408us/step - loss: 0.4446 - acc: 0.8233 - val_loss: 0.5283 - val_acc: 0.7990\n",
      "Epoch 96/100\n",
      "9000/9000 [==============================] - 4s 411us/step - loss: 0.4432 - acc: 0.8216 - val_loss: 0.5509 - val_acc: 0.7780\n",
      "Epoch 97/100\n",
      "9000/9000 [==============================] - 3s 340us/step - loss: 0.4396 - acc: 0.8221 - val_loss: 0.5618 - val_acc: 0.7940\n",
      "Epoch 98/100\n",
      "9000/9000 [==============================] - 5s 547us/step - loss: 0.4375 - acc: 0.8229 - val_loss: 0.4940 - val_acc: 0.8120\n",
      "Epoch 99/100\n",
      "9000/9000 [==============================] - 3s 385us/step - loss: 0.4353 - acc: 0.8227 - val_loss: 0.5275 - val_acc: 0.7770\n",
      "Epoch 100/100\n",
      "9000/9000 [==============================] - 4s 393us/step - loss: 0.4333 - acc: 0.8249 - val_loss: 0.4917 - val_acc: 0.8210\n",
      "Evaluation\n",
      "1000/1000 [==============================] - 0s 282us/step\n",
      "Test loss / test accuracy = 0.4418 / 0.8200\n"
     ]
    }
   ],
   "source": [
    "#contet=8; 52 words; 100 iterations\n",
    "import os\n",
    "import sys\n",
    "train=os.path.realpath('C:/Users/nisht/Desktop/MITA/capstone_project/qa1_single-supporting-fact_train.txt')\n",
    "test=os.path.realpath('C:/Users/nisht/Desktop/MITA/capstone_project/qa1_single-supporting-fact_test.txt')\n",
    "context=6\n",
    "X_tr,Q_tr,y_tr,X_te,Q_te,y_te,model=create_model_nnm(train, test, context)\n",
    "print('Training')\n",
    "history=model.fit([X_tr, Q_tr], y_tr,batch_size=32,epochs=100, verbose=1,validation_split=0.1)\n",
    "print('Evaluation')\n",
    "loss, acc = model.evaluate([X_te,Q_te], y_te,batch_size=32)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_117 (InputLayer)          (None, 41)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_118 (InputLayer)          (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_85 (Embedding)        (None, 41, 64)       9472        input_117[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_87 (Embedding)        (None, 3, 64)        9472        input_118[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_14 (Dot)                    (None, 41, 3)        0           embedding_85[0][0]               \n",
      "                                                                 embedding_87[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 41, 3)        0           dot_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_86 (Embedding)        (None, 41, 3)        444         input_117[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 41, 3)        0           activation_18[0][0]              \n",
      "                                                                 embedding_86[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_14 (Permute)            (None, 3, 41)        0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 3, 105)       0           permute_14[0][0]                 \n",
      "                                                                 embedding_87[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 3, 105)       11130       concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 3, 105)       0           concatenate_59[0][0]             \n",
      "                                                                 dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 315)          0           multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 148)          46768       flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 148)          0           dense_62[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 77,286\n",
      "Trainable params: 77,286\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Training\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "9000/9000 [==============================] - 12s 1ms/step - loss: 2.1234 - acc: 0.1859 - val_loss: 1.7232 - val_acc: 0.2580\n",
      "Epoch 2/30\n",
      "9000/9000 [==============================] - 5s 560us/step - loss: 1.3813 - acc: 0.4001 - val_loss: 1.1098 - val_acc: 0.5540\n",
      "Epoch 3/30\n",
      "9000/9000 [==============================] - 5s 580us/step - loss: 0.8427 - acc: 0.7037 - val_loss: 0.6671 - val_acc: 0.7600\n",
      "Epoch 4/30\n",
      "9000/9000 [==============================] - 5s 502us/step - loss: 0.5518 - acc: 0.7957 - val_loss: 0.4751 - val_acc: 0.8320\n",
      "Epoch 5/30\n",
      "9000/9000 [==============================] - 5s 509us/step - loss: 0.4114 - acc: 0.8568 - val_loss: 0.3800 - val_acc: 0.8700\n",
      "Epoch 6/30\n",
      "9000/9000 [==============================] - 5s 511us/step - loss: 0.2458 - acc: 0.9581 - val_loss: 0.2450 - val_acc: 0.9620\n",
      "Epoch 7/30\n",
      "9000/9000 [==============================] - 5s 508us/step - loss: 0.1342 - acc: 0.9837 - val_loss: 0.1598 - val_acc: 0.9770\n",
      "Epoch 8/30\n",
      "9000/9000 [==============================] - 5s 507us/step - loss: 0.1520 - acc: 0.9653 - val_loss: 0.0895 - val_acc: 0.9930\n",
      "Epoch 9/30\n",
      "9000/9000 [==============================] - 5s 502us/step - loss: 0.0551 - acc: 0.9946 - val_loss: 0.0898 - val_acc: 0.9890\n",
      "Epoch 10/30\n",
      "9000/9000 [==============================] - 5s 512us/step - loss: 0.0857 - acc: 0.9807 - val_loss: 0.1071 - val_acc: 0.9870\n",
      "Epoch 11/30\n",
      "9000/9000 [==============================] - 5s 550us/step - loss: 0.0357 - acc: 0.9960 - val_loss: 0.1274 - val_acc: 0.9720\n",
      "Epoch 12/30\n",
      "9000/9000 [==============================] - 7s 782us/step - loss: 0.0754 - acc: 0.9801 - val_loss: 0.0840 - val_acc: 0.9920\n",
      "Epoch 13/30\n",
      "9000/9000 [==============================] - 6s 664us/step - loss: 0.0276 - acc: 0.9977 - val_loss: 0.0557 - val_acc: 0.9960\n",
      "Epoch 14/30\n",
      "9000/9000 [==============================] - 5s 550us/step - loss: 0.0209 - acc: 0.9981 - val_loss: 0.0531 - val_acc: 0.9960\n",
      "Epoch 15/30\n",
      "9000/9000 [==============================] - 4s 490us/step - loss: 0.0521 - acc: 0.9873 - val_loss: 0.0647 - val_acc: 0.9940\n",
      "Epoch 16/30\n",
      "9000/9000 [==============================] - 5s 535us/step - loss: 0.0328 - acc: 0.9932 - val_loss: 0.0693 - val_acc: 0.9890\n",
      "Epoch 17/30\n",
      "9000/9000 [==============================] - 4s 449us/step - loss: 0.0189 - acc: 0.9977 - val_loss: 0.0381 - val_acc: 0.9950\n",
      "Epoch 18/30\n",
      "9000/9000 [==============================] - 4s 491us/step - loss: 0.0944 - acc: 0.9738 - val_loss: 0.0704 - val_acc: 0.9870\n",
      "Epoch 19/30\n",
      "9000/9000 [==============================] - 4s 464us/step - loss: 0.0201 - acc: 0.9971 - val_loss: 0.0414 - val_acc: 0.9940\n",
      "Epoch 20/30\n",
      "9000/9000 [==============================] - 5s 573us/step - loss: 0.0124 - acc: 0.9984 - val_loss: 0.0876 - val_acc: 0.9870\n",
      "Epoch 21/30\n",
      "9000/9000 [==============================] - 5s 573us/step - loss: 0.0209 - acc: 0.9968 - val_loss: 0.0326 - val_acc: 0.9950\n",
      "Epoch 22/30\n",
      "9000/9000 [==============================] - 5s 587us/step - loss: 0.0099 - acc: 0.9992 - val_loss: 0.0257 - val_acc: 0.9960\n",
      "Epoch 23/30\n",
      "9000/9000 [==============================] - 5s 540us/step - loss: 0.1067 - acc: 0.9741 - val_loss: 0.0512 - val_acc: 0.9960\n",
      "Epoch 24/30\n",
      "9000/9000 [==============================] - 4s 488us/step - loss: 0.0149 - acc: 0.9984 - val_loss: 0.0363 - val_acc: 0.9960\n",
      "Epoch 25/30\n",
      "9000/9000 [==============================] - 4s 472us/step - loss: 0.0126 - acc: 0.9982 - val_loss: 0.0374 - val_acc: 0.9960\n",
      "Epoch 26/30\n",
      "9000/9000 [==============================] - 4s 486us/step - loss: 0.0115 - acc: 0.9986 - val_loss: 0.0346 - val_acc: 0.9960\n",
      "Epoch 27/30\n",
      "9000/9000 [==============================] - 5s 600us/step - loss: 0.0070 - acc: 0.9994 - val_loss: 0.0294 - val_acc: 0.9960\n",
      "Epoch 28/30\n",
      "9000/9000 [==============================] - 5s 529us/step - loss: 0.0236 - acc: 0.9940 - val_loss: 0.0404 - val_acc: 0.9950\n",
      "Epoch 29/30\n",
      "9000/9000 [==============================] - 5s 525us/step - loss: 0.0087 - acc: 0.9989 - val_loss: 0.0247 - val_acc: 0.9970\n",
      "Epoch 30/30\n",
      "9000/9000 [==============================] - 5s 561us/step - loss: 0.0059 - acc: 0.9992 - val_loss: 0.0169 - val_acc: 0.9950\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "9000/9000 [==============================] - 27s 3ms/step - loss: 2.1884 - acc: 0.1722 - val_loss: 1.7948 - val_acc: 0.1700\n",
      "Epoch 2/30\n",
      "9000/9000 [==============================] - 11s 1ms/step - loss: 1.8009 - acc: 0.1682 - val_loss: 1.7948 - val_acc: 0.1680\n",
      "Epoch 3/30\n",
      "9000/9000 [==============================] - 11s 1ms/step - loss: 1.7967 - acc: 0.1674 - val_loss: 1.8103 - val_acc: 0.1570\n",
      "Epoch 4/30\n",
      "9000/9000 [==============================] - 11s 1ms/step - loss: 1.7978 - acc: 0.1728 - val_loss: 1.7946 - val_acc: 0.1610\n",
      "Epoch 5/30\n",
      "9000/9000 [==============================] - 12s 1ms/step - loss: 1.7957 - acc: 0.1714 - val_loss: 1.7938 - val_acc: 0.1720\n",
      "Epoch 6/30\n",
      "9000/9000 [==============================] - 15s 2ms/step - loss: 1.7956 - acc: 0.1718 - val_loss: 1.7979 - val_acc: 0.1680\n",
      "Epoch 7/30\n",
      "9000/9000 [==============================] - 14s 2ms/step - loss: 1.7931 - acc: 0.1806 - val_loss: 1.7951 - val_acc: 0.1620\n",
      "Epoch 8/30\n",
      "9000/9000 [==============================] - 12s 1ms/step - loss: 1.7933 - acc: 0.1780 - val_loss: 1.7919 - val_acc: 0.1730\n",
      "Epoch 9/30\n",
      "9000/9000 [==============================] - 13s 1ms/step - loss: 1.7924 - acc: 0.1864 - val_loss: 1.7948 - val_acc: 0.1690\n",
      "Epoch 10/30\n",
      "9000/9000 [==============================] - 12s 1ms/step - loss: 1.7924 - acc: 0.1818 - val_loss: 1.8068 - val_acc: 0.1660\n",
      "Epoch 11/30\n",
      "9000/9000 [==============================] - 12s 1ms/step - loss: 1.7937 - acc: 0.1843 - val_loss: 1.7942 - val_acc: 0.1560\n",
      "Epoch 12/30\n",
      "9000/9000 [==============================] - 12s 1ms/step - loss: 1.7903 - acc: 0.1873 - val_loss: 1.7959 - val_acc: 0.1840\n",
      "Epoch 13/30\n",
      "9000/9000 [==============================] - 12s 1ms/step - loss: 1.7923 - acc: 0.1873 - val_loss: 1.7966 - val_acc: 0.1830\n",
      "Epoch 14/30\n",
      "9000/9000 [==============================] - 12s 1ms/step - loss: 1.7919 - acc: 0.1817 - val_loss: 1.7915 - val_acc: 0.1880\n",
      "Epoch 15/30\n",
      "9000/9000 [==============================] - 11s 1ms/step - loss: 1.7927 - acc: 0.1819 - val_loss: 1.7939 - val_acc: 0.1610\n",
      "Epoch 16/30\n",
      "9000/9000 [==============================] - 11s 1ms/step - loss: 1.7924 - acc: 0.1810 - val_loss: 1.7962 - val_acc: 0.1590\n",
      "Epoch 17/30\n",
      "9000/9000 [==============================] - 12s 1ms/step - loss: 1.7924 - acc: 0.1851 - val_loss: 1.8008 - val_acc: 0.1660\n",
      "Epoch 18/30\n",
      "9000/9000 [==============================] - 11s 1ms/step - loss: 1.7921 - acc: 0.1817 - val_loss: 1.7939 - val_acc: 0.1890\n",
      "Epoch 19/30\n",
      "9000/9000 [==============================] - 12s 1ms/step - loss: 1.7904 - acc: 0.1828 - val_loss: 1.7931 - val_acc: 0.1770\n",
      "Epoch 20/30\n",
      "9000/9000 [==============================] - 11s 1ms/step - loss: 1.7903 - acc: 0.1854 - val_loss: 1.7967 - val_acc: 0.1640\n",
      "Epoch 21/30\n",
      "9000/9000 [==============================] - 11s 1ms/step - loss: 1.7917 - acc: 0.1788 - val_loss: 1.7909 - val_acc: 0.1570\n",
      "Epoch 22/30\n",
      "9000/9000 [==============================] - 12s 1ms/step - loss: 1.7920 - acc: 0.1793 - val_loss: 1.7895 - val_acc: 0.1860\n",
      "Epoch 23/30\n",
      "9000/9000 [==============================] - 11s 1ms/step - loss: 1.7909 - acc: 0.1819 - val_loss: 1.7901 - val_acc: 0.1620\n",
      "Epoch 24/30\n",
      "9000/9000 [==============================] - 12s 1ms/step - loss: 1.7912 - acc: 0.1857 - val_loss: 1.7946 - val_acc: 0.1730\n",
      "Epoch 25/30\n",
      "9000/9000 [==============================] - 11s 1ms/step - loss: 1.7912 - acc: 0.1817 - val_loss: 1.7914 - val_acc: 0.1790\n",
      "Epoch 26/30\n",
      "9000/9000 [==============================] - 12s 1ms/step - loss: 1.7894 - acc: 0.1842 - val_loss: 1.7966 - val_acc: 0.1550\n",
      "Epoch 27/30\n",
      "9000/9000 [==============================] - 11s 1ms/step - loss: 1.7908 - acc: 0.1828 - val_loss: 1.8012 - val_acc: 0.1620\n",
      "Epoch 28/30\n",
      "9000/9000 [==============================] - 12s 1ms/step - loss: 1.7910 - acc: 0.1830 - val_loss: 1.7899 - val_acc: 0.1810\n",
      "Epoch 29/30\n",
      "9000/9000 [==============================] - 12s 1ms/step - loss: 1.7888 - acc: 0.1862 - val_loss: 1.7911 - val_acc: 0.1780\n",
      "Epoch 30/30\n",
      "9000/9000 [==============================] - 11s 1ms/step - loss: 1.4545 - acc: 0.3623 - val_loss: 0.7960 - val_acc: 0.6760\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "9000/9000 [==============================] - 9s 1ms/step - loss: 3.9943 - acc: 0.1651 - val_loss: 2.6540 - val_acc: 0.1850\n",
      "Epoch 2/30\n",
      "9000/9000 [==============================] - 3s 332us/step - loss: 2.1146 - acc: 0.1676 - val_loss: 1.8658 - val_acc: 0.1850\n",
      "Epoch 3/30\n",
      "9000/9000 [==============================] - 3s 353us/step - loss: 1.8204 - acc: 0.1638 - val_loss: 1.7978 - val_acc: 0.1830\n",
      "Epoch 4/30\n",
      "9000/9000 [==============================] - 3s 357us/step - loss: 1.7950 - acc: 0.1686 - val_loss: 1.7930 - val_acc: 0.1630\n",
      "Epoch 5/30\n",
      "9000/9000 [==============================] - 3s 344us/step - loss: 1.7930 - acc: 0.1638 - val_loss: 1.7917 - val_acc: 0.1680\n",
      "Epoch 6/30\n",
      "9000/9000 [==============================] - 3s 332us/step - loss: 1.7924 - acc: 0.1700 - val_loss: 1.7919 - val_acc: 0.1630\n",
      "Epoch 7/30\n",
      "9000/9000 [==============================] - 3s 334us/step - loss: 1.7925 - acc: 0.1684 - val_loss: 1.7907 - val_acc: 0.1830\n",
      "Epoch 8/30\n",
      "9000/9000 [==============================] - 3s 341us/step - loss: 1.7925 - acc: 0.1677 - val_loss: 1.7922 - val_acc: 0.1790\n",
      "Epoch 9/30\n",
      "9000/9000 [==============================] - 3s 337us/step - loss: 1.7925 - acc: 0.1683 - val_loss: 1.7919 - val_acc: 0.1760\n",
      "Epoch 10/30\n",
      "9000/9000 [==============================] - 3s 329us/step - loss: 1.7920 - acc: 0.1650 - val_loss: 1.7931 - val_acc: 0.1470\n",
      "Epoch 11/30\n",
      "9000/9000 [==============================] - 3s 353us/step - loss: 1.7924 - acc: 0.1686 - val_loss: 1.7916 - val_acc: 0.1830\n",
      "Epoch 12/30\n",
      "9000/9000 [==============================] - 3s 352us/step - loss: 1.7913 - acc: 0.1702 - val_loss: 1.7884 - val_acc: 0.2110\n",
      "Epoch 13/30\n",
      "9000/9000 [==============================] - 3s 332us/step - loss: 1.7821 - acc: 0.2006 - val_loss: 1.7732 - val_acc: 0.2370\n",
      "Epoch 14/30\n",
      "9000/9000 [==============================] - 3s 341us/step - loss: 1.7581 - acc: 0.2312 - val_loss: 1.7400 - val_acc: 0.2120\n",
      "Epoch 15/30\n",
      "9000/9000 [==============================] - 3s 365us/step - loss: 1.7200 - acc: 0.2471 - val_loss: 1.6917 - val_acc: 0.2610\n",
      "Epoch 16/30\n",
      "9000/9000 [==============================] - 3s 331us/step - loss: 1.6687 - acc: 0.2657 - val_loss: 1.6364 - val_acc: 0.2680\n",
      "Epoch 17/30\n",
      "9000/9000 [==============================] - 3s 331us/step - loss: 1.6033 - acc: 0.2833 - val_loss: 1.5571 - val_acc: 0.2890\n",
      "Epoch 18/30\n",
      "9000/9000 [==============================] - 3s 334us/step - loss: 1.5295 - acc: 0.2981 - val_loss: 1.4863 - val_acc: 0.2990\n",
      "Epoch 19/30\n",
      "9000/9000 [==============================] - 3s 356us/step - loss: 1.4650 - acc: 0.3150 - val_loss: 1.4390 - val_acc: 0.3150\n",
      "Epoch 20/30\n",
      "9000/9000 [==============================] - 3s 351us/step - loss: 1.4112 - acc: 0.3213 - val_loss: 1.3930 - val_acc: 0.3070\n",
      "Epoch 21/30\n",
      "9000/9000 [==============================] - 3s 347us/step - loss: 1.3715 - acc: 0.3301 - val_loss: 1.3578 - val_acc: 0.3310\n",
      "Epoch 22/30\n",
      "9000/9000 [==============================] - 4s 396us/step - loss: 1.3397 - acc: 0.3402 - val_loss: 1.3417 - val_acc: 0.3330\n",
      "Epoch 23/30\n",
      "9000/9000 [==============================] - 4s 489us/step - loss: 1.3132 - acc: 0.3469 - val_loss: 1.3043 - val_acc: 0.3670\n",
      "Epoch 24/30\n",
      "9000/9000 [==============================] - 4s 409us/step - loss: 1.2716 - acc: 0.3669 - val_loss: 1.2551 - val_acc: 0.3810\n",
      "Epoch 25/30\n",
      "9000/9000 [==============================] - 4s 415us/step - loss: 1.2364 - acc: 0.4156 - val_loss: 1.2249 - val_acc: 0.4520\n",
      "Epoch 26/30\n",
      "9000/9000 [==============================] - 4s 396us/step - loss: 1.2003 - acc: 0.4511 - val_loss: 1.1983 - val_acc: 0.4460\n",
      "Epoch 27/30\n",
      "9000/9000 [==============================] - 3s 368us/step - loss: 1.1562 - acc: 0.4957 - val_loss: 1.1465 - val_acc: 0.5000\n",
      "Epoch 28/30\n",
      "9000/9000 [==============================] - 4s 408us/step - loss: 1.1020 - acc: 0.5504 - val_loss: 1.0927 - val_acc: 0.5520\n",
      "Epoch 29/30\n",
      "9000/9000 [==============================] - 3s 385us/step - loss: 1.0291 - acc: 0.5783 - val_loss: 1.0120 - val_acc: 0.5680\n",
      "Epoch 30/30\n",
      "9000/9000 [==============================] - 3s 363us/step - loss: 0.9144 - acc: 0.6273 - val_loss: 0.8929 - val_acc: 0.6250\n",
      "Evaluation for SImpleRNN\n",
      "1000/1000 [==============================] - 0s 205us/step\n",
      "Test loss / test accuracy = 0.0030 / 0.9990\n",
      "Evaluation for LSTM\n",
      "1000/1000 [==============================] - 0s 315us/step\n",
      "Test loss / test accuracy = 0.7953 / 0.6910\n",
      "Evaluation for E-E-Memory\n",
      "1000/1000 [==============================] - 0s 165us/step\n",
      "Test loss / test accuracy = 0.8672 / 0.6340\n"
     ]
    }
   ],
   "source": [
    "#contet=8; 52 words; 100 iterations\n",
    "import os\n",
    "import sys\n",
    "train=os.path.realpath('C:/Users/nisht/Desktop/MITA/capstone_project/qa1_single-supporting-fact_train.txt')\n",
    "test=os.path.realpath('C:/Users/nisht/Desktop/MITA/capstone_project/qa1_single-supporting-fact_test.txt')\n",
    "context=-1\n",
    "X_tr,Q_tr,y_tr,X_te,Q_te,y_te,model1=create_model(train, test, context)\n",
    "X_tr,Q_tr,y_tr,X_te,Q_te,y_te,model2=create_model_lstm(train, test, context)\n",
    "X_tr,Q_tr,y_tr,X_te,Q_te,y_te,model3=create_model_nnm(train, test, context)\n",
    "print('Training')\n",
    "history1=model1.fit([X_tr, Q_tr], y_tr,batch_size=32,epochs=30, verbose=1,validation_split=0.1, shuffle=False)\n",
    "history2=model2.fit([X_tr, Q_tr], y_tr,batch_size=32,epochs=30, verbose=1,validation_split=0.1, shuffle=False)\n",
    "history3=model3.fit([X_tr, Q_tr], y_tr,batch_size=32,epochs=30, verbose=1,validation_split=0.1, shuffle=False)\n",
    "print('Evaluation for SImpleRNN')\n",
    "loss1, acc1 = model1.evaluate([X_te,Q_te], y_te,batch_size=32)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss1, acc1))\n",
    "\n",
    "print('Evaluation for LSTM')\n",
    "loss2, acc2 = model2.evaluate([X_te,Q_te], y_te,batch_size=32)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss2, acc2))\n",
    "\n",
    "print('Evaluation for E-E-Memory')\n",
    "loss3, acc3 = model3.evaluate([X_te,Q_te], y_te,batch_size=32)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss3, acc3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8FWX2+PHPSU+AAEmQFpo0QcEgRSlfxYIFAcvaQLDgrmXtq6uuuhbU73d31Z+oi7urgrA2RHdXWQtFlyyCKKGJgJIgJYSWkAAJKaSd3x9zc0nCTSHkZnKT8+Y1rzvtzpyZCXPuPM/MM6KqGGOMMQBBbgdgjDGm8bCkYIwxxsuSgjHGGC9LCsYYY7wsKRhjjPGypGCMMcbLkoIxjZCIHBaRk+t73hOMabSIpPl7PcZdlhRMjUQkUUQOiEi427E0dvV14lTVlqq6tb7nbSgicpOILHM7DnP8LCmYaolId+B/AAUmNPC6QxpyfQ2lqW6XaRosKZia3AB8C8wGbiw/QUQiReRFEdkhIodEZJmIRHqmjRKRb0TkoIjsFJGbPOMTReSX5ZZR4ReliKiI3CkiKUCKZ9zLnmVki8hqEfmfcvMHi8ijIvKziOR4pncRkRki8mKleP8tIvf52kgRGSEiSZ7tSBKREeWmJYrIMyKy3LOORSIS52MZLYAvgE6eIp3DItJJRJ4SkY9E5B0RyQZuEpFhIrLCs3/2iMifRSSs0n7o5emf7dmezzzr/05EetZx3gtFZLNnO18Tkf+WPx4+ju9sz1XiJmBopemPlNvvm0TkCs/4fsBfgeGefXDQM/5SEVnrOY47ReQpX+s1LlNV66yrsgO2AL8GBgNFQPty02YAiUBnIBgYAYQDXYEcYCIQCsQCCZ7vJAK/LLeMm4Bl5YYVWAzEAJGecZM9ywgBHgD2AhGeab8FfgD6AgKc7pl3GLAbCPLMFwfklY+/3DpjgAPAFM86JnqGY8vF/DPQB4j0DP+hiv01GkirNO4pz767HOeHWKRnf57lWV934Efgvkr7oZenfzaQ5dmmEOBdYO7xzuvZB9nAlZ5p93ri+mUV2/IH4GvP/ukCbCi/bcDVQCfPNl0L5AIdfR3XcvtmgGf+gcA+4HK3/8atq3Tc3Q7AusbbAaM8J404z/BPwP2e/iAgHzjdx/d+B/yrimUmUnNSOK+GuA6UrRfYDFxWxXw/AmM8/XcBn1cx3xRgZaVxK4CbysX8eLlpvwYWVLGsqpLC0hq26b7y+8zHif7NctPGAj8d77w4V30ryk0TYGc1SWErcHG54Vsrb1ul+deVHQtfScHH/NOBl9z+O7euYmfFR6Y6NwKLVHW/Z/g9jhYhxQEROL+gK+tSxfja2ll+QEQeEJEfPUUeB4HWnvXXtK45OFcZeD7frmK+TsCOSuN24FwBldlbrj8PaFntFhyr8jb1EZFPRWSvp0jpfzm6Tb4cz/qrmrdT+TjUOTNXVyleYX4q7SMRuUFE1nmKwA4Cp1HNNojImSKyREQyROQQcHt18xt3WFIwPnnqBq4BzvGcuPYC9wOni8jpwH6gAOjp4+s7qxgPThFDVLnhDj7m8Tbd66k/eNgTS1tVbQMcwvmVW9O63gEu88TbD/i4ivl2A90qjesK7Kpi/upU1exw5fF/wbny6q2q0cCjHN0mf9kDxJcNiIiUH65i/i7lhruW+2434A2cK7BYz3HZwNFt8LUf3gPmA11UtTVOvYO/t9kcJ0sKpiqXAyVAfyDB0/XDKWO+QVVLgVnA//NUpgaLyHBxblt9F7hARK4RkRARiRWRBM9y1wFXikiUp3L0lhriaAUUAxlAiIg8AUSXm/4m8IyI9BbHQBGJBVDVNCAJ5wrhH6qaX8U6Pgf6iMgkT7zXerb709rurHL2AbEi0roW25UNHBaRU4A76rCu4/UZMEBELhfnDqg78Z2Uy8wDficibUUkHri73LQWOCf+DAARuRnnSqHMPiC+fOU5zjZnqWqBiAwDJp3wFpl6Z0nBVOVG4C1VTVXVvWUd8Gfges9J5UGcSt4knMrNP+JU7KbilGU/4Bm/DqcCGOAloBDnpDEHJ4FUZyHOHT3JOMUXBVQs0vh/OCevRTgn2Zk4Fbll5uBUblZVdISqZgLjPPFmAg8B48oVm9Waqv4EvA9s9RSrdKpi1gdxToo5OL+4PzjeddUhtv04lcN/wtnO/sAq4EgVX3kaZ59vw9m/3n2oqpuAF3HqXvbh7OPl5b77H2AjsFdEyvbjr4FpIpIDPIFz3EwjI54KH2OaJBE5G6cYqbvn6sZ4iEgQTp3C9aq6xO14TONgVwqmyRKRUJzbLt+0hOAQkYtEpI2nmK+sHuNbl8MyjYglBdMkeR6gOgh0xLn10TiG49yttR8Yj/OcQFV1LaYZsuIjY4wxXnalYIwxxivgGuaKi4vT7t27ux2GMcYElNWrV+9X1XY1zRdwSaF79+6sWrXK7TCMMSagiEjlp/Z9suIjY4wxXpYUjDHGeFlSMMYY42VJwRhjjJclBWOMMV5+SwoiMktE0kVkQxXTRUReEZEtIrJeRM7wVyzGGGNqx59XCrOBi6uZfgnQ29PditO+vDHGGBf57TkFVV0qIt2rmeUy4O+etz9962mkq6Oq7vFXTKYZUoWMDCguhpISKC31/VlS4szbqxe0PN6XqtWDI0ec9UdE1P+yVaGoCAoKjnZHjlTsP3IEQkMhKgoiI53P8v0hPk4VJSVw+DAcOgTZ2cd2eXlw6aXQs6p3INXBmjWQmQkiEBTkfJZ1lYdFnONbVad69PgXFzv7qLDQ+fTVFRY6x6drV+jeHbp1g44dnfUej9JS528yLc3psrKqj7N8N2YMJCTUvI4T4ObDa52p2C5+mmfcMUlBRG7FuZqga9eulScbN+zfD99/D8OHOyeNE7VlC3zwAWzfDpdfDhde6Jyk6io9HWbPhjffhJSU2n8vOBgGD4azz4ZzzoGRI6Ft27rHUVgIe/Y43e7dTlfWX35cZia0aAEPPggPPACtWtV9nQAbN8Lvfw8LFkB+PbR3FxJyNFGIQE6OkxBq8tvfwj33wGOPQZs2dV//unXw0EOweHHdl+EPoaFOkujW7Wii6NYN4uOdxJiWBjt3Hk0AaWmwa5fzd1EXf/mL35OCXxvE81wpfKqqp/mY9hnwf6q6zDP8FfCQqq6ubplDhgxRe6LZRaowdy7cfbdzIouMdE7gV1wB48ZBbGztl5WWBvPmwfvvQ9kxbdXKOeHExcF118HkyTBsmHMiqklpKXz5JbzxBnz8sfPrb9QouPJK52QWHOz8qgsO9t1fWuqcfJYuhe++c/7jisDAgU6SKOtOOqni/sjIgK1bfXdpac485QUHQ4cO0KmT03Xs6Hx+/z384x/Qrh088QTceiuEhXFctm2DJ5+Ed95x9uWUKc4xCQ93fuVGRPjuDwtz9ldentPl51fdX1IC0dFHu9atKw6XdUVF8OyzTnKOjYWnn3a2yddVR1VSU53k9vbbTnJ+/HEYOtTZp2Vd2a9+X8Nlx7Z8V3ZVUX44NPTYLizs2HH5+bBjh9Nt335s/x4fBR1hYU6SiI+HLl2O9pd1cXG+4/TVlcVUByKyWlWH1DijqvqtA7oDG6qY9jdgYrnhzUDHmpY5ePBgNS7ZvVv1ssuc/27DhqnOm6d6112q8fHOuKAg1dGjVadPV922zfcy0tNVX3tN9eyzVUWc7w0erPr886qpqapHjqjOn696zTWqERHO9J49VZ98UjU52fcyd+1SfeYZ1e7dnfljY1Xvv19106a6b2t+vup//6s6bZrqBReoRkUdPe2ccorquHGqAweqtmxZ/nTkdB07qo4cqTpliuoTT6i+8YbqZ5+prlmjunevanFx1ev99lvVc85xlnPyyarvv69aUlJzvLt3q955p2poqLPffvtb1f3767799Wn16qPb1L+/6hdf1PydAwdUH3pINTzc6R5+2BnX2OXnO3+n//mPc7zT01VLS92OSlVVgVVam/N2bWaqa1dDUrgU5zWLApwFrKzNMi0pHKcjR1RfeEH1qqtUP/xQtbDw+JdRWqo6e7ZqmzbOCef55yue2EpLVZOSVB97TPXUU4+eHBMSVJ96SnXlSuf7F12kGhzsTOvXzznhbt5c9XoPHVJ96y3V888/mkCGDVN95RXnJPjpp6oTJhxd5nnnOSfRgoLj38aaFBY6J+w//clJCAMGqI4fr3rvvaovv6z673+rbtyompt74usqLVX9/HMn6YDqoEGqixb5njcrS/WRR1QjI1VDQlRvv101Le3EY6hvpaWq//qXk+BB9eKLnf1VWUGB6ksvqcbEOMf8hhtUd+xo+HibINeTAs57avcARTj1BbcAtwO3e6YLMAPnhR8/AENqs1xLCrVUWur84u7VyznMMTFHf8U++WTtTxw7d6qOHet8d9So6k/iZZKTncQxcuTRkzk4v+QfeUT1+++P/9dTWpqzzISEir/KTzrJ+RWZknJ8ywsEJSWqb7+t2q2bs60XXKC6apUz7fBh1eeeU23d2tnHkyYFxj44ckT1xReduIODVX/9a9WMDOfvYe5c1R49nG0dM0Z17Vq3o21SXE8K/uosKdTChg3Of6qyoo4vvnB+2f/7384JXsT5D3nllapffun7BF1aqvr666rR0U7Rycsv164Yo7K9e50T24oV9XcZ/cMPqs8+q/rRR85Jpqkr+/UcG+sc0/HjVdu3P9r//fduR3j8MjKc4q7gYCdBlCX7gQNVFy50O7omyZJCc5SZ6ZTxBwc7RT0vv+y7uOjnn53y2rKTTN++Tj1AWZnttm3Or1JQPfdcZ37jvoMHVR9/XLVVK6eMfvlytyM6cRs3ql56qfPjZfbs6utbzAmpbVIIuNdx2t1HPhQXw1//6tyxcugQ3H67c6dHXFz13ysogA8/dG5zW7HCuZNo3Dj4/HPnTofnn4df/er478M2xjQ6tb37yP63B7rFi+H0051bRAcNcm6pnDGj5oQAzq2IU6bAN984DwVNnuzc1/4//wMbNsBtt1lCMKaZsSuFQKUK11/v3ON/8snw4otw2WW1u5+/puWe6DKMMY2OXSk0df/5j5MQHngANm1yngKuj5O5JQRjmjVLCoFq+nTnyddnn3WeSjXGmHpgSSEQpaTAp5/CHXf4pwE1Y0yzZUkhEL3yitMGyh13uB2JMaaJsaQQaA4ehLfegokTnUbVjDGmHllSCDQzZ0JuLtx7r9uRGGOaIEsKgaS4GF591Wnnf9Agt6MxxjRBlhQCySefOG2233ef25EYY5ooSwqB5KWXoEcPGD/e7UiMMU2UJYVAkZQEy5c7rzYMDnY7GmNME2VJIVC8/LLzesWpU92OxBjThFlSCAS7dzsvtZ861Xn3rTHG+IklhUDw2mvOy9LvvtvtSIwxTZwlhcYuP995V8Jll0HPnm5HY4xp4iwpNHbvvguZmXYbqjGmQVhSaMxUndZQExLg7LPdjsYY0wyEuB2AqcZXX8HGjTB7tr3nwBjTIOxKoTGbPh1OOgmuu87tSIwxzYQlhcYqORk++wx+/Wt7iY4xpsFYUmisyt6ZcPvtbkdijGlGLCk0RgcOOO9MmDQJ2rd3OxpjTDNiSaExmjkT8vLsnQnGmAZnSaGxKXtnwujRzq2oxhjTgOyW1MZm3jxITXUSgzHGNDC7UmhMdu1ymsYeNAguvdTtaIwxzZAlhcaipASmTHHaOnr/fXtngjHGFVZ81Fj88Y+wZAnMmgV9+7odjTGmmbIrhcbg22/hiSecJ5dvusntaIwxzZglBbcdOgQTJ0KXLk4T2dbGkTHGRVZ85CZVuO022LkTli2D1q3djsgY08xZUnDT7NnOazb/93/hrLPcjsYYY6z4yDWbN8Ndd8F558FDD7kdjTHGAJYU3HHkiFOpHBkJb79tt58aYxoNKz5ywyOPwLp1MH8+dOrkdjTGGOPl1ysFEblYRDaLyBYRecTH9K4iskRE1orIehEZ6894GoXPPnNennP33TB+vNvRGGNMBX5LCiISDMwALgH6AxNFpH+l2R4H5qnqIOA64DV/xdMo7NnjPIcwcCD86U9uR2OMMcfw55XCMGCLqm5V1UJgLnBZpXkUiPb0twZ2+zEed5WWOs1Y5ObC3LkQEeF2RMYYcwx/1il0BnaWG04Dzqw0z1PAIhG5G2gBXOBrQSJyK3ArQNeuXes90Abx/PPw1VfwxhvQr5/b0RhjjE/+vFLw9WiuVhqeCMxW1XhgLPC2iBwTk6q+rqpDVHVIu3bt/BCqn6WlOc1YXHUV3HKL29EYY0yV/JkU0oAu5YbjObZ46BZgHoCqrgAigDg/xuSOF15wio+ef96asTDGNGr+TApJQG8R6SEiYTgVyfMrzZMKnA8gIv1wkkKGH2NqeOnp8PrrMHkydO/udjTGGFMtvyUFVS0G7gIWAj/i3GW0UUSmicgEz2wPAL8Ske+B94GbVLVyEVNge+klKCiA3/3O7UiMMaZGEmjn4CFDhuiqVavcDqN2DhyAbt1g7FjnjiNjjHGJiKxW1SE1zWfNXPjTq69CTg48+qjbkRhjTK1YUvCXnBx4+WWYMMF5WM0YYwKAJQV/+etfISsLHnvM7UiMMabWLCn4Q34+vPgijBkDw4a5HY0xxtSaJQV/mDkT9u2Dxx93OxJjjDkulhTqW2Gh09jdqFFw9tluR2OMMcfF3qdQ395+23nn8htvuB2JMcYcN7tSqE/FxfCHP8DgwXDhhW5HY4wxx82uFOrTvHmwZQv861/WxpExJiDZlUJ9KS2F//1fOPVU59kEY4wJQHalUF8++QQ2boT33oMgy7XGmMBkZ6/6oArPPQe9esE117gdjTHG1JldKdSHhQth9Wp4800IDnY7GmOMqTO7UjhRqvDss9Cli/MOZmOMCWB2pXCili6F5cudFlHDwtyOxhhjTohdKZyo556D9u3t3cvGmCbBksKJSEqCxYvhgQcgMtLtaIwx5oRZUjgRn3wCISFw++1uR2KMMfXCksKJSE6GHj2gVSu3IzHGmHphSeFEJCdDnz5uR2GMMfXGkkJdqTrtHPXu7XYkxhhTbywp1NWePZCba0nBGNOk2HMKdZWc7Hxa8ZFfFBUVkZaWRkFBgduhNGkRERHEx8cTGhrqdiimkbCkUFcpKc6nXSn4RVpaGq1ataJ79+6INUPuF6pKZmYmaWlp9OjRw+1wTCNhxUd1lZwM4eFO8xam3hUUFBAbG2sJwY9EhNjYWLsaMxVYUqirlBSnVVRrJttvLCH4n+1jU5md0eoqJcXqE4wxTY4lhbooKbHbUZuB5557jlNPPZWBAweSkJDAd999xy9/+Us2bdpUL8tv2bJljfMEBweTkJDAaaedxvjx4zl48CAA27dvR0R49dVXvfPeddddzJ49G4CbbrqJzp07c+TIEQD2799P9+7d6yVu07RZUqiLnTuhsNCSQhO2YsUKPv30U9asWcP69ev58ssv6dKlC2+++Sb9+/dvsDgiIyNZt24dGzZsICYmhhkzZninnXTSSbz88ssUFhb6/G5wcDCzZs1qqFBNE2FJoS7sdtQmb8+ePcTFxREeHg5AXFwcnTp1YvTo0axatQpwfuk//PDDDB48mAsuuICVK1cyevRoTj75ZObPnw/A7Nmzueyyy7j44ovp27cvTz/9tM/1Pf/88wwdOpSBAwfy5JNP+pxn+PDh7Nq1yzvcrl07zj//fObMmeNz/vvuu4+XXnqJ4uLiOu8H0/zYLal1YbejNqz77oN16+p3mQkJMH16lZMvvPBCpk2bRp8+fbjgggu49tprOeeccyrMk5uby+jRo/njH//IFVdcweOPP87ixYvZtGkTN954IxMmTABg5cqVbNiwgaioKIYOHcqll17KkCFDvMtZtGgRKSkprFy5ElVlwoQJLF26lLPPPts7T0lJCV999RW3VGqi/ZFHHuGSSy5h6tSpx2xD165dGTVqFG+//Tbjx4+v024yzY9dKdRFcjK0bAkdOrgdifGTli1bsnr1al5//XXatWvHtdde6y2vLxMWFsbFF18MwIABAzjnnHMIDQ1lwIABbN++3TvfmDFjiI2NJTIykiuvvJJly5ZVWM6iRYtYtGgRgwYN4owzzuCnn34ixfPDIz8/n4SEBGJjY8nKymLMmDEVvtujRw+GDRvGe++953M7Hn30UZ5//nlKS0tPcI+Y5sKuFOoiJcW5SrDb+RpGNb/o/Sk4OJjRo0czevRoBgwYcEwxTWhoqPeWzqCgIG9RU1BQUIUim8q3fVYeVlV+97vfcdtttx0TQ1mdwqFDhxg3bhwzZszgnnvuqTDPo48+ylVXXVXhyqJMr169SEhIYN68ecex5aY5syuFuihLCqbJ2rx5s/fXOsC6devo1q1bnZa1ePFisrKyyM/P5+OPP2bkyJEVpl900UXMmjWLw4cPA7Br1y7S09MrzNO6dWteeeUVXnjhBYqKiipMO+WUU+jfvz+ffvqpz/U/9thjvPDCC3WK3TQ/lhSOV1ERbNtmlcxN3OHDh7nxxhvp378/AwcOZNOmTTz11FN1WtaoUaOYMmUKCQkJ/OIXv6hQnwBO/cWkSZMYPnw4AwYM4KqrriInJ+eY5QwaNIjTTz+duXPnHjPtscceIy0tzef6Tz31VM4444w6xW4ah1It5dGvHmVX9q6aZz5Boqp+X0l9GjJkiJbd/eGK5GTo2xfmzIEbbnAvjibuxx9/pF+/fm6HccJmz57NqlWr+POf/+x2KFVqKvu6qVJV7l1wL6+ufJXXxr7GHUPvqNNyRGS1qg6paT67UjhedjuqMaYB/WHZH3h15as8MPyBOieE42EVzcfLbkc1x+Gmm27ipptucjsME6BmrpnJo/95lMkDJ/OnMX9qkHXW6kpBRHqKSLinf7SI3CMibfwbWiOVnAxt20JsrNuRGGOasPmb53Prp7dyUc+LmDVhFkHSMAU7tV3LP4ASEekFzAR6AL5vjC5HRC4Wkc0iskVEHqlinmtEZJOIbBSRGpfpOmsIzxjjZ8tTl3PtR9cyuONgPrrmI0KDG+4lSLUtPipV1WIRuQKYrqqvisja6r4gIsHADGAMkAYkich8Vd1Ubp7ewO+Akap6QEROqttmNKCUFPBxP7gxxtSHjekbGff+OLq27spnkz6jZVjNDSfWp9peKRSJyETgRqDsZuiaUtcwYIuqblXVQmAucFmleX4FzFDVAwCqmk5jlp8Pqal2pWCM8YvUQ6lc9M5FRIZEsnDyQtq1aNfgMdQ2KdwMDAeeU9VtItIDeKeG73QGdpYbTvOMK68P0EdElovItyJysa8FicitIrJKRFZlZGTUMmQ/+Pln59MqmZsFX01bb968mdGjR5OQkEC/fv249dZbWbhwIQkJCSQkJNCyZUv69u1LQkICN9xwA4mJiYgIM2fO9C5j7dq1iIg9UGYqyMzL5KJ3LuJw4WEWTF5A9zbdXYmjVsVHniKfewBEpC3QSlX/UMPXfLUBUfmhiBCgNzAaiAe+FpHTVPVgpfW/DrwOznMKtYnZL+x21Gbvnnvu4f777+eyy5yL3h9++IEBAwZw0UUXATB69GheeOEF7wNqiYmJDBgwgA8++MDbmN3cuXM5/fTT3dkA0yjlFuYy7v1xbDuwjYWTFzKw/UDXYqnt3UeJIhItIjHA98BbIvL/avhaGlD+BcbxwG4f83yiqkWqug3YjJMkGie7HbXZ27NnD/Hx8d7hAQMG1Pidrl27UlBQwL59+1BVFixYwCWXXOLPME0AKSop4tqPrmXlrpW894v3OKf7OTV/yY9qW9HcWlWzReSXwFuq+qSIrK/hO0lAb09R0y7gOmBSpXk+BiYCs0UkDqc4aWvtw29gKSnQvj20auV2JM3Kfffdx7p6bjo7ISGB6XVoaO/+++/nvPPOY8SIEVx44YXcfPPNtGlT893ZV111FR9++KG3JdSyxvNM86aq/Orfv+KzlM/466V/5cp+V7odUq3rFEJEpCNwDUcrmqulqsXAXcBC4EdgnqpuFJFpIjLBM9tCIFNENgFLgN+qauZxbUFDSk62oqNm7uabb+bHH3/k6quvJjExkbPOOsv7ysvqXHPNNXz44Ye8//77TJw4sQEiNY1dZl4mU/41hTnfz+Gpc57itiHHtpLrhtpeKUzDOYEvV9UkETkZSKnhO6jq58DnlcY9Ua5fgd94usYvJQXGjnU7imanLr/o/alTp05MnTqVqVOnctppp7FhwwYGDx5c7Xc6dOhAaGgoixcv5uWXX+abb75poGhNY6OqvLP+HX6z6DccyD/Ak+c8yRPnPFHzFxtIbSuaPwQ+LDe8FfiFv4JqlLKzYe9eu1Jo5hYsWMD5559PaGgoe/fuJTMzk86dK99U59u0adNIT08nODjYz1GaxmpL1hZu//R2vtr2FWd2PpPXb3jd1UplX2qVFEQkHngVGIlzB9Ey4F5V9d1Wb1O0ZYvzaZXMzUZeXl6FSuXf/OY3pKWlce+99xIREQE471buUMs38I0YMcIvcZrGr7CkkBe+eYFnlj5DWHAYM8bO4LbBtxEc1Ph+INSq6WwRWYzTrMXbnlGTgetVdUzV3/IP15rOnjsXJk6E9euhFnecmBNjzTk3HNvX/rU8dTm3fXobGzM28ot+v+CVS16hU6tODR5HfTed3U5V31LVYk83G2j4R+3cVHY7aq9e7sZhjAkIBwsOcvuntzPqrVFkH8lm/nXz+eiaj1xJCMejthXN+0VkMvC+Z3gi0HjvEvKHlBTo0gUiI92OxBjTyH206SPu/uJu0nPTuf+s+5l27rQGb8OormqbFKYCfwZewqlT+Aan6Yvmw25HNcbUwvs/vM+kf07ijI5n8OnETxncqfo70xqbWhUfqWqqqk5Q1XaqepKqXg64/5RFQ0pJsUpmY0y11u5Zyy3zb2FU11GsuGVFwCUEOLHXcQbGswX1ITMTsrIsKRhjqpSem87lH1xObFQsH139EWHBYW6HVCcn8jpOXw3eNU1llcxWfGSM8aGopIirP7ya9Nx0lt28jPYt27sdUp2dyJWCe62VNjRrCK9ZEhEeeOAB7/ALL7zAU089BcBTTz1FVFQU6elHXwFSvqltEWHKlCne4eLiYtq1a8e4ceP8H7im9E9QAAAfvklEQVRpcPctuI+lO5by5vg3A7LIqLxqk4KI5IhIto8uB2jc91XVp+RkCA6GHj3cjsQ0oPDwcP75z3+yf/9+n9Pj4uJ48cUXfU5r0aIFGzZsID8/H4DFixfX+slnE1jeWP0Gr616jQeHP8j1A693O5wTVm1SUNVWqhrto2ulqidS9BRYUlKge3cIC8wyQlM3ISEh3Hrrrbz00ks+p0+dOpUPPviArKwsn9MvueQSPvvsMwBrCK+JWp66nDs/v5MLe17IHy6o6RUzgaH5nNhPhN2O6qr7FtzHur313HR2hwSmX1xzQ3t33nknAwcO5KGHHjpmWsuWLZk6dSovv/wyTz/99DHTr7vuOqZNm8a4ceNYv349U6dO5euvv66X+I370rLT+MW8X9CtTTfm/mJuo2yyoi5OpE6heVC121GbsejoaG644QZeeeUVn9Pvuece5syZQ3Z29jHTBg4cyPbt23n//fcZa63rNin5Rflc8cEV5Bbl8vG1H9M2sq3bIdUbu1Koyd69cPiwJQUX1eYXvT/dd999nHHGGdx887HPa7Zp04ZJkybx2muv+fzuhAkTePDBB0lMTCQzs3k1AtBUqSq3fXobq3av4uNrP+bUk051O6R6ZVcKNbHbUZu9mJgYrrnmGmbOnOlz+m9+8xv+9re/UVxcfMy0qVOn8sQTT9TqtZ0mMEz/djpvr3+bp0c/zWWnXOZ2OPXOkkJN7HZUAzzwwAPV3oV0xRVX+HwDW3x8PPfee6+/wzMN5MutX/Lg4ge54pQrePzsx90Oxy9q1XR2Y9LgTWc//DBMnw55ec5tqaZBWHPODcf2de38nPUzQ98YSqdWnVhxywpahQfWu9rru+ns5islBXr2tIRgTDOWeiiVMW87r4/55LpPAi4hHA+raK5JcrIVHRnTjO08tJNz55xLVn4Wi6cspmdMT7dD8iu7UqhOaanzGk6rZHZFoBVtBiLbx9XbeWgno+eMZn/efhZNWcTQzkPdDsnvLClUZ+dOOHLErhRcEBERQWZmpp20/EhVyczM9L5v2lSUlp3GuXPOZX/efhZPWcywzsPcDqlBWPFRdex2VNfEx8eTlpZGRkaG26E0aREREcTHx7sdRqOTlp3G6NmjycjLYNHkRc0mIYAlherZ7aiuCQ0NpYc1QGhcsCt7F+fOOZf03HQWTVnEmfFnuh1Sg7Lio+okJ0NUFHRqPg3CGtOclSWEfYf3sWjKIs6KP8vtkBqcJYXqlLV5JM3nfULGNFe7c3Zz7pxz2Xt4LwsnL2yWCQEsKVTPbkc1plkoSwh7Du9hweQFDO8y3O2QXGNJoSrFxbBtm1UyG9PE7cnZw7lzzmV3zm4WTl7IiC4j3A7JVZYUqrJ9u5MY7ErBmCZrS9YWb0JYcP2CZp8QwJJC1ZKTnU+7UjCmSVqwZQFD3xhKRl4GC65fwMiuI90OqVGwpFAVux3VmCZJVfnDsj8w9t2xdGvdjVW/WmUJoRx7TqEqycnQujXExbkdiTGmnhwuPMzUT6by4aYPue6063hz/Ju0CGvhdliNiiWFqqSkOEVHdjuqMU3Cz1k/c/kHl7MpYxPPj3meB4Y/gNj/72NYUqhKcjKMtEtKY5qChVsWct0/rkMQFly/gDE9x7gdUqNldQq+FBRAaqpVMhsT4FSVPy77I2PfG0uX6C6sunWVJYQa2JWCL1u3gqpVMhsTwHILc5k6fyrzNs7jmlOvYdaEWVZ/UAuWFHwpux3VkoIxAWn7we1MeH8CGzM28scL/shvR/zW6g9qyZKCL3Y7qjEBq6zJioMFB/l80udc1Osit0MKKH6tUxCRi0Vks4hsEZFHqpnvKhFREanxpdINIjkZ2rWDNm3cjsQYcxwOFhzk4ncuJiPXeQ+CJYTj57ekICLBwAzgEqA/MFFE+vuYrxVwD/Cdv2I5bmW3oxpjAkZ+UT4T3p/AT/t/4l/X/qtZvDrTH/x5pTAM2KKqW1W1EJgLXOZjvmeAPwEFfozl+JQ1mW2MCQjFpcVc94/rWJa6jLeveNvuMDoB/kwKnYGd5YbTPOO8RGQQ0EVVP61uQSJyq4isEpFVfn89Y0YG7N4Np57q3/UYY+qFqnLbv29j/ub5vHLJK1x72rVuhxTQ/JkUfFX1e9/CLiJBwEvAAzUtSFVfV9UhqjqkXbt29RiiD0lJzudQu/Q0JhA89p/HmLVuFr8/+/fcNewut8MJeP5MCmlAl3LD8cDucsOtgNOARBHZDpwFzHe9sjkpyWna4owzXA3DGFOz6d9O5/+W/R+3nnErT49+2u1wmgR/JoUkoLeI9BCRMOA6YH7ZRFU9pKpxqtpdVbsD3wITVHWVH2OqWVIS9OsHrVq5GoYxpnrvrn+X+xfez5X9ruS1S1+z5xDqid+SgqoWA3cBC4EfgXmqulFEponIBH+t94SoOknBio6MadS+SPmCmz65idHdR/Pule8SHBTsdkhNhl8fXlPVz4HPK417oop5R/szllrZuRPS0y0pGNOIfZv2LVd9eBUDThrAJ9d9QkRIhNshNSnWIF55VslsTKP2Y8aPXPrepXRs2ZEvrv+C6PBot0NqciwplJeUBKGhcPrpbkdijCkntzCXP6/8M+f9/TzCgsNYNGUR7Vu2dzusJsmSQnlJSTBwIISHux2JMQbYk7OHx756jC4vdeHuL+6me5vuLJq8iJPbnux2aA0qPz+ffv368eGHH/p9XdYgXpnSUli1CiZNcjsSY5q9DekbeHHFi7z3w3sUlRRxRb8reGD4A4zoMsLt0FyxYsUKfvrpJ1q08H/T35YUyqSkQHa21ScY4xJV5attX/HCNy+w8OeFRIVG8aszfsV9Z91Hr5hebofnqsTERIKDgxk1apTf12VJoYxVMhvjikMFh5i/eT4vrHiB9fvW075Fe54991luH3I7sVGxbofXKCxZsoTBgwcTHe3/inVLCmWSkiAqynlwzRhTrwpLCtl6YCvJmcls3r+Z5MxkkrOc/n25+wA4td2pzJowi0kDJhEeYvV6ZfLy8vjuu++4//77G2R9lhTKJCU5TVuE2C4x5kTsPbyXb3Z+w4qdK/hx/49sztzMtgPbKNES7zztotrRN64vl/a+lD6xfRjaeSjndj/Xnkr24ZtvvqGoqIhzzz23QdZnZ0CAoiJYuxbuuMPtSIwJKCWlJWxI38A3O7/hm7RvWJ66nG0HtwEQFhzGKXGnkNAhgWtPvZa+sX3pE9uHPrF9aBvZ1uXIA0dZfcLIkSMbZH2WFAA2boSCAqtPMKYGBwsOkrQrieU7l/PNzm/4Nu1bcgpzAGjfoj0ju47kzqF3MrLrSAZ1GGTFQPVgyZIlDB06lFYN1B6bJQWwSmZjfMjMy2TNnjWs3rPa+7n1wFYABGFA+wFMHjiZEV1GMKLLCHq06WHFP/UsNzeXlStX8uCDDzbYOi0pgJMU2raFnj3djsSYBqeqpOems3bvWu/Jf/Xu1ew4tMM7T482PTij4xn8ctAvGdJpCGfGn2lNTDSA5cuXU1xc3GD1CWBJwZGUBEOGOO9RMKYJUlUy8jJIyUxhS9YWUrIqfmYfyfbO2yumF2fGn8mvh/6awR0HM6jjIGIiY1yMvvlKTEwkJCSEESMa7qE9Swr5+fDDD/Dww25HYky9yT6SzbyN8/hy65c+T/zBEkz3Nt3pFdOLEfEj6BXTi4HtBzKo4yDaRLRxMXJT3pIlSxg2bBgtW7ZssHVaUli3DkpKrD7BBLxSLWXpjqW8te4tPtr0EXlFeXRt3ZV+cf0YET+C3rG96RXTi94xvenWphthwWFuh2yqkZOTQ1JSEg838A9WSwpWyWwCXOqhVOasm8Ps72ez9cBWosOjmTxgMlMHTWVY52FW+Rugli9fTklJSYPWJ4AlBScpdOwInTu7HYkxtZZflM/HP33MW+ve4sutX6Io5/U4j6dHP82V/a4kKjTK7RDNCVqyZAmhoaENWp8AlhTs9ZsmYJSUlvB16td8sOED5m6cy8GCg3Rr3Y0nznmCG0+/kR5te7gdoqlHiYmJnHnmmURFNWyCb95J4dAh2LwZJk92OxJjfCpLBPM2zuOfP/6Tfbn7iAyJ5Mp+V3Jzws2c2+NcgsRei9LUZGdns3r1an73u981+Lqbd1JYvdr5tCsF04iUlJawdMdSPtz0YYVEcGmfS7m6/9Vc2vtSWoT5v119455ly5a5Up8AzT0plFUyDxnibhym2asuEVzT/xrG9h5riaAZWbJkCWFhYZx11lkNvu7mnRRWrnSeYo61NtuNO9Ky05i1dhZvrnmTndk7iQyJZFyfcVzd/2pLBM2YW/UJ0NyTQlISNFDLg8aUKSkt4YstX/D66tf5LOUzSrWUMSeP4fkxzzOuzzhLBM3coUOHWLNmDY8//rgr62++SWHfPti50+oTTIPZeWgnM9fOZObamaRlp9G+RXseHvkwvzzjl83uRfSmal9//TWlpaWMHj3alfU336RgD62ZBlBcWsznKZ/z+urX+WLLF6gqF/W6iJcvfpnxfcYTGhzqdoimkVmyZAnh4eEMHz7clfU376QQFOS8bc2YerYnZw9vrHmD11e/zq6cXXRs2ZFHRz3KLWfcQvc23d0OzzRiiYmJnHXWWURERLiy/uadFPr3hxZWfmvqh6qyLHUZM5Jm8I8f/0FxaTEX9byIP4/9M+P6jCMkqPn+dzO1c+DAAdauXcuTTz7pWgzN869U1UkK48e7HYlpAg4XHubd9e/y2qrXWL9vPW0i2nD3sLu5Y8gd9I7t7XZ4JoB8/fXXqKpr9QnQXJPCjh2wf7/VJ5gTkpyZzGtJr/HWurfIPpJNQocE3hj/BhNPm2h3EJk6WbJkCREREZx55pmuxdA8k4JVMps6yi/K59/J/+bNNW+yeOtiQoNCuar/Vdw59E5GdBlhLZKaE5KYmMjw4cNdq0+A5pwUwsJg4EC3IzEBoKS0hMTtibz7w7t8tOkjcgpziI+O55lzn+FXZ/yK9i3bux2iaQKysrL4/vvvefrpp12No/kmhdNPdxKDMT6oKt/v+55317/LexveY3fOblqFteKq/lcxeeBkzul2DsFBwW6HaZqQpUuXul6fAM0xKZSWOg3hTZnidiSmEUo9lMp7P7zHO+vfYWPGRkKCQhjbeyyTB0xmXJ9xRIZGuh2iaaKWLFlCZGQkw4YNczWO5pcUNm+GnByrTzAVpGSmcOfnd7J462IARnYZyWtjX+PqU68mLirO5ehMc5CYmMiIESMIDw93NY7mlxSsktmUo6r8ddVfeXDxg4QFhzFt9DSuH3i9NTthGtT+/ftZv349zz77rNuhNNOk0KIFnHKK25EYl+3O2c0t829hwZYFXNjzQmZNmEXnaHstq2l4S5cuBXC9PgGaa1IYPBiCrZKwOZu3cR53fHYH+UX5zBg7gzuG3GG3kxrXLFmyhKioKIY2ghKM5vUev8JCWLfOio6asQP5B5j0j0lc+9G19Irpxdrb1vLrob+2hGBclZiYyMiRIwlrBHdE+jUpiMjFIrJZRLaIyCM+pv9GRDaJyHoR+UpEuvkzHjZsgCNHLCk0U4t/XsyAvwzgw00fMm30NJZPXU7fuL5uh2WauYyMDDZs2ODKqzd98VtSEJFgYAZwCdAfmCgi/SvNthYYoqoDgY+AP/krHsAqmZupvKI87v78bi5850JahbdixS0r+P05v7cG6kyj8N///hdoHPUJ4N86hWHAFlXdCiAic4HLgE1lM6jqknLzfwtM9mM8TlKIjYUePfy6GtN4JO1KYsq/prA5czP3nnkv/3f+/9mzBqZRWbJkCS1atGBII3lXvD+LjzoDO8sNp3nGVeUW4AtfE0TkVhFZJSKrMjIy6h5RUhIMGQJWftzkFZYU8sSSJxg+czi5Rbl8OeVLpl883RKCaXQSExMZNWoUoaGN44VL/kwKvs686nNGkcnAEOB5X9NV9XVVHaKqQ9q1a1e3aPLyYONGKzpqBjakb+CsN8/imaXPcP3A6/nhjh84/+Tz3Q7LmGPs27ePTZs2NZr6BPBv8VEa0KXccDywu/JMInIB8Bhwjqoe8Vs0a9dCSYklhXqSlZXFnj176NChAzExMX67e0dVyc7O5sCBAxw4cICsrCwOHDjAwYMHKS4urjBvqZbyZd6X/Pvwv4mQCG5rfRsJexP4eO7HdOvWjR49ehAfH09IiNUlBCpVbTJ3ih05coTPPvsMaDz1CeDfpJAE9BaRHsAu4DpgUvkZRGQQ8DfgYlVN92MsVslcR6rKzp07Wbt2LWvXrmXdunWsXbuW1NRU7zwRERF06tSJzp07++w6depESUkJ2dnZHDp0yNtVHi7rKp/8S0pKag60LXA50A34EQ5/epi/5f7tmNmCg4Pp0qULPXr0oEePHnTv3t3b361bNyIjI1FVVJXS0lJvf+VxIkJoaOgxXXBw8DEnrdLSUrKysti3bx979+5l7969FfrLhnNzc4mNjSUuLo64uLgK/eW72NhYAAoLCyksLOTIkSM+PwsLC8nLy+PQoUMcPHjQu3999efk5NChQwf69OlDnz596Nu3r/ezQ4cOfjsRHzlyhOzsbLKyssjIyCA9Pd3b+RrOzMykRYsWtG/fnvbt29OhQwdvf+WuRYsWFf7Gqvr7y8nJITg4mIiICCIjI4mIiDimv2w4NDS02r+Lsq6kpIRDhw6RmZlJVlZWhc+y/tzcXACio6MZPHiwX/ZvXYiqzxKd+lm4yFhgOhAMzFLV50RkGrBKVeeLyJfAAGCP5yupqjqhumUOGTJEV61adfzBrF0LX34Jv/3t8X83AO3fv581a9awevVq1qxZQ2pqKq1atSI6OprWrVt7u/LD0dHRtGzZku3bt1dIAllZWQCICH369GHQoEEMGjSILl26sHfvXnbt2nVMd+RI7S/6IiMjvetv06YNbdu2pW3btsTExHj7fQ2Hhoaiqvz9x78zbcU0QoJCeHbks1zV+6oKJ7Hc3Fy2b9/Otm3bvJ9l3d69e+t934eFhXmTREhIiM+rGnCSadlJrUOHDkRFRZGVlcX+/fu9XdmJoz6EhobSpk0bWrdufcxny5Yt2b17N8nJySQnJ1NQUOD9XqtWrbzJok+fPnTu3JnS0lJKSkq8XXFxcYXhsnGHDx+u9odAdX8nbdu2pV27dpx00kneLjY2lpycHPbt21ehK/sbPR5RUVG0bt2aVq1aUVpaSn5+PgUFBRQUFJCfn09paWmd9nN5wcHBxMTEEBMTQ2xsrPezfP/gwYMb5KE1EVmtqjXWZvs1KfhDnZNCE5aens7q1au9CWD16tUVfsmffPLJ9OzZk9zc3Ar/ObOzs6tcZnh4OAMGDGDQoEEkJCQwaNAgBg4cSItavNNaVcnKymL37t3s2rWL3bt3Exoa6jMhRUdH1/mBnV3Zu7hl/i0s/HkhY04ew8wJM+nSukvNXywnPz+fHTt2sG3bNnbs2EFhYSEiQlBQECLi7SoPqypFRUVVdoWFhRQVFVFcXEybNm3o0KGDtytLAtHR0TX+As/PzyczM9ObJMr6RYTw8HDCwsIICwvz2R8eHk5ERIT3xB8REVGrX/ylpaWkpaWxefNmkpOTK3zu2LGD2p4zRMTnDxFfP0jatm3LSSed5E0CcXFxx/V3UVhYSEZGhveqa9++feTl5flcV1kiqK5iV1UpLi72JoiyZFFUVFTh76C6v5Wy9QYFNY5nhC0pVPLWW28xffr0Ki81y7p27drVqcy5tLSUffv2sWPHDlJTU9mxY4e3S01NZefOnZSUlHj/o0ZERHj7K48r+wVcWlpaoSsbV1xaTF5oHjkhOezctZPMfZlQBBRDt87dOL3/6QwaMIhhg4Zx5uAziY2JrTLmnJycCr/gsrOziY+P55RTTnHtboji0mLyi/LJL84nryiPvKI88ouc/rJxOw7u4Kn/PkVhSSHPj3nemqloIAUFBWRkZBAcHOztQkJCKgyXdXY8GpfaJoVmU+MWFh1GbL9Ydh3cxfqt6zmw4QCFUgjhHNOFtgwlVEMJKQwhtCiU8KJwworCCC8JJ7I0ksiSSCIlktCQUAoLC0ndmUpqRipFkUXQCoh2utDYUMK7hMOpUBheSCihSLE43RFB85Wi/CJKDpeQl50H6VCY5/zCJARKWpVQFF1EUcsiClsXUtiykMIWhRRGFaJBnmRe6eVxOzz/5ufPh2+AbyA8OJyIkAhCg0MJCQohNMjzWcWw7lGKvyumuPRoV6IlFYaLS4sJkiBiImOIjYwlLiqO2MhYYqNijw57+mMiY8gvzicjN4P9efvJyHM+y/eXTTtQcIDCksJaHdMRXUYw5/I59IrpVV9/JqYGERERdOlyfFdjJrA0m6SQ1j6NJf2WVDk9IiiCcMIJKQkhqDiIQi2kIKiA7OBs3zfXlkJoYShBpUEU/U8RpUEVyx+DJIiTWp5EfHQ8naM706llJ3KLctmVs4u07DR2Ze/i0JFDxyw2JjKGqNAodmXvQsvdwRsdHk2fmD70iulFz7Y9nc+YnoQFh3l/VVf3WVBcQHFpMUWlRRU/S44dDpIgQoJCKnTBQcFHh8X5LC4tJqsgi8y8TDZlbCIzP5PMvExKtOaKYUGIjYqlXVQ74qLi6BvXl5GRI2kb2ZYWoS2ICo0iMjSSqNAopz8kssK4FqEt6BnTkyBpHJfmxjQVzSYpjO87nu5tuhMdHk3riNZEh0d7u5ZhLats8qC4tJjMvEzSc9NJz00nIy/D25+em05eUR6dW3Wmc3RnJwG0cj7bt2xfYzMKhwsPsyvbSRJp2WnehHG48DAntz2ZXjG9vF1sZGxAXI6rKtlHstmft9+bJLLys4gMjfQmgHYt2tE2oq29ztKYRqjZ1CkYY0xzVts6Bbv2NsYY42VJwRhjjJclBWOMMV6WFIwxxnhZUjDGGONlScEYY4yXJQVjjDFelhSMMcZ4BdzDayKSAeyoNDoO2O9COP7S1LYHmt42NbXtgaa3TU1te+DEtqmbqtb46sqASwq+iMiq2jypFyia2vZA09umprY90PS2qaltDzTMNlnxkTHGGC9LCsYYY7yaSlJ43e0A6llT2x5oetvU1LYHmt42NbXtgQbYpiZRp2CMMaZ+NJUrBWOMMfXAkoIxxhivgE4KInKxiGwWkS0i8ojb8dQHEdkuIj+IyDoRCci3CYnILBFJF5EN5cbFiMhiEUnxfLZ1M8bjUcX2PCUiuzzHaZ2IjHUzxuMhIl1EZImI/CgiG0XkXs/4QD5GVW1TQB4nEYkQkZUi8r1ne572jO8hIt95jtEHIhJW7+sO1DoFEQkGkoExQBqQBExU1U2uBnaCRGQ7MERVA/ahGxE5GzgM/F1VT/OM+xOQpap/8CTwtqr6sJtx1lYV2/MUcFhVX3AztroQkY5AR1VdIyKtgNXA5cBNBO4xqmqbriEAj5M4795toaqHRSQUWAbcC/wG+KeqzhWRvwLfq+pf6nPdgXylMAzYoqpbVbUQmAtc5nJMBlDVpUBWpdGXAXM8/XNw/sMGhCq2J2Cp6h5VXePpzwF+BDoT2Meoqm0KSOo47BkM9XQKnAd85Bnvl2MUyEmhM7Cz3HAaAfxHUI4Ci0RktYjc6nYw9ai9qu4B5z8wcJLL8dSHu0Rkvad4KWCKWsoTke7AIOA7msgxqrRNEKDHSUSCRWQdkA4sBn4GDqpqsWcWv5zzAjkpiI9xgVkWVtFIVT0DuAS401N0YRqfvwA9gQRgD/Ciu+EcPxFpCfwDuE9Vs92Opz742KaAPU6qWqKqCUA8TslIP1+z1fd6AzkppAFdyg3HA7tdiqXeqOpuz2c68C+cP4amYJ+n3Les/Dfd5XhOiKru8/ynLQXeIMCOk6ec+h/Au6r6T8/ogD5GvrYp0I8TgKoeBBKBs4A2IhLimeSXc14gJ4UkoLenNj4MuA6Y73JMJ0REWngqyRCRFsCFwIbqvxUw5gM3evpvBD5xMZYTVnby9LiCADpOnkrMmcCPqvr/yk0K2GNU1TYF6nESkXYi0sbTHwlcgFNPsgS4yjObX45RwN59BOC5vWw6EAzMUtXnXA7phIjIyThXBwAhwHuBuE0i8j4wGqeZ333Ak8DHwDygK5AKXK2qAVF5W8X2jMYpklBgO3BbWXl8Yycio4CvgR+AUs/oR3HK4AP1GFW1TRMJwOMkIgNxKpKDcX68z1PVaZ5zxFwgBlgLTFbVI/W67kBOCsYYY+pXIBcfGWOMqWeWFIwxxnhZUjDGGONlScEYY4yXJQVjjDFelhSM8RCRknKtaa6rz5Z3RaR7+VZWjWmsQmqexZhmI9/TrIAxzZZdKRhTA887Lv7oad9+pYj08ozvJiJfeRpb+0pEunrGtxeRf3nawv9eREZ4FhUsIm942sdf5HlSFRG5R0Q2eZYz16XNNAawpGBMeZGVio+uLTctW1WHAX/GeYoeT//fVXUg8C7wimf8K8B/VfV04Axgo2d8b2CGqp4KHAR+4Rn/CDDIs5zb/bVxxtSGPdFsjIeIHFbVlj7GbwfOU9WtnkbX9qpqrIjsx3mxS5Fn/B5VjRORDCC+fPMDnuacF6tqb8/ww0Coqj4rIgtwXuLzMfBxuXb0jWlwdqVgTO1oFf1VzeNL+TZqSjhap3cpMAMYDKwu1wqmMQ3OkoIxtXNtuc8Vnv5vcFrnBbge55WJAF8Bd4D3RSnRVS1URIKALqq6BHgIaAMcc7ViTEOxXyTGHBXpedNVmQWqWnZbariIfIfzQ2qiZ9w9wCwR+S2QAdzsGX8v8LqI3IJzRXAHzgtefAkG3hGR1jgvjnrJ036+Ma6wOgVjauCpUxiiqvvdjsUYf7PiI2OMMV52pWCMMcbLrhSMMcZ4WVIwxhjjZUnBGGOMlyUFY4wxXpYUjDHGeP1/OpoMxQ+UrMoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figsize=(16,4)\n",
    "history1_dict = history1.history\n",
    "#history_dict.keys()\n",
    "history2_dict = history2.history\n",
    "history3_dict = history3.history\n",
    "acc_values1 = history1_dict['acc']\n",
    "acc_values2 = history2_dict['acc']\n",
    "acc_values3 = history3_dict['acc']\n",
    "epochs = range(1, len(history1_dict['acc']) + 1)\n",
    "plt.plot(epochs,  acc_values1, 'b', label='SimpleRNN',color='r')\n",
    "plt.plot(epochs, acc_values2, 'b', label='LSTM', color='black')\n",
    "plt.plot(epochs, acc_values3, 'b', label='NNM', color='green')\n",
    "plt.title('Accuracy on training data')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history2_dict = history2.history\n",
    "len(history2_dict['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
